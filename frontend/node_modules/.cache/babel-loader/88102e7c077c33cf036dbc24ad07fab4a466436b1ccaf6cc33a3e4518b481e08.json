{"ast":null,"code":"import _objectWithoutProperties from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/objectWithoutProperties.js\";\nimport _objectSpread from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\nimport _defineProperty from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nconst _excluded = [\"__META\"];\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport { dep } from \"optimism\";\nimport { isReference } from \"@apollo/client/utilities\";\nimport { __DEV__ } from \"@apollo/client/utilities/environment\";\nimport { DeepMerger, isNonNullObject, makeReference, maybeDeepFreeze } from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\nimport { fieldNameFromStoreName, hasOwn } from \"./helpers.js\";\nconst DELETE = {};\nconst delModifier = () => DELETE;\nconst INVALIDATE = {};\nexport class EntityStore {\n  constructor(policies, group) {\n    _defineProperty(this, \"policies\", void 0);\n    _defineProperty(this, \"group\", void 0);\n    _defineProperty(this, \"data\", {});\n    // Maps root entity IDs to the number of times they have been retained, minus\n    // the number of times they have been released. Retained entities keep other\n    // entities they reference (even indirectly) from being garbage collected.\n    _defineProperty(this, \"rootIds\", {});\n    // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n    _defineProperty(this, \"refs\", {});\n    // Bound function that can be passed around to provide easy access to fields\n    // of Reference objects as well as ordinary objects.\n    _defineProperty(this, \"getFieldValue\", (objectOrReference, storeFieldName) => maybeDeepFreeze(isReference(objectOrReference) ? this.get(objectOrReference.__ref, storeFieldName) : objectOrReference && objectOrReference[storeFieldName]));\n    // Returns true for non-normalized StoreObjects and non-dangling\n    // References, indicating that readField(name, objOrRef) has a chance of\n    // working. Useful for filtering out dangling references from lists.\n    _defineProperty(this, \"canRead\", objOrRef => {\n      return isReference(objOrRef) ? this.has(objOrRef.__ref) : typeof objOrRef === \"object\";\n    });\n    // Bound function that converts an id or an object with a __typename and\n    // primary key fields to a Reference object. If called with a Reference object,\n    // that same Reference object is returned. Pass true for mergeIntoStore to persist\n    // an object into the store.\n    _defineProperty(this, \"toReference\", (objOrIdOrRef, mergeIntoStore) => {\n      if (typeof objOrIdOrRef === \"string\") {\n        return makeReference(objOrIdOrRef);\n      }\n      if (isReference(objOrIdOrRef)) {\n        return objOrIdOrRef;\n      }\n      const [id] = this.policies.identify(objOrIdOrRef);\n      if (id) {\n        const ref = makeReference(id);\n        if (mergeIntoStore) {\n          this.merge(id, objOrIdOrRef);\n        }\n        return ref;\n      }\n    });\n    this.policies = policies;\n    this.group = group;\n  }\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n  toObject() {\n    return _objectSpread({}, this.data);\n  }\n  has(dataId) {\n    return this.lookup(dataId, true) !== void 0;\n  }\n  get(dataId, fieldName) {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (fieldName === \"__typename\" && hasOwn.call(this.policies.rootTypenamesById, dataId)) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n  lookup(dataId, dependOnExistence) {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n    if (this.policies.rootTypenamesById[dataId]) {\n      return {};\n    }\n  }\n  merge(older, newer) {\n    let dataId;\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n    const existing = typeof older === \"string\" ? this.lookup(dataId = older) : older;\n    const incoming = typeof newer === \"string\" ? this.lookup(dataId = newer) : newer;\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n    invariant(typeof dataId === \"string\", 99);\n    const merged = new DeepMerger({\n      reconciler: storeObjectReconciler\n    }).merge(existing, incoming);\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty = {};\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach(storeFieldName => {\n          if (!existing || existing[storeFieldName] !== merged[storeFieldName]) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (fieldName !== storeFieldName && !this.policies.hasKeyArgs(merged.__typename, fieldName)) {\n              fieldsToDirty[fieldName] = 1;\n            }\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n        if (fieldsToDirty.__typename && !(existing && existing.__typename) &&\n        // Since we return default root __typename strings\n        // automatically from store.get, we don't need to dirty the\n        // ROOT_QUERY.__typename field if merged.__typename is equal\n        // to the default string (usually \"Query\").\n        this.policies.rootTypenamesById[dataId] === merged.__typename) {\n          delete fieldsToDirty.__typename;\n        }\n        Object.keys(fieldsToDirty).forEach(fieldName => this.group.dirty(dataId, fieldName));\n      }\n    }\n  }\n  modify(dataId, fields, exact) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const changedFields = {};\n      let needToMerge = false;\n      let allDeleted = true;\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: (fieldNameOrOptions, from) => this.policies.readField(typeof fieldNameOrOptions === \"string\" ? {\n          fieldName: fieldNameOrOptions,\n          from: from || makeReference(dataId)\n        } : fieldNameOrOptions, {\n          store: this\n        })\n      };\n      Object.keys(storeObject).forEach(storeFieldName => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify = typeof fields === \"function\" ? fields : fields[storeFieldName] || (exact ? undefined : fields[fieldName]);\n        if (modify) {\n          let newValue = modify === delModifier ? DELETE : modify(maybeDeepFreeze(fieldValue), _objectSpread(_objectSpread({}, sharedDetails), {}, {\n            fieldName,\n            storeFieldName,\n            storage: this.getStorage(dataId, storeFieldName)\n          }));\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue;\n              if (__DEV__) {\n                const checkReference = ref => {\n                  if (this.lookup(ref.__ref) === undefined) {\n                    __DEV__ && invariant.warn(100, ref);\n                    return true;\n                  }\n                };\n                if (isReference(newValue)) {\n                  checkReference(newValue);\n                } else if (Array.isArray(newValue)) {\n                  // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                  let seenReference = false;\n                  let someNonReference;\n                  for (const value of newValue) {\n                    if (isReference(value)) {\n                      seenReference = true;\n                      if (checkReference(value)) break;\n                    } else {\n                      // Do not warn on primitive values, since those could never be represented\n                      // by a reference. This is a valid (albeit uncommon) use case.\n                      if (typeof value === \"object\" && !!value) {\n                        const [id] = this.policies.identify(value);\n                        // check if object could even be referenced, otherwise we are not interested in it for this warning\n                        if (id) {\n                          someNonReference = value;\n                        }\n                      }\n                    }\n                    if (seenReference && someNonReference !== undefined) {\n                      __DEV__ && invariant.warn(101, someNonReference);\n                      break;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n        return true;\n      }\n    }\n    return false;\n  }\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  delete(dataId, fieldName, args) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue(storeObject, \"__typename\");\n      const storeFieldName = fieldName && args ? this.policies.getStoreFieldName({\n        typename,\n        fieldName,\n        args\n      }) : fieldName;\n      return this.modify(dataId, storeFieldName ? {\n        [storeFieldName]: delModifier\n      } : delModifier, !!args);\n    }\n    return false;\n  }\n  evict(options, limit) {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n  clear() {\n    this.replace(null);\n  }\n  extract() {\n    const obj = this.toObject();\n    const extraRootIds = [];\n    this.getRootIdSet().forEach(id => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = {\n        extraRootIds: extraRootIds.sort()\n      };\n    }\n    return obj;\n  }\n  replace(newData) {\n    Object.keys(this.data).forEach(dataId => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const {\n          __META\n        } = newData,\n        rest = _objectWithoutProperties(newData, _excluded);\n      Object.keys(rest).forEach(dataId => {\n        this.merge(dataId, rest[dataId]);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n  retain(rootId) {\n    return this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1;\n  }\n  release(rootId) {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  getRootIdSet() {\n    let ids = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : new Set();\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach(id => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach(id => root.delete(id));\n    }\n    return idsToRemove;\n  }\n  findChildRefIds(dataId) {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = this.refs[dataId] = {};\n      const root = this.data[dataId];\n      if (!root) return found;\n      const workSet = new Set([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach(obj => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach(key => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n  makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n  get supportsResultCaching() {\n    return this.group.caching;\n  }\n}\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  constructor(caching) {\n    let parent = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n    _defineProperty(this, \"caching\", void 0);\n    _defineProperty(this, \"parent\", void 0);\n    _defineProperty(this, \"d\", null);\n    // Used by the EntityStore#makeCacheKey method to compute cache keys\n    // specific to this CacheGroup.\n    _defineProperty(this, \"keyMaker\", void 0);\n    this.caching = caching;\n    this.parent = parent;\n    this.resetCaching();\n  }\n  resetCaching() {\n    this.d = this.caching ? dep() : null;\n    this.keyMaker = new Trie();\n  }\n  depend(dataId, storeFieldName) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n  dirty(dataId, storeFieldName) {\n    if (this.d) {\n      this.d.dirty(makeDepKey(dataId, storeFieldName),\n      // When storeFieldName === \"__exists\", that means the entity identified\n      // by dataId has either disappeared from the cache or was newly added,\n      // so the result caching system would do well to \"forget everything it\n      // knows\" about that object. To achieve that kind of invalidation, we\n      // not only dirty the associated result cache entry, but also remove it\n      // completely from the dependency graph. For the optimism implementation\n      // details, see https://github.com/benjamn/optimism/pull/195.\n      storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\");\n    }\n  }\n}\nfunction makeDepKey(dataId, storeFieldName) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + \"#\" + dataId;\n}\nexport function maybeDependOnExistenceOfEntity(store, entityId) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\nclass Root extends EntityStore {\n  constructor(_ref) {\n    let {\n      policies,\n      resultCaching = true,\n      seed\n    } = _ref;\n    super(policies, new CacheGroup(resultCaching));\n    _defineProperty(this, \"stump\", new Stump(this));\n    _defineProperty(this, \"storageTrie\", new Trie());\n    if (seed) this.replace(seed);\n  }\n  addLayer(layerId, replay) {\n    // Adding an optimistic Layer on top of the Root actually adds the Layer\n    // on top of the Stump, so the Stump always comes between the Root and\n    // any Layer objects that we've added.\n    return this.stump.addLayer(layerId, replay);\n  }\n  removeLayer() {\n    // Never remove the root layer.\n    return this;\n  }\n  getStorage() {\n    return this.storageTrie.lookupArray(arguments);\n  }\n}\nEntityStore.Root = Root;\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(id, parent, replay, group) {\n    super(parent.policies, group);\n    _defineProperty(this, \"id\", void 0);\n    _defineProperty(this, \"parent\", void 0);\n    _defineProperty(this, \"replay\", void 0);\n    _defineProperty(this, \"group\", void 0);\n    this.id = id;\n    this.parent = parent;\n    this.replay = replay;\n    this.group = group;\n    replay(this);\n  }\n  addLayer(layerId, replay) {\n    return new Layer(layerId, this, replay, this.group);\n  }\n  removeLayer(layerId) {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach(dataId => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach(storeFieldName => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach(storeFieldName => {\n              if (!equal(ownStoreObject[storeFieldName], parentStoreObject[storeFieldName])) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n      return parent;\n    }\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n  toObject() {\n    return _objectSpread(_objectSpread({}, this.parent.toObject()), this.data);\n  }\n  findChildRefIds(dataId) {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ? _objectSpread(_objectSpread({}, fromParent), super.findChildRefIds(dataId)) : fromParent;\n  }\n  getStorage() {\n    let p = this.parent;\n    while (p.parent) p = p.parent;\n    return p.getStorage(...arguments);\n  }\n}\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root) {\n    super(\"EntityStore.Stump\", root, () => {}, new CacheGroup(root.group.caching, root.group));\n  }\n  removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n  merge(older, newer) {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge(older, newer);\n  }\n}\nfunction storeObjectReconciler(existingObject, incomingObject, property) {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\nexport function supportsResultCaching(store) {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store && store.supportsResultCaching);\n}","map":{"version":3,"names":["equal","Trie","dep","isReference","__DEV__","DeepMerger","isNonNullObject","makeReference","maybeDeepFreeze","invariant","fieldNameFromStoreName","hasOwn","DELETE","delModifier","INVALIDATE","EntityStore","constructor","policies","group","_defineProperty","objectOrReference","storeFieldName","get","__ref","objOrRef","has","objOrIdOrRef","mergeIntoStore","id","identify","ref","merge","toObject","_objectSpread","data","dataId","lookup","fieldName","depend","call","storeObject","rootTypenamesById","Layer","parent","dependOnExistence","older","newer","existing","incoming","merged","reconciler","storeObjectReconciler","refs","caching","fieldsToDirty","__exists","Object","keys","forEach","hasKeyArgs","__typename","dirty","modify","fields","exact","changedFields","needToMerge","allDeleted","sharedDetails","toReference","canRead","readField","fieldNameOrOptions","from","store","fieldValue","undefined","newValue","storage","getStorage","checkReference","warn","Array","isArray","seenReference","someNonReference","value","delete","args","typename","getFieldValue","getStoreFieldName","evict","options","limit","evicted","clear","replace","extract","obj","extraRootIds","getRootIdSet","push","length","__META","sort","newData","rest","_objectWithoutProperties","_excluded","retain","rootId","rootIds","release","count","ids","arguments","Set","add","gc","snapshot","findChildRefIds","idsToRemove","root","found","workSet","key","child","makeCacheKey","keyMaker","lookupArray","supportsResultCaching","CacheGroup","resetCaching","d","makeDepKey","maybeDependOnExistenceOfEntity","entityId","Root","_ref","resultCaching","seed","Stump","addLayer","layerId","replay","stump","removeLayer","storageTrie","ownStoreObject","parentStoreObject","fromParent","p","existingObject","incomingObject","property","existingValue","incomingValue"],"sources":["/home/zobair-qauomi/todo_app/node_modules/@apollo/src/cache/inmemory/entityStore.ts"],"sourcesContent":["import { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport type { DocumentNode, FieldNode, SelectionSetNode } from \"graphql\";\nimport type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep } from \"optimism\";\n\nimport type {\n  Reference,\n  StoreObject,\n  StoreValue,\n} from \"@apollo/client/utilities\";\nimport { isReference } from \"@apollo/client/utilities\";\nimport { __DEV__ } from \"@apollo/client/utilities/environment\";\nimport {\n  DeepMerger,\n  isNonNullObject,\n  makeReference,\n  maybeDeepFreeze,\n} from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\n\nimport type { Cache } from \"../core/types/Cache.js\";\nimport type {\n  CanReadFunction,\n  DeleteModifier,\n  InvalidateModifier,\n  Modifier,\n  ModifierDetails,\n  Modifiers,\n  ReadFieldOptions,\n  SafeReadonly,\n  ToReferenceFunction,\n} from \"../core/types/common.js\";\n\nimport { fieldNameFromStoreName, hasOwn } from \"./helpers.js\";\nimport type { Policies, StorageType } from \"./policies.js\";\nimport type { NormalizedCache, NormalizedCacheObject } from \"./types.js\";\n\nconst DELETE = {} as DeleteModifier;\nconst delModifier: Modifier<any> = () => DELETE;\nconst INVALIDATE = {} as InvalidateModifier;\n\nexport abstract class EntityStore implements NormalizedCache {\n  public declare static Root: typeof Root;\n\n  protected data: NormalizedCacheObject = {};\n\n  constructor(\n    public readonly policies: Policies,\n    public readonly group: CacheGroup\n  ) {}\n\n  public abstract addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any\n  ): Layer;\n\n  public abstract removeLayer(layerId: string): EntityStore;\n\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n  public toObject(): NormalizedCacheObject {\n    return { ...this.data };\n  }\n\n  public has(dataId: string): boolean {\n    return this.lookup(dataId, true) !== void 0;\n  }\n\n  public get(dataId: string, fieldName: string): StoreValue {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (\n      fieldName === \"__typename\" &&\n      hasOwn.call(this.policies.rootTypenamesById, dataId)\n    ) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n\n  protected lookup(\n    dataId: string,\n    dependOnExistence?: boolean\n  ): StoreObject | undefined {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return {};\n    }\n  }\n\n  public merge(older: string | StoreObject, newer: StoreObject | string): void {\n    let dataId: string | undefined;\n\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n\n    const existing: StoreObject | undefined =\n      typeof older === \"string\" ? this.lookup((dataId = older)) : older;\n\n    const incoming: StoreObject | undefined =\n      typeof newer === \"string\" ? this.lookup((dataId = newer)) : newer;\n\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n\n    invariant(typeof dataId === \"string\", \"store.merge expects a string ID\");\n\n    const merged: StoreObject = new DeepMerger({\n      reconciler: storeObjectReconciler,\n    }).merge(existing, incoming);\n\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty: Record<string, 1> = {};\n\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach((storeFieldName) => {\n          if (\n            !existing ||\n            existing[storeFieldName] !== merged[storeFieldName]\n          ) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (\n              fieldName !== storeFieldName &&\n              !this.policies.hasKeyArgs(merged.__typename, fieldName)\n            ) {\n              fieldsToDirty[fieldName] = 1;\n            }\n\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (\n          fieldsToDirty.__typename &&\n          !(existing && existing.__typename) &&\n          // Since we return default root __typename strings\n          // automatically from store.get, we don't need to dirty the\n          // ROOT_QUERY.__typename field if merged.__typename is equal\n          // to the default string (usually \"Query\").\n          this.policies.rootTypenamesById[dataId] === merged.__typename\n        ) {\n          delete fieldsToDirty.__typename;\n        }\n\n        Object.keys(fieldsToDirty).forEach((fieldName) =>\n          this.group.dirty(dataId as string, fieldName)\n        );\n      }\n    }\n  }\n\n  public modify(\n    dataId: string,\n    fields: Modifier<any> | Modifiers<Record<string, any>>,\n    exact: boolean\n  ): boolean {\n    const storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      const changedFields: Record<string, any> = {};\n      let needToMerge = false;\n      let allDeleted = true;\n\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: <V = StoreValue>(\n          fieldNameOrOptions: string | ReadFieldOptions,\n          from?: StoreObject | Reference\n        ) =>\n          this.policies.readField<V>(\n            typeof fieldNameOrOptions === \"string\" ?\n              {\n                fieldName: fieldNameOrOptions,\n                from: from || makeReference(dataId),\n              }\n            : fieldNameOrOptions,\n            { store: this }\n          ),\n      } satisfies Partial<ModifierDetails>;\n\n      Object.keys(storeObject).forEach((storeFieldName) => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify: Modifier<StoreValue> | undefined =\n          typeof fields === \"function\" ? fields : (\n            fields[storeFieldName] || (exact ? undefined : fields[fieldName])\n          );\n        if (modify) {\n          let newValue =\n            modify === delModifier ? DELETE : (\n              modify(maybeDeepFreeze(fieldValue), {\n                ...sharedDetails,\n                fieldName,\n                storeFieldName,\n                storage: this.getStorage(dataId, storeFieldName),\n              })\n            );\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue as StoreValue;\n\n              if (__DEV__) {\n                const checkReference = (ref: Reference) => {\n                  if (this.lookup(ref.__ref) === undefined) {\n                    invariant.warn(\n                      \"cache.modify: You are trying to write a Reference that is not part of the store: %o\\n\" +\n                        \"Please make sure to set the `mergeIntoStore` parameter to `true` when creating a Reference that is not part of the store yet:\\n\" +\n                        \"`toReference(object, true)`\",\n                      ref\n                    );\n                    return true;\n                  }\n                };\n                if (isReference(newValue)) {\n                  checkReference(newValue);\n                } else if (Array.isArray(newValue)) {\n                  // Warn about writing \"mixed\" arrays of Reference and non-Reference objects\n                  let seenReference: boolean = false;\n                  let someNonReference: unknown;\n                  for (const value of newValue) {\n                    if (isReference(value)) {\n                      seenReference = true;\n                      if (checkReference(value)) break;\n                    } else {\n                      // Do not warn on primitive values, since those could never be represented\n                      // by a reference. This is a valid (albeit uncommon) use case.\n                      if (typeof value === \"object\" && !!value) {\n                        const [id] = this.policies.identify(value);\n                        // check if object could even be referenced, otherwise we are not interested in it for this warning\n                        if (id) {\n                          someNonReference = value;\n                        }\n                      }\n                    }\n                    if (seenReference && someNonReference !== undefined) {\n                      invariant.warn(\n                        \"cache.modify: Writing an array with a mix of both References and Objects will not result in the Objects being normalized correctly.\\n\" +\n                          \"Please convert the object instance %o to a Reference before writing it to the cache by calling `toReference(object, true)`.\",\n                        someNonReference\n                      );\n                      break;\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  public delete(\n    dataId: string,\n    fieldName?: string,\n    args?: Record<string, any>\n  ) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue<string>(storeObject, \"__typename\");\n      const storeFieldName =\n        fieldName && args ?\n          this.policies.getStoreFieldName({ typename, fieldName, args })\n        : fieldName;\n      return this.modify(\n        dataId,\n        storeFieldName ?\n          {\n            [storeFieldName]: delModifier,\n          }\n        : delModifier,\n        !!args\n      );\n    }\n    return false;\n  }\n\n  public evict(options: Cache.EvictOptions, limit: EntityStore): boolean {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n\n  public clear(): void {\n    this.replace(null);\n  }\n\n  public extract(): NormalizedCacheObject {\n    const obj = this.toObject();\n    const extraRootIds: string[] = [];\n    this.getRootIdSet().forEach((id) => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = { extraRootIds: extraRootIds.sort() };\n    }\n    return obj;\n  }\n\n  public replace(newData: NormalizedCacheObject | null): void {\n    Object.keys(this.data).forEach((dataId) => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const { __META, ...rest } = newData;\n      Object.keys(rest).forEach((dataId) => {\n        this.merge(dataId, rest[dataId] as StoreObject);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n\n  public abstract getStorage(\n    idOrObj: string | StoreObject,\n    ...storeFieldNames: (string | number)[]\n  ): StorageType;\n\n  // Maps root entity IDs to the number of times they have been retained, minus\n  // the number of times they have been released. Retained entities keep other\n  // entities they reference (even indirectly) from being garbage collected.\n  private rootIds: {\n    [rootId: string]: number;\n  } = {};\n\n  public retain(rootId: string): number {\n    return (this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1);\n  }\n\n  public release(rootId: string): number {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  public getRootIdSet(ids = new Set<string>()) {\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  public gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach((id) => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root: EntityStore = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach((id) => root.delete(id));\n    }\n    return idsToRemove;\n  }\n\n  // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n  private refs: {\n    [dataId: string]: Record<string, true>;\n  } = {};\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = (this.refs[dataId] = {} as Record<string, true>);\n      const root = this.data[dataId];\n      if (!root) return found;\n\n      const workSet = new Set<Record<string | number, any>>([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach((obj) => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach((key) => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n\n  // Used to compute cache keys specific to this.group.\n  /** overload for `InMemoryCache.maybeBroadcastWatch` */\n  public makeCacheKey(\n    document: DocumentNode,\n    callback: Cache.WatchCallback<any>,\n    details: string\n  ): object;\n  /** overload for `StoreReader.executeSelectionSet` */\n  public makeCacheKey(\n    selectionSet: SelectionSetNode,\n    parent: string /* = ( Reference.__ref ) */ | StoreObject,\n    varString: string | undefined\n  ): object;\n  /** overload for `StoreReader.executeSubSelectedArray` */\n  public makeCacheKey(\n    field: FieldNode,\n    array: readonly any[],\n    varString: string | undefined\n  ): object;\n  /**\n   * @deprecated This is only meant for internal usage,\n   * in your own code please use a `Trie` instance instead.\n   */\n  public makeCacheKey(...args: any[]): object;\n  public makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n\n  // Bound function that can be passed around to provide easy access to fields\n  // of Reference objects as well as ordinary objects.\n  public getFieldValue = <T = StoreValue>(\n    objectOrReference: StoreObject | Reference | undefined,\n    storeFieldName: string\n  ) =>\n    maybeDeepFreeze(\n      isReference(objectOrReference) ?\n        this.get(objectOrReference.__ref, storeFieldName)\n      : objectOrReference && objectOrReference[storeFieldName]\n    ) as SafeReadonly<T>;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  public canRead: CanReadFunction = (objOrRef) => {\n    return isReference(objOrRef) ?\n        this.has(objOrRef.__ref)\n      : typeof objOrRef === \"object\";\n  };\n\n  // Bound function that converts an id or an object with a __typename and\n  // primary key fields to a Reference object. If called with a Reference object,\n  // that same Reference object is returned. Pass true for mergeIntoStore to persist\n  // an object into the store.\n  public toReference: ToReferenceFunction = (objOrIdOrRef, mergeIntoStore) => {\n    if (typeof objOrIdOrRef === \"string\") {\n      return makeReference(objOrIdOrRef);\n    }\n\n    if (isReference(objOrIdOrRef)) {\n      return objOrIdOrRef;\n    }\n\n    const [id] = this.policies.identify(objOrIdOrRef);\n\n    if (id) {\n      const ref = makeReference(id);\n      if (mergeIntoStore) {\n        this.merge(id, objOrIdOrRef);\n      }\n      return ref;\n    }\n  };\n\n  public get supportsResultCaching(): boolean {\n    return this.group.caching;\n  }\n}\n\nexport type FieldValueGetter = EntityStore[\"getFieldValue\"];\n\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  private d: OptimisticDependencyFunction<string> | null = null;\n\n  // Used by the EntityStore#makeCacheKey method to compute cache keys\n  // specific to this CacheGroup.\n  public keyMaker!: Trie<object>;\n\n  constructor(\n    public readonly caching: boolean,\n    private parent: CacheGroup | null = null\n  ) {\n    this.resetCaching();\n  }\n\n  public resetCaching() {\n    this.d = this.caching ? dep<string>() : null;\n    this.keyMaker = new Trie();\n  }\n\n  public depend(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n\n  public dirty(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d.dirty(\n        makeDepKey(dataId, storeFieldName),\n        // When storeFieldName === \"__exists\", that means the entity identified\n        // by dataId has either disappeared from the cache or was newly added,\n        // so the result caching system would do well to \"forget everything it\n        // knows\" about that object. To achieve that kind of invalidation, we\n        // not only dirty the associated result cache entry, but also remove it\n        // completely from the dependency graph. For the optimism implementation\n        // details, see https://github.com/benjamn/optimism/pull/195.\n        storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\"\n      );\n    }\n  }\n}\n\nfunction makeDepKey(dataId: string, storeFieldName: string) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + \"#\" + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(\n  store: NormalizedCache,\n  entityId: string\n) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\nclass Root extends EntityStore {\n  constructor({\n    policies,\n    resultCaching = true,\n    seed,\n  }: {\n    policies: Policies;\n    resultCaching?: boolean;\n    seed?: NormalizedCacheObject;\n  }) {\n    super(policies, new CacheGroup(resultCaching));\n    if (seed) this.replace(seed);\n  }\n\n  public readonly stump = new Stump(this);\n\n  public addLayer(layerId: string, replay: (layer: EntityStore) => any): Layer {\n    // Adding an optimistic Layer on top of the Root actually adds the Layer\n    // on top of the Stump, so the Stump always comes between the Root and\n    // any Layer objects that we've added.\n    return this.stump.addLayer(layerId, replay);\n  }\n\n  public removeLayer(): Root {\n    // Never remove the root layer.\n    return this;\n  }\n\n  public readonly storageTrie = new Trie<StorageType>();\n  public getStorage(): StorageType {\n    return this.storageTrie.lookupArray(arguments);\n  }\n}\nEntityStore.Root = Root;\n\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(\n    public readonly id: string,\n    public readonly parent: EntityStore,\n    public readonly replay: (layer: EntityStore) => any,\n    public readonly group: CacheGroup\n  ) {\n    super(parent.policies, group);\n    replay(this);\n  }\n\n  public addLayer(layerId: string, replay: (layer: EntityStore) => any): Layer {\n    return new Layer(layerId, this, replay, this.group);\n  }\n\n  public removeLayer(layerId: string): EntityStore {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach((dataId) => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach((storeFieldName) => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach((storeFieldName) => {\n              if (\n                !equal(\n                  ownStoreObject[storeFieldName],\n                  parentStoreObject[storeFieldName]\n                )\n              ) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    }\n\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n\n  public toObject(): NormalizedCacheObject {\n    return {\n      ...this.parent.toObject(),\n      ...this.data,\n    };\n  }\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ?\n        {\n          ...fromParent,\n          ...super.findChildRefIds(dataId),\n        }\n      : fromParent;\n  }\n\n  public getStorage(\n    ...args: Parameters<EntityStore[\"getStorage\"]>\n  ): StorageType {\n    let p: EntityStore = this.parent;\n    while ((p as Layer).parent) p = (p as Layer).parent;\n    return p.getStorage(...args);\n  }\n}\n\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root: Root) {\n    super(\n      \"EntityStore.Stump\",\n      root,\n      () => {},\n      new CacheGroup(root.group.caching, root.group)\n    );\n  }\n\n  public removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n\n  public merge(older: string | StoreObject, newer: string | StoreObject) {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge(older, newer);\n  }\n}\n\nfunction storeObjectReconciler(\n  existingObject: StoreObject,\n  incomingObject: StoreObject,\n  property: string | number\n): StoreValue {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store: any): store is EntityStore {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store && store.supportsResultCaching);\n}\n"],"mappings":";;;;AAAA,SAASA,KAAT,QAAsB,eAAe;AACrC,SAASC,IAAT,QAAqB,WAAW;AAGhC,SAASC,GAAT,QAAoB,UAAU;AAO9B,SAASC,WAAT,QAA4B,0BAA0B;AACtD,SAASC,OAAT,QAAwB,sCAAsC;AAC9D,SACEC,UAAU,EACVC,eAAe,EACfC,aAAa,EACbC,eAAe,QACV,mCAAmC;AAC1C,SAASC,SAAT,QAA0B,oCAAoC;AAe9D,SAASC,sBAAsB,EAAEC,MAAjC,QAA+C,cAAc;AAI7D,MAAMC,MAAN,GAAe,CAAf,CAAmC;AACnC,MAAMC,WAAN,GAAmCA,CAAA,KAAMD,MAAM;AAC/C,MAAME,UAAN,GAAmB,CAAnB,CAA2C;AAE3C,aAAsBC,WAAtB;EAKEC,WAAFA,CACoBC,QAAkB,EAClBC,KAAiB,EAFrC;IAAAC,eAAA;IAAAA,eAAA;IAAAA,eAAA,eAF0C,CAA1C,CAA4C;IA8X1C;IACA;IACA;IAAAA,eAAA,kBAGI,CAFN,CAEQ;IAyDN;IAAAA,eAAA,eAGI,CAFN,CAEQ;IAiEN;IACA;IAAAA,eAAA,wBACuB,CACrBC,iBAAsD,EACtDC,cAAsB,KAEtBb,eAAe,CACbL,WAAW,CAACiB,iBAAiB,IAC3B,IAAI,CAACE,GAAG,CAACF,iBAAiB,CAACG,KAAK,EAAEF,cAAc,IAChDD,iBAAR,IAA6BA,iBAAiB,CAACC,cAAc,CAAC,CACtC;IAEtB;IACA;IACA;IAAAF,eAAA,kBACmCK,QAAQ,IAA7C;MACI,OAAOrB,WAAW,CAACqB,QAAQ,IACvB,IAAI,CAACC,GAAG,CAACD,QAAQ,CAACD,KAAK,IACvB,OAAOC,QAAf,KAA4B,QAAQ;IAClC,CAAC;IAED;IACA;IACA;IACA;IAAAL,eAAA,sBAC0C,CAACO,YAAY,EAAEC,cAAc,KAAzE;MACI,IAAI,OAAOD,YAAf,KAAgC,QAAQ,EAAE;QACpC,OAAOnB,aAAa,CAACmB,YAAY,CAAC;MACpC;MAEA,IAAIvB,WAAW,CAACuB,YAAY,CAAC,EAAE;QAC7B,OAAOA,YAAY;MACrB;MAEA,MAAM,CAACE,EAAE,IAAI,IAAI,CAACX,QAAQ,CAACY,QAAQ,CAACH,YAAY,CAAC;MAEjD,IAAIE,EAAE,EAAE;QACN,MAAME,GAAZ,GAAkBvB,aAAa,CAACqB,EAAE,CAAC;QAC7B,IAAID,cAAc,EAAE;UAClB,IAAI,CAACI,KAAK,CAACH,EAAE,EAAEF,YAAY,CAAC;QAC9B;QACA,OAAOI,GAAG;MACZ;IACF,CAAC;IAxiBiB,IAApB,CAAAb,QAAA,GAAoBA,QAAQ;IACR,IAApB,CAAAC,KAAA,GAAoBA,KAAK;EACpB;EASH;EACA;EACA;EAEOc,QAAQA,CAAA,EAAjB;IACI,OAAAC,aAAA,KAAY,IAAI,CAACC,IAArB;EACE;EAEOT,GAAGA,CAACU,MAAc,EAA3B;IACI,OAAO,IAAI,CAACC,MAAM,CAACD,MAAM,EAAE,IAAI,MAAM,KAAK,CAAC;EAC7C;EAEOb,GAAGA,CAACa,MAAc,EAAEE,SAAiB,EAA9C;IACI,IAAI,CAACnB,KAAK,CAACoB,MAAM,CAACH,MAAM,EAAEE,SAAS,CAAC;IACpC,IAAI1B,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACL,IAAI,EAAEC,MAAM,CAAC,EAAE;MAClC,MAAMK,WAAZ,GAA0B,IAAI,CAACN,IAAI,CAACC,MAAM,CAAC;MACrC,IAAIK,WAAV,IAAyB7B,MAAM,CAAC4B,IAAI,CAACC,WAAW,EAAEH,SAAS,CAAC,EAAE;QACtD,OAAOG,WAAW,CAACH,SAAS,CAAC;MAC/B;IACF;IACA,IACEA,SADN,KACoB,YADpB,IAEM1B,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACtB,QAAQ,CAACwB,iBAAiB,EAAEN,MAAM,CAAC,EACpD;MACA,OAAO,IAAI,CAAClB,QAAQ,CAACwB,iBAAiB,CAACN,MAAM,CAAC;IAChD;IACA,IAAI,IAAR,YAAwBO,KAAK,EAAE;MACzB,OAAO,IAAI,CAACC,MAAM,CAACrB,GAAG,CAACa,MAAM,EAAEE,SAAS,CAAC;IAC3C;EACF;EAEUD,MAAMA,CACdD,MAAc,EACdS,iBAA2B,EAF/B;IAII;IACA;IACA;IACA;IACA;IACA,IAAIA,iBAAiB,EAAE,IAAI,CAAC1B,KAAK,CAACoB,MAAM,CAACH,MAAM,EAAE,UAAU,CAAC;IAE5D,IAAIxB,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACL,IAAI,EAAEC,MAAM,CAAC,EAAE;MAClC,OAAO,IAAI,CAACD,IAAI,CAACC,MAAM,CAAC;IAC1B;IAEA,IAAI,IAAR,YAAwBO,KAAK,EAAE;MACzB,OAAO,IAAI,CAACC,MAAM,CAACP,MAAM,CAACD,MAAM,EAAES,iBAAiB,CAAC;IACtD;IAEA,IAAI,IAAI,CAAC3B,QAAQ,CAACwB,iBAAiB,CAACN,MAAM,CAAC,EAAE;MAC3C,OAAO,CAAb,CAAe;IACX;EACF;EAEOJ,KAAKA,CAACc,KAA2B,EAAEC,KAA2B,EAAvE;IACI,IAAIX,MAA0B;IAE9B;IACA,IAAIhC,WAAW,CAAC0C,KAAK,CAAC,EAAEA,KAA5B,GAAoCA,KAAK,CAACtB,KAAK;IAC3C,IAAIpB,WAAW,CAAC2C,KAAK,CAAC,EAAEA,KAA5B,GAAoCA,KAAK,CAACvB,KAAK;IAE3C,MAAMwB,QAAV,GACM,OAAOF,KADb,KACuB,QADvB,GACkC,IAAI,CAACT,MAAM,CAAED,MAD/C,GACwDU,KAAM,IAAIA,KAAK;IAEnE,MAAMG,QAAV,GACM,OAAOF,KADb,KACuB,QADvB,GACkC,IAAI,CAACV,MAAM,CAAED,MAD/C,GACwDW,KAAM,IAAIA,KAAK;IAEnE;IACA;IACA,IAAI,CAACE,QAAQ,EAAE;IAEfvC,SAAJ,CAAc,OAAO0B,MAArB,KAAgC,QAAhC,KAA4E;IAExE,MAAMc,MAAV,GAAgC,IAAI5C,UAAU,CAAC;MACzC6C,UAAU,EAAEC;IAClB,CAAK,CAAC,CAACpB,KAAK,CAACgB,QAAQ,EAAEC,QAAQ,CAAC;IAE5B;IACA;IACA,IAAI,CAACd,IAAI,CAACC,MAAM,IAAIc,MAAM;IAE1B,IAAIA,MAAR,KAAmBF,QAAQ,EAAE;MACvB,OAAO,IAAI,CAACK,IAAI,CAACjB,MAAM,CAAC;MACxB,IAAI,IAAI,CAACjB,KAAK,CAACmC,OAAO,EAAE;QACtB,MAAMC,aAAd,GAAiD,CAAjD,CAAmD;QAE3C;QACA;QACA;QACA,IAAI,CAACP,QAAQ,EAAEO,aAAa,CAACC,QAArC,GAAgD,CAAC;QAEzC;QACA;QACAC,MAAM,CAACC,IAAI,CAACT,QAAQ,CAAC,CAACU,OAAO,CAAErC,cAAc,IAArD;UACU,IACE,CAAC0B,QADb,IAEYA,QAAQ,CAAC1B,cAAc,MAAM4B,MAAM,CAAC5B,cAAc,CAAC,EACnD;YACA;YACA;YACAiC,aAAa,CAACjC,cAAc,IAAI,CAAC;YAEjC;YACA;YACA;YACA;YACA;YACA;YACA;YACA,MAAMgB,SAAlB,GAA8B3B,sBAAsB,CAACW,cAAc,CAAC;YACxD,IACEgB,SADd,KAC4BhB,cAD5B,IAEc,CAAC,IAAI,CAACJ,QAAQ,CAAC0C,UAAU,CAACV,MAAM,CAACW,UAAU,EAAEvB,SAAS,CAAC,EACvD;cACAiB,aAAa,CAACjB,SAAS,IAAI,CAAC;YAC9B;YAEA;YACA;YACA;YACA,IAAIY,MAAM,CAAC5B,cAAc,MAAM,KAAK,KAAK,EAAE,IAAvD,YAAuEqB,KAAK,CAAC,EAAE;cACjE,OAAOO,MAAM,CAAC5B,cAAc,CAAC;YAC/B;UACF;QACF,CAAC,CAAC;QAEF,IACEiC,aAAa,CAACM,UADxB,IAEU,EAAEb,QAAZ,IAAwBA,QAAQ,CAACa,UAAU;QACjC;QACA;QACA;QACA;QACA,IAAI,CAAC3C,QAAQ,CAACwB,iBAAiB,CAACN,MAAM,MAAMc,MAAM,CAACW,UAAU,EAC7D;UACA,OAAON,aAAa,CAACM,UAAU;QACjC;QAEAJ,MAAM,CAACC,IAAI,CAACH,aAAa,CAAC,CAACI,OAAO,CAAErB,SAAS,IAC3C,IAAI,CAACnB,KAAK,CAAC2C,KAAK,CAAC1B,MAAgB,EAAEE,SAAS,CAAC,CAC9C;MACH;IACF;EACF;EAEOyB,MAAMA,CACX3B,MAAc,EACd4B,MAAsD,EACtDC,KAAc,EAHlB;IAKI,MAAMxB,WAAV,GAAwB,IAAI,CAACJ,MAAM,CAACD,MAAM,CAAC;IAEvC,IAAIK,WAAW,EAAE;MACf,MAAMyB,aAAZ,GAAiD,CAAjD,CAAmD;MAC7C,IAAIC,WAAV,GAAwB,KAAK;MACvB,IAAIC,UAAV,GAAuB,IAAI;MAErB,MAAMC,aAAZ,GAA4B;QACpBxD,MAAM;QACNE,UAAU;QACVX,WAAW;QACXkE,WAAW,EAAE,IAAI,CAACA,WAAW;QAC7BC,OAAO,EAAE,IAAI,CAACA,OAAO;QACrBC,SAAS,EAAEA,CACTC,kBAA6C,EAC7CC,IAA8B,KAE9B,IAAI,CAACxD,QAAQ,CAACsD,SAAS,CACrB,OAAOC,kBALnB,KAK0C,QAL1C,GAMc;UACEnC,SAAS,EAAEmC,kBAAkB;UAC7BC,IAAI,EAAEA,IAAtB,IAA8BlE,aAAa,CAAC4B,MAAM;QAClD,IACcqC,kBAAkB,EACpB;UAAEE,KAAK,EAAE;QADrB,CAC2B;MAE3B,CAA0C;MAEpClB,MAAM,CAACC,IAAI,CAACjB,WAAW,CAAC,CAACkB,OAAO,CAAErC,cAAc,IAAtD;QACQ,MAAMgB,SAAd,GAA0B3B,sBAAsB,CAACW,cAAc,CAAC;QACxD,IAAIsD,UAAZ,GAAyBnC,WAAW,CAACnB,cAAc,CAAC;QAC5C,IAAIsD,UAAZ,KAA2B,KAAK,CAAC,EAAE;QAC3B,MAAMb,MAAd,GACU,OAAOC,MADjB,KAC4B,UAD5B,GACyCA,MADzC,GAEYA,MAAM,CAAC1C,cAAc,MAAM2C,KAFvC,GAE+CY,SAF/C,GAE2Db,MAAM,CAAC1B,SAAS,CAAC,CACjE;QACH,IAAIyB,MAAM,EAAE;UACV,IAAIe,QAAd,GACYf,MADZ,KACuBjD,WADvB,GACqCD,MADrC,GAEckD,MAAM,CAACtD,eAAe,CAACmE,UAAU,CAAC,EAAA1C,aAAA,CAAAA,aAAA,KAC7BmC,aAAa;YAChB/B,SAAS;YACThB,cAAc;YACdyD,OAAO,EAAE,IAAI,CAACC,UAAU,CAAC5C,MAAM,EAAEd,cAAc;UAAC,EACjD,CACF;UACH,IAAIwD,QAAd,KAA2B/D,UAAU,EAAE;YAC3B,IAAI,CAACI,KAAK,CAAC2C,KAAK,CAAC1B,MAAM,EAAEd,cAAc,CAAC;UAC1C,OAAO;YACL,IAAIwD,QAAhB,KAA6BjE,MAAM,EAAEiE,QAArC,GAAgD,KAAK,CAAC;YAC1C,IAAIA,QAAhB,KAA6BF,UAAU,EAAE;cAC3BV,aAAa,CAAC5C,cAAc,IAAIwD,QAAQ;cACxCX,WAAd,GAA4B,IAAI;cAClBS,UAAd,GAA2BE,QAAsB;cAEnC,IAAIzE,OAAO,EAAE;gBACX,MAAM4E,cAAtB,GAAwClD,GAAc,IAAtD;kBACkB,IAAI,IAAI,CAACM,MAAM,CAACN,GAAG,CAACP,KAAK,MAAMqD,SAAS,EAAE;+BACxCnE,SAAS,CAACwE,IAA9B,MAIsBnD,GADtB,CAEqB;oBACD,OAAO,IAAI;kBACb;gBACF,CAAC;gBACD,IAAI3B,WAAW,CAAC0E,QAAQ,CAAC,EAAE;kBACzBG,cAAc,CAACH,QAAQ,CAAC;gBAC1B,OAAO,IAAIK,KAAK,CAACC,OAAO,CAACN,QAAQ,CAAC,EAAE;kBAClC;kBACA,IAAIO,aAAtB,GAA+C,KAAK;kBAClC,IAAIC,gBAAyB;kBAC7B,KAAK,MAAMC,KAA7B,IAAsCT,QAAQ,EAAE;oBAC5B,IAAI1E,WAAW,CAACmF,KAAK,CAAC,EAAE;sBACtBF,aAAtB,GAAsC,IAAI;sBACpB,IAAIJ,cAAc,CAACM,KAAK,CAAC,EAAE;oBAC7B,OAAO;sBACL;sBACA;sBACA,IAAI,OAAOA,KAAjC,KAA2C,QAA3C,IAAuD,CAAC,CAACA,KAAK,EAAE;wBACxC,MAAM,CAAC1D,EAAE,IAAI,IAAI,CAACX,QAAQ,CAACY,QAAQ,CAACyD,KAAK,CAAC;wBAC1C;wBACA,IAAI1D,EAAE,EAAE;0BACNyD,gBAA1B,GAA6CC,KAAK;wBAC1B;sBACF;oBACF;oBACA,IAAIF,aAAxB,IAAyCC,gBAAzC,KAA8DT,SAAS,EAAE;iCACnDnE,SAAS,CAACwE,IAAhC,MAGwBI,gBADxB,CAEuB;sBACD;oBACF;kBACF;gBACF;cACF;YACF;UACF;QACF;QACA,IAAIV,UAAZ,KAA2B,KAAK,CAAC,EAAE;UACzBR,UAAV,GAAuB,KAAK;QACpB;MACF,CAAC,CAAC;MAEF,IAAID,WAAW,EAAE;QACf,IAAI,CAACnC,KAAK,CAACI,MAAM,EAAE8B,aAAa,CAAC;QAEjC,IAAIE,UAAU,EAAE;UACd,IAAI,IAAd,YAA8BzB,KAAK,EAAE;YACzB,IAAI,CAACR,IAAI,CAACC,MAAM,IAAI,KAAK,CAAC;UAC5B,OAAO;YACL,OAAO,IAAI,CAACD,IAAI,CAACC,MAAM,CAAC;UAC1B;UACA,IAAI,CAACjB,KAAK,CAAC2C,KAAK,CAAC1B,MAAM,EAAE,UAAU,CAAC;QACtC;QAEA,OAAO,IAAI;MACb;IACF;IAEA,OAAO,KAAK;EACd;EAEA;EACA;EACA;EACA;EACA;EACA;EACOoD,MAAMA,CACXpD,MAAc,EACdE,SAAkB,EAClBmD,IAA0B,EAH9B;IAKI,MAAMhD,WAAV,GAAwB,IAAI,CAACJ,MAAM,CAACD,MAAM,CAAC;IACvC,IAAIK,WAAW,EAAE;MACf,MAAMiD,QAAZ,GAAuB,IAAI,CAACC,aAAa,CAASlD,WAAW,EAAE,YAAY,CAAC;MACtE,MAAMnB,cAAZ,GACQgB,SADR,IACqBmD,IADrB,GAEU,IAAI,CAACvE,QAAQ,CAAC0E,iBAAiB,CAAC;QAAEF,QAAQ;QAAEpD,SAAS;QAAEmD;MAAjE,CAAuE,IAC7DnD,SAAS;MACb,OAAO,IAAI,CAACyB,MAAM,CAChB3B,MAAM,EACNd,cAFR,GAGU;QACE,CAACA,cAAc,GAAGR;MAC9B,IACUA,WAAW,EACb,CAAC,CAAC2E,IAAI,CACP;IACH;IACA,OAAO,KAAK;EACd;EAEOI,KAAKA,CAACC,OAA2B,EAAEC,KAAkB,EAA9D;IACI,IAAIC,OAAR,GAAkB,KAAK;IACnB,IAAIF,OAAO,CAACjE,EAAE,EAAE;MACd,IAAIjB,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACL,IAAI,EAAE2D,OAAO,CAACjE,EAAE,CAAC,EAAE;QACtCmE,OAAR,GAAkB,IAAI,CAACR,MAAM,CAACM,OAAO,CAACjE,EAAE,EAAEiE,OAAO,CAACxD,SAAS,EAAEwD,OAAO,CAACL,IAAI,CAAC;MACpE;MACA,IAAI,IAAV,YAA0B9C,KAA1B,IAAmC,IAAnC,KAA4CoD,KAAK,EAAE;QAC3CC,OAAR,GAAkB,IAAI,CAACpD,MAAM,CAACiD,KAAK,CAACC,OAAO,EAAEC,KAAK,KAAKC,OAAO;MACxD;MACA;MACA;MACA;MACA;MACA,IAAIF,OAAO,CAACxD,SAAlB,IAA+B0D,OAAO,EAAE;QAChC,IAAI,CAAC7E,KAAK,CAAC2C,KAAK,CAACgC,OAAO,CAACjE,EAAE,EAAEiE,OAAO,CAACxD,SAA7C,IAA0D,UAAU,CAAC;MAC/D;IACF;IACA,OAAO0D,OAAO;EAChB;EAEOC,KAAKA,CAAA,EAAd;IACI,IAAI,CAACC,OAAO,CAAC,IAAI,CAAC;EACpB;EAEOC,OAAOA,CAAA,EAAhB;IACI,MAAMC,GAAV,GAAgB,IAAI,CAACnE,QAAQ,CAA7B,CAA+B;IAC3B,MAAMoE,YAAV,GAAmC,EAAE;IACjC,IAAI,CAACC,YAAY,CAArB,CAAuB,CAAC3C,OAAO,CAAE9B,EAAE,IAAnC;MACM,IAAI,CAACjB,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACtB,QAAQ,CAACwB,iBAAiB,EAAEb,EAAE,CAAC,EAAE;QACrDwE,YAAY,CAACE,IAAI,CAAC1E,EAAE,CAAC;MACvB;IACF,CAAC,CAAC;IACF,IAAIwE,YAAY,CAACG,MAAM,EAAE;MACvBJ,GAAG,CAACK,MAAV,GAAmB;QAAEJ,YAAY,EAAEA,YAAY,CAACK,IAAI,CAApD;MAAA,CAAwD;IACpD;IACA,OAAON,GAAG;EACZ;EAEOF,OAAOA,CAACS,OAAqC,EAAtD;IACIlD,MAAM,CAACC,IAAI,CAAC,IAAI,CAACvB,IAAI,CAAC,CAACwB,OAAO,CAAEvB,MAAM,IAA1C;MACM,IAAI,EAAEuE,OAAZ,IAAuB/F,MAAM,CAAC4B,IAAI,CAACmE,OAAO,EAAEvE,MAAM,CAAC,CAAC,EAAE;QAC9C,IAAI,CAACoD,MAAM,CAACpD,MAAM,CAAC;MACrB;IACF,CAAC,CAAC;IACF,IAAIuE,OAAO,EAAE;MACX,MAAM;UAAEF;QAAd,IAAkCE,OAAO;QAAhBC,IAAzB,GAAAC,wBAAA,CAAkCF,OAAO,EAAAG,SAAA;MACnCrD,MAAM,CAACC,IAAI,CAACkD,IAAI,CAAC,CAACjD,OAAO,CAAEvB,MAAM,IAAvC;QACQ,IAAI,CAACJ,KAAK,CAACI,MAAM,EAAEwE,IAAI,CAACxE,MAAM,CAAgB,CAAC;MACjD,CAAC,CAAC;MACF,IAAIqE,MAAM,EAAE;QACVA,MAAM,CAACJ,YAAY,CAAC1C,OAAO,CAAC,IAAI,CAACoD,MAAM,EAAE,IAAI,CAAC;MAChD;IACF;EACF;EAcOA,MAAMA,CAACC,MAAc,EAA9B;IACI,OAAQ,IAAI,CAACC,OAAO,CAACD,MAAM,IAAI,CAAC,IAAI,CAACC,OAAO,CAACD,MAAM,KAAK,CAAC,IAAI,CAAC;EAChE;EAEOE,OAAOA,CAACF,MAAc,EAA/B;IACI,IAAI,IAAI,CAACC,OAAO,CAACD,MAAM,IAAI,CAAC,EAAE;MAC5B,MAAMG,KAAZ,GAAoB,EAAE,IAAI,CAACF,OAAO,CAACD,MAAM,CAAC;MACpC,IAAI,CAACG,KAAK,EAAE,OAAO,IAAI,CAACF,OAAO,CAACD,MAAM,CAAC;MACvC,OAAOG,KAAK;IACd;IACA,OAAO,CAAC;EACV;EAEA;EACA;EACOb,YAAYA,CAAA,EAArB;IAAA,IAAsBc,GAAtB,GAAAC,SAAA,CAAAb,MAAA,QAAAa,SAAA,QAAAxC,SAAA,GAAAwC,SAAA,MAA4B,IAAIC,GAAG,CAAnC,CAA6C;IACzC7D,MAAM,CAACC,IAAI,CAAC,IAAI,CAACuD,OAAO,CAAC,CAACtD,OAAO,CAACyD,GAAG,CAACG,GAAG,EAAEH,GAAG,CAAC;IAC/C,IAAI,IAAR,YAAwBzE,KAAK,EAAE;MACzB,IAAI,CAACC,MAAM,CAAC0D,YAAY,CAACc,GAAG,CAAC;IAC/B,OAAO;MACL;MACA;MACA;MACA3D,MAAM,CAACC,IAAI,CAAC,IAAI,CAACxC,QAAQ,CAACwB,iBAAiB,CAAC,CAACiB,OAAO,CAACyD,GAAG,CAACG,GAAG,EAAEH,GAAG,CAAC;IACpE;IACA,OAAOA,GAAG;EACZ;EAEA;EACA;EACA;EACA;EACOI,EAAEA,CAAA,EAAX;IACI,MAAMJ,GAAV,GAAgB,IAAI,CAACd,YAAY,CAAjC,CAAmC;IAC/B,MAAMmB,QAAV,GAAqB,IAAI,CAACxF,QAAQ,CAAlC,CAAoC;IAChCmF,GAAG,CAACzD,OAAO,CAAE9B,EAAE,IAAnB;MACM,IAAIjB,MAAM,CAAC4B,IAAI,CAACiF,QAAQ,EAAE5F,EAAE,CAAC,EAAE;QAC7B;QACA;QACA;QACA4B,MAAM,CAACC,IAAI,CAAC,IAAI,CAACgE,eAAe,CAAC7F,EAAE,CAAC,CAAC,CAAC8B,OAAO,CAACyD,GAAG,CAACG,GAAG,EAAEH,GAAG,CAAC;QAC3D;QACA;QACA,OAAOK,QAAQ,CAAC5F,EAAE,CAAC;MACrB;IACF,CAAC,CAAC;IACF,MAAM8F,WAAV,GAAwBlE,MAAM,CAACC,IAAI,CAAC+D,QAAQ,CAAC;IACzC,IAAIE,WAAW,CAACnB,MAAM,EAAE;MACtB,IAAIoB,IAAV,GAA8B,IAAI;MAC5B,OAAOA,IAAb,YAA6BjF,KAAK,EAAEiF,IAApC,GAA2CA,IAAI,CAAChF,MAAM;MAChD+E,WAAW,CAAChE,OAAO,CAAE9B,EAAE,IAAK+F,IAAI,CAACpC,MAAM,CAAC3D,EAAE,CAAC,CAAC;IAC9C;IACA,OAAO8F,WAAW;EACpB;EAOOD,eAAeA,CAACtF,MAAc,EAAvC;IACI,IAAI,CAACxB,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACa,IAAI,EAAEjB,MAAM,CAAC,EAAE;MACnC,MAAMyF,KAAZ,GAAqB,IAAI,CAACxE,IAAI,CAACjB,MAAM,IAAI,CAAzC,CAAoE;MAC9D,MAAMwF,IAAZ,GAAmB,IAAI,CAACzF,IAAI,CAACC,MAAM,CAAC;MAC9B,IAAI,CAACwF,IAAI,EAAE,OAAOC,KAAK;MAEvB,MAAMC,OAAZ,GAAsB,IAAIR,GAAG,CAA+B,CAACM,IAAI,CAAC,CAAC;MAC7D;MACA;MACAE,OAAO,CAACnE,OAAO,CAAEyC,GAAG,IAA1B;QACQ,IAAIhG,WAAW,CAACgG,GAAG,CAAC,EAAE;UACpByB,KAAK,CAACzB,GAAG,CAAC5E,KAAK,IAAI,IAAI;UACvB;UACA;UACA;UACA;UACA;UACA;UACA;QACF;QACA,IAAIjB,eAAe,CAAC6F,GAAG,CAAC,EAAE;UACxB3C,MAAM,CAACC,IAAI,CAAC0C,GAAG,CAAC,CAACzC,OAAO,CAAEoE,GAAG,IAAvC;YACY,MAAMC,KAAlB,GAA0B5B,GAAG,CAAC2B,GAAG,CAAC;YACtB;YACA;YACA,IAAIxH,eAAe,CAACyH,KAAK,CAAC,EAAE;cAC1BF,OAAO,CAACP,GAAG,CAACS,KAAK,CAAC;YACpB;UACF,CAAC,CAAC;QACJ;MACF,CAAC,CAAC;IACJ;IACA,OAAO,IAAI,CAAC3E,IAAI,CAACjB,MAAM,CAAC;EAC1B;EA0BO6F,YAAYA,CAAA,EAArB;IACI,OAAO,IAAI,CAAC9G,KAAK,CAAC+G,QAAQ,CAACC,WAAW,CAACd,SAAS,CAAC;EACnD;EA+CA,IAAWe,qBAAqBA,CAAA,EAAlC;IACI,OAAO,IAAI,CAACjH,KAAK,CAACmC,OAAO;EAC3B;AACF;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM+E,UAAN;EAOEpH,WAAFA,CACoBqC,OAAgB,EADpC;IAAA,IAEYV,MAFZ,GAAAyE,SAAA,CAAAb,MAAA,QAAAa,SAAA,QAAAxC,SAAA,GAAAwC,SAAA,MAEwC,IAAI;IAAAjG,eAAA;IAAAA,eAAA;IAAAA,eAAA,YARe,IAAI;IAE7D;IACA;IAAAA,eAAA;IAIkB,IAApB,CAAAkC,OAAA,GAAoBA,OAAO;IACf,IAAZ,CAAAV,MAAA,GAAYA,MAAM;IAEd,IAAI,CAAC0F,YAAY,CAArB,CAAuB;EACrB;EAEOA,YAAYA,CAAA,EAArB;IACI,IAAI,CAACC,CAAA,GAAI,IAAI,CAACjF,OAAlB,GAA4BnD,GAAG,CAA/B,IAA4C,IAAI;IAC5C,IAAI,CAAC+H,QAAT,GAAoB,IAAIhI,IAAI,CAA5B,CAA8B;EAC5B;EAEOqC,MAAMA,CAACH,MAAc,EAAEd,cAAsB,EAAtD;IACI,IAAI,IAAI,CAACiH,CAAC,EAAE;MACV,IAAI,CAACA,CAAC,CAACC,UAAU,CAACpG,MAAM,EAAEd,cAAc,CAAC,CAAC;MAC1C,MAAMgB,SAAZ,GAAwB3B,sBAAsB,CAACW,cAAc,CAAC;MACxD,IAAIgB,SAAV,KAAwBhB,cAAc,EAAE;QAChC;QACA;QACA;QACA;QACA;QACA,IAAI,CAACiH,CAAC,CAACC,UAAU,CAACpG,MAAM,EAAEE,SAAS,CAAC,CAAC;MACvC;MACA,IAAI,IAAI,CAACM,MAAM,EAAE;QACf,IAAI,CAACA,MAAM,CAACL,MAAM,CAACH,MAAM,EAAEd,cAAc,CAAC;MAC5C;IACF;EACF;EAEOwC,KAAKA,CAAC1B,MAAc,EAAEd,cAAsB,EAArD;IACI,IAAI,IAAI,CAACiH,CAAC,EAAE;MACV,IAAI,CAACA,CAAC,CAACzE,KAAK,CACV0E,UAAU,CAACpG,MAAM,EAAEd,cAAc,CAAC;MAClC;MACA;MACA;MACA;MACA;MACA;MACA;MACAA,cAAR,KAA2B,UAA3B,GAAwC,QAAxC,GAAmD,UAAU,CACtD;IACH;EACF;AACF;AAEA,SAASkH,UAAUA,CAACpG,MAAc,EAAEd,cAAsB,EAA1D;EACE;EACA;EACA;EACA,OAAOA,cAAT,GAA0B,GAA1B,GAAgCc,MAAM;AACtC;AAEA,gBAAgBqG,8BAA8BA,CAC5C9D,KAAsB,EACtB+D,QAAgB,EAFlB;EAIE,IAAIN,qBAAqB,CAACzD,KAAK,CAAC,EAAE;IAChC;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACAA,KAAK,CAACxD,KAAK,CAACoB,MAAM,CAACmG,QAAQ,EAAE,UAAU,CAAC;EAC1C;AACF;AAEA,MAAMC,IAAN,SAAmB3H,WAAnB;EACEC,WAAFA,CAAA2H,IAAA;IAAA,IAAc;MACV1H,QAAQ;MACR2H,aAFJ,GAEoB,IAAI;MACpBC;IAHJ,CAQG,GAAAF,IAAA;IACC,KAAK,CAAC1H,QAAQ,EAAE,IAAImH,UAAU,CAACQ,aAAa,CAAC,CAAC;IAAAzH,eAAA,gBAIxB,IAAI2H,KAAK,CAAC,IAAI,CAAC;IAAA3H,eAAA,sBAcT,IAAIlB,IAAI,CAAxC,CAAuD;IAjBnD,IAAI4I,IAAI,EAAE,IAAI,CAAC5C,OAAO,CAAC4C,IAAI,CAAC;EAC9B;EAIOE,QAAQA,CAACC,OAAe,EAAEC,MAAmC,EAAtE;IACI;IACA;IACA;IACA,OAAO,IAAI,CAACC,KAAK,CAACH,QAAQ,CAACC,OAAO,EAAEC,MAAM,CAAC;EAC7C;EAEOE,WAAWA,CAAA,EAApB;IACI;IACA,OAAO,IAAI;EACb;EAGOpE,UAAUA,CAAA,EAAnB;IACI,OAAO,IAAI,CAACqE,WAAW,CAAClB,WAAW,CAACd,SAAS,CAAC;EAChD;AACF;AACArG,WAAW,CAAC2H,IAAZ,GAAmBA,IAAI;AAEvB;AACA;AACA,MAAMhG,KAAN,SAAoB3B,WAApB;EACEC,WAAFA,CACoBY,EAAU,EACVe,MAAmB,EACnBsG,MAAmC,EACnC/H,KAAiB,EAJrC;IAMI,KAAK,CAACyB,MAAM,CAAC1B,QAAQ,EAAEC,KAAK,CAAC;IAAAC,eAAA;IAAAA,eAAA;IAAAA,eAAA;IAAAA,eAAA;IALb,IAApB,CAAAS,EAAA,GAAoBA,EAAE;IACF,IAApB,CAAAe,MAAA,GAAoBA,MAAM;IACN,IAApB,CAAAsG,MAAA,GAAoBA,MAAM;IACN,IAApB,CAAA/H,KAAA,GAAoBA,KAAK;IAGrB+H,MAAM,CAAC,IAAI,CAAC;EACd;EAEOF,QAAQA,CAACC,OAAe,EAAEC,MAAmC,EAAtE;IACI,OAAO,IAAIvG,KAAK,CAACsG,OAAO,EAAE,IAAI,EAAEC,MAAM,EAAE,IAAI,CAAC/H,KAAK,CAAC;EACrD;EAEOiI,WAAWA,CAACH,OAAe,EAApC;IACI;IACA,MAAMrG,MAAV,GAAmB,IAAI,CAACA,MAAM,CAACwG,WAAW,CAACH,OAAO,CAAC;IAE/C,IAAIA,OAAR,KAAoB,IAAI,CAACpH,EAAE,EAAE;MACvB,IAAI,IAAI,CAACV,KAAK,CAACmC,OAAO,EAAE;QACtB;QACA;QACA;QACA;QACAG,MAAM,CAACC,IAAI,CAAC,IAAI,CAACvB,IAAI,CAAC,CAACwB,OAAO,CAAEvB,MAAM,IAA9C;UACU,MAAMkH,cAAhB,GAAiC,IAAI,CAACnH,IAAI,CAACC,MAAM,CAAC;UACxC,MAAMmH,iBAAhB,GAAoC3G,MAAM,CAAC,QAAQ,CAAC,CAACR,MAAM,CAAC;UAClD,IAAI,CAACmH,iBAAiB,EAAE;YACtB;YACA;YACA;YACA;YACA;YACA,IAAI,CAAC/D,MAAM,CAACpD,MAAM,CAAC;UACrB,OAAO,IAAI,CAACkH,cAAc,EAAE;YAC1B;YACA;YACA;YACA;YACA,IAAI,CAACnI,KAAK,CAAC2C,KAAK,CAAC1B,MAAM,EAAE,UAAU,CAAC;YACpCqB,MAAM,CAACC,IAAI,CAAC6F,iBAAiB,CAAC,CAAC5F,OAAO,CAAErC,cAAc,IAAlE;cACc,IAAI,CAACH,KAAK,CAAC2C,KAAK,CAAC1B,MAAM,EAAEd,cAAc,CAAC;YAC1C,CAAC,CAAC;UACJ,OAAO,IAAIgI,cAArB,KAAwCC,iBAAiB,EAAE;YAC/C;YACA;YACA;YACA9F,MAAM,CAACC,IAAI,CAAC4F,cAAc,CAAC,CAAC3F,OAAO,CAAErC,cAAc,IAA/D;cACc,IACE,CAACrB,KAAK,CACJqJ,cAAc,CAAChI,cAAc,CAAC,EAC9BiI,iBAAiB,CAACjI,cAAc,CAAC,CAClC,EACD;gBACA,IAAI,CAACH,KAAK,CAAC2C,KAAK,CAAC1B,MAAM,EAAEd,cAAc,CAAC;cAC1C;YACF,CAAC,CAAC;UACJ;QACF,CAAC,CAAC;MACJ;MAEA,OAAOsB,MAAM;IACf;IAEA;IACA,IAAIA,MAAR,KAAmB,IAAI,CAACA,MAAM,EAAE,OAAO,IAAI;IAEvC;IACA,OAAOA,MAAM,CAACoG,QAAQ,CAAC,IAAI,CAACnH,EAAE,EAAE,IAAI,CAACqH,MAAM,CAAC;EAC9C;EAEOjH,QAAQA,CAAA,EAAjB;IACI,OAAAC,aAAA,CAAAA,aAAA,KACK,IAAI,CAACU,MAAM,CAACX,QAAQ,CAA7B,CAA+B,GACtB,IAAI,CAACE,IAAI;EAEhB;EAEOuF,eAAeA,CAACtF,MAAc,EAAvC;IACI,MAAMoH,UAAV,GAAuB,IAAI,CAAC5G,MAAM,CAAC8E,eAAe,CAACtF,MAAM,CAAC;IACtD,OAAOxB,MAAM,CAAC4B,IAAI,CAAC,IAAI,CAACL,IAAI,EAAEC,MAAM,IAAAF,aAAA,CAAAA,aAAA,KAE3BsH,UAAU,GACV,KAAK,CAAC9B,eAAe,CAACtF,MAAM,CAAC,IAElCoH,UAAU;EAChB;EAEOxE,UAAUA,CAAA,EAAnB;IAGI,IAAIyE,CAAA,GAAiB,IAAI,CAAC7G,MAAM;IAChC,OAAQ6G,CAAW,CAAC7G,MAAM,EAAE6G,CAAA,GAAKA,CAAW,CAAC7G,MAAM;IACnD,OAAO6G,CAAC,CAACzE,UAAU,CAAC,GAAAqC,SAAO,CAAC;EAC9B;AACF;AAEA;AACA;AACA;AACA;AACA,MAAM0B,KAAN,SAAoBpG,KAApB;EACE1B,WAAFA,CAAc2G,IAAU,EAAxB;IACI,KAAK,CACH,mBAAmB,EACnBA,IAAI,EACJ,MAHN,CAGa,CAAC,EACR,IAAIS,UAAU,CAACT,IAAI,CAACzG,KAAK,CAACmC,OAAO,EAAEsE,IAAI,CAACzG,KAAK,CAAC,CAC/C;EACH;EAEOiI,WAAWA,CAAA,EAApB;IACI;IACA,OAAO,IAAI;EACb;EAEOpH,KAAKA,CAACc,KAA2B,EAAEC,KAA2B,EAAvE;IACI;IACA;IACA;IACA;IACA;IACA,OAAO,IAAI,CAACH,MAAM,CAACZ,KAAK,CAACc,KAAK,EAAEC,KAAK,CAAC;EACxC;AACF;AAEA,SAASK,qBAAqBA,CAC5BsG,cAA2B,EAC3BC,cAA2B,EAC3BC,QAAyB,EAH3B;EAKE,MAAMC,aAAR,GAAwBH,cAAc,CAACE,QAAQ,CAAC;EAC9C,MAAME,aAAR,GAAwBH,cAAc,CAACC,QAAQ,CAAC;EAC9C;EACA;EACA;EACA;EACA;EACA,OAAO3J,KAAK,CAAC4J,aAAa,EAAEC,aAAa,IAAID,aAA/C,GAA+DC,aAAa;AAC5E;AAEA,gBAAgB1B,qBAAqBA,CAACzD,KAAU,EAAhD;EACE;EACA,OAAO,CAAC,EAAEA,KAAZ,IAAqBA,KAAK,CAACyD,qBAAqB,CAAC;AACjD","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}