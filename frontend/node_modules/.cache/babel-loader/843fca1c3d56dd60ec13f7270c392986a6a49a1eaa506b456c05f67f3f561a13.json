{"ast":null,"code":"import _defineProperty from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport _objectSpread from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\nimport { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport { Kind } from \"graphql\";\nimport { addTypenameToDocument, canonicalStringify, isReference } from \"@apollo/client/utilities\";\nimport { __DEV__ } from \"@apollo/client/utilities/environment\";\nimport { argumentsObjectFromField, cloneDeep, getDefaultValues, getFragmentFromSelection, getOperationDefinition, hasDirectives, isArray, isField, isNonEmptyArray, makeReference, resultKeyNameFromField, shouldInclude, streamInfoSymbol } from \"@apollo/client/utilities/internal\";\nimport { invariant, newInvariantError } from \"@apollo/client/utilities/invariant\";\nimport { extractFragmentContext, fieldNameFromStoreName, makeProcessedFieldsMerger, storeValueIsStoreObject } from \"./helpers.js\";\nimport { defaultStreamFieldMergeFn, normalizeReadFieldOptions } from \"./policies.js\";\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor(context, clientOnly, deferred) {\n  const key = \"\".concat(clientOnly).concat(deferred);\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(key, flavored = context.clientOnly === clientOnly && context.deferred === deferred ? context : _objectSpread(_objectSpread({}, context), {}, {\n      clientOnly,\n      deferred\n    }));\n  }\n  return flavored;\n}\nexport class StoreWriter {\n  constructor(cache, reader, fragments) {\n    _defineProperty(this, \"cache\", void 0);\n    _defineProperty(this, \"reader\", void 0);\n    _defineProperty(this, \"fragments\", void 0);\n    this.cache = cache;\n    this.reader = reader;\n    this.fragments = fragments;\n  }\n  writeToStore(store, _ref) {\n    let {\n      query,\n      result,\n      dataId,\n      variables,\n      overwrite,\n      extensions\n    } = _ref;\n    const operationDefinition = getOperationDefinition(query);\n    const merger = makeProcessedFieldsMerger();\n    variables = _objectSpread(_objectSpread({}, getDefaultValues(operationDefinition)), variables);\n    const context = _objectSpread(_objectSpread({\n      store,\n      written: {},\n      merge(existing, incoming) {\n        return merger.merge(existing, incoming);\n      },\n      variables: variables,\n      varString: canonicalStringify(variables)\n    }, extractFragmentContext(query, this.fragments)), {}, {\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map(),\n      extensions\n    });\n    const ref = this.processSelectionSet({\n      result: result || {},\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context,\n      path: []\n    });\n    if (!isReference(ref)) {\n      throw newInvariantError(109, result);\n    }\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach((_ref2, dataId) => {\n      let {\n        storeObject,\n        mergeTree,\n        fieldNodeSet\n      } = _ref2;\n      const entityRef = makeReference(dataId);\n      if (mergeTree && mergeTree.map.size) {\n        const applied = this.applyMerges(mergeTree, entityRef, storeObject, context);\n        if (isReference(applied)) {\n          // Assume References returned by applyMerges have already been merged\n          // into the store. See makeMergeObjectsFunction in policies.ts for an\n          // example of how this can happen.\n          return;\n        }\n        // Otherwise, applyMerges returned a StoreObject, whose fields we should\n        // merge into the store (see store.merge statement below).\n        storeObject = applied;\n      }\n      if (__DEV__ && !context.overwrite) {\n        const fieldsWithSelectionSets = {};\n        fieldNodeSet.forEach(field => {\n          if (field.selectionSet) {\n            fieldsWithSelectionSets[field.name.value] = true;\n          }\n        });\n        const hasSelectionSet = storeFieldName => fieldsWithSelectionSets[fieldNameFromStoreName(storeFieldName)] === true;\n        const hasMergeFunction = storeFieldName => {\n          const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n        Object.keys(storeObject).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) && !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(entityRef, storeObject, storeFieldName, context.store);\n          }\n        });\n      }\n      store.merge(dataId, storeObject);\n    });\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n    return ref;\n  }\n  processSelectionSet(_ref3) {\n    let {\n      dataId,\n      result,\n      selectionSet,\n      context,\n      // This object allows processSelectionSet to report useful information\n      // to its callers without explicitly returning that information.\n      mergeTree,\n      path: currentPath\n    } = _ref3;\n    const {\n      policies\n    } = this.cache;\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming = {};\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField = function () {\n      for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n        args[_key] = arguments[_key];\n      }\n      const options = normalizeReadFieldOptions(args, incoming, context.variables);\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField(_objectSpread(_objectSpread({}, options), {}, {\n            from: info.storeObject\n          }), context);\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n      return policies.readField(options, context);\n    };\n    const fieldNodeSet = new Set();\n    this.flattenFields(selectionSet, result,\n    // This WriteContext will be the default context value for fields returned\n    // by the flattenFields method, but some fields may be assigned a modified\n    // context, depending on the presence of @client and other directives.\n    context, typename).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n      const path = [...currentPath, field.name.value];\n      fieldNodeSet.add(field);\n      if (value !== void 0) {\n        var _context$extensions;\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables\n        });\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n        let incomingValue = this.processFieldValue(value, field,\n        // Reset context.clientOnly and context.deferred to their default\n        // values before processing nested selection sets.\n        field.selectionSet ? getContextFlavor(context, false, false) : context, childTree, path);\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename;\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (field.selectionSet && (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))) {\n          childTypename = readField(\"__typename\", incomingValue);\n        }\n        const merge = policies.getMergeFunction(typename, field.name.value, childTypename);\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n            path\n          };\n        } else if (hasDirectives([\"stream\"], field) && Array.isArray(incomingValue) && (_context$extensions = context.extensions) !== null && _context$extensions !== void 0 && _context$extensions[streamInfoSymbol]) {\n          childTree.info = {\n            field,\n            typename,\n            merge: defaultStreamFieldMergeFn,\n            path\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue\n        });\n      } else if (__DEV__ && !context.clientOnly && !context.deferred && !addTypenameToDocument.added(field) &&\n      // If the field has a read function, it may be a synthetic field or\n      // provide a default value, so its absence from the written data should\n      // not be cause for alarm.\n      !policies.getReadFunction(typename, field.name.value)) {\n        invariant.error(110, resultKeyNameFromField(field), result);\n      }\n    });\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField\n      });\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(result, dataRef, selectionSet, context)) {\n        return dataRef;\n      }\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach(field => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet\n        });\n      }\n      return dataRef;\n    }\n    return incoming;\n  }\n  processFieldValue(value, field, context, mergeTree, path) {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i), [...path, i]);\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n      path\n    });\n  }\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  flattenFields(selectionSet, result, context) {\n    let typename = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : getTypenameFromResult(result, selectionSet, context.fragmentMap);\n    const fieldMap = new Map();\n    const {\n      policies\n    } = this.cache;\n    const limitingTrie = new Trie(false); // No need for WeakMap, since limitingTrie does not escape.\n    (function flatten(selectionSet, inheritedContext) {\n      const visitedNode = limitingTrie.lookup(selectionSet,\n      // Because we take inheritedClientOnly and inheritedDeferred into\n      // consideration here (in addition to selectionSet), it's possible for\n      // the same selection set to be flattened more than once, if it appears\n      // in the query with different @client and/or @directive configurations.\n      inheritedContext.clientOnly, inheritedContext.deferred);\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n      selectionSet.selections.forEach(selection => {\n        if (!shouldInclude(selection, context.variables)) return;\n        let {\n          clientOnly,\n          deferred\n        } = inheritedContext;\n        if (\n        // Since the presence of @client or @defer on this field can only\n        // cause clientOnly or deferred to become true, we can skip the\n        // forEach loop if both clientOnly and deferred are already true.\n        !(clientOnly && deferred) && isNonEmptyArray(selection.directives)) {\n          selection.directives.forEach(dir => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || args.if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n          fieldMap.set(selection, getContextFlavor(context, clientOnly, deferred));\n        } else {\n          const fragment = getFragmentFromSelection(selection, context.lookupFragment);\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(111, selection.name.value);\n          }\n          if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n            flatten(fragment.selectionSet, getContextFlavor(context, clientOnly, deferred));\n          }\n        }\n      });\n    })(selectionSet, context);\n    return fieldMap;\n  }\n  applyMerges(mergeTree, existing, incoming, context, getStorageArgs) {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e =\n      // Items in the same position in different arrays are not\n      // necessarily related to each other, so when incoming is an array\n      // we process its elements as if there was no existing data.\n      !isArray(incoming) && (\n      // Likewise, existing must be either a Reference or a StoreObject\n      // in order for its fields to be safe to merge with the fields of\n      // the incoming object.\n      isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0;\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming;\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields;\n      const getValue = (from, name) => {\n        return isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map();\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = isArray(i) ? i.slice(0) : _objectSpread({}, i);\n        changedFields.forEach((value, name) => {\n          incoming[name] = value;\n        });\n      }\n    }\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && context.store.getStorage(...getStorageArgs));\n    }\n    return incoming;\n  }\n}\nconst emptyMergeTreePool = [];\nfunction getChildMergeTree(_ref4, name) {\n  let {\n    map\n  } = _ref4;\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n  return map.get(name);\n}\nfunction mergeMergeTrees(left, right) {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n  const info = left.info && right.info ? _objectSpread(_objectSpread({}, left.info), right.info) : left.info || right.info;\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map = needToMergeMaps ? new Map() : left.map.size ? left.map : right.map;\n  const merged = {\n    info,\n    map\n  };\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys.delete(key);\n    });\n    remainingRightKeys.forEach(key => {\n      merged.map.set(key, mergeMergeTrees(right.map.get(key), left.map.get(key)));\n    });\n  }\n  return merged;\n}\nfunction mergeTreeIsEmpty(tree) {\n  return !tree || !(tree.info || tree.map.size);\n}\nfunction maybeRecycleChildMergeTree(_ref5, name) {\n  let {\n    map\n  } = _ref5;\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\nconst warnings = new Set();\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  const getChild = objOrRef => {\n    const child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n  const existing = getChild(existingRef);\n  if (!existing) return;\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n  const parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = \"\".concat(parentType, \".\").concat(fieldName);\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  const childTypenames = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n  __DEV__ && invariant.warn(112, fieldName, parentType, childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\", typeDotName, Array.isArray(existing) ? [...existing] : _objectSpread({}, existing), Array.isArray(incoming) ? [...incoming] : _objectSpread({}, incoming));\n}\nfunction getTypenameFromResult(result, selectionSet, fragmentMap) {\n  let fragments;\n  for (const selection of selectionSet.selections) {\n    if (isField(selection)) {\n      if (selection.name.value === \"__typename\") {\n        return result[resultKeyNameFromField(selection)];\n      }\n    } else if (fragments) {\n      fragments.push(selection);\n    } else {\n      fragments = [selection];\n    }\n  }\n  if (typeof result.__typename === \"string\") {\n    return result.__typename;\n  }\n  if (fragments) {\n    for (const selection of fragments) {\n      const typename = getTypenameFromResult(result, getFragmentFromSelection(selection, fragmentMap).selectionSet, fragmentMap);\n      if (typeof typename === \"string\") {\n        return typename;\n      }\n    }\n  }\n}","map":{"version":3,"names":["equal","Trie","Kind","addTypenameToDocument","canonicalStringify","isReference","__DEV__","argumentsObjectFromField","cloneDeep","getDefaultValues","getFragmentFromSelection","getOperationDefinition","hasDirectives","isArray","isField","isNonEmptyArray","makeReference","resultKeyNameFromField","shouldInclude","streamInfoSymbol","invariant","newInvariantError","extractFragmentContext","fieldNameFromStoreName","makeProcessedFieldsMerger","storeValueIsStoreObject","defaultStreamFieldMergeFn","normalizeReadFieldOptions","getContextFlavor","context","clientOnly","deferred","key","concat","flavored","flavors","get","set","_objectSpread","StoreWriter","constructor","cache","reader","fragments","_defineProperty","writeToStore","store","_ref","query","result","dataId","variables","overwrite","extensions","operationDefinition","merger","written","merge","existing","incoming","varString","incomingById","Map","ref","processSelectionSet","selectionSet","mergeTree","map","path","forEach","_ref2","storeObject","fieldNodeSet","entityRef","size","applied","applyMerges","fieldsWithSelectionSets","field","name","value","hasSelectionSet","storeFieldName","hasMergeFunction","childTree","Boolean","info","Object","keys","warnAboutDataLoss","retain","__ref","_ref3","currentPath","policies","typename","rootTypenamesById","getTypenameFromResult","fragmentMap","__typename","readField","_len","arguments","length","args","Array","_key","options","from","Set","flattenFields","resultFieldKey","add","_context$extensions","getStoreFieldName","fieldName","getChildMergeTree","incomingValue","processFieldValue","childTypename","getMergeFunction","maybeRecycleChildMergeTree","added","getReadFunction","error","id","keyObject","identify","e","dataRef","sets","indexOf","push","isFresh","previous","mergeMergeTrees","mergeTreeIsEmpty","item","i","undefined","fieldMap","limitingTrie","flatten","inheritedContext","visitedNode","lookup","visited","selections","selection","directives","dir","if","fragment","lookupFragment","kind","FRAGMENT_SPREAD","fragmentMatches","getStorageArgs","changedFields","getValue","getFieldValue","String","eVal","iVal","aVal","pop","slice","runMergeFunction","getStorage","emptyMergeTreePool","_ref4","has","left","right","needToMergeMaps","merged","remainingRightKeys","leftTree","delete","tree","_ref5","warnings","existingRef","incomingObj","getChild","objOrRef","child","every","parentType","typeDotName","childTypenames","includes","warn","join"],"sources":["/home/zobair-qauomi/todo_app/node_modules/@apollo/src/cache/inmemory/writeToStore.ts"],"sourcesContent":["import { equal } from \"@wry/equality\";\nimport { Trie } from \"@wry/trie\";\nimport type {\n  FieldNode,\n  FragmentSpreadNode,\n  InlineFragmentNode,\n  SelectionSetNode,\n} from \"graphql\";\nimport { Kind } from \"graphql\";\n\nimport type { Cache, OperationVariables } from \"@apollo/client\";\nimport type {\n  Reference,\n  StoreObject,\n  StoreValue,\n} from \"@apollo/client/utilities\";\nimport {\n  addTypenameToDocument,\n  canonicalStringify,\n  isReference,\n} from \"@apollo/client/utilities\";\nimport { __DEV__ } from \"@apollo/client/utilities/environment\";\nimport type {\n  FragmentMap,\n  FragmentMapFunction,\n} from \"@apollo/client/utilities/internal\";\nimport {\n  argumentsObjectFromField,\n  cloneDeep,\n  getDefaultValues,\n  getFragmentFromSelection,\n  getOperationDefinition,\n  hasDirectives,\n  isArray,\n  isField,\n  isNonEmptyArray,\n  makeReference,\n  resultKeyNameFromField,\n  shouldInclude,\n  streamInfoSymbol,\n} from \"@apollo/client/utilities/internal\";\nimport {\n  invariant,\n  newInvariantError,\n} from \"@apollo/client/utilities/invariant\";\n\nimport type { ReadFieldFunction } from \"../core/types/common.js\";\n\nimport type { EntityStore } from \"./entityStore.js\";\nimport {\n  extractFragmentContext,\n  fieldNameFromStoreName,\n  makeProcessedFieldsMerger,\n  storeValueIsStoreObject,\n} from \"./helpers.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport {\n  defaultStreamFieldMergeFn,\n  normalizeReadFieldOptions,\n} from \"./policies.js\";\nimport type { StoreReader } from \"./readFromStore.js\";\nimport type {\n  InMemoryCacheConfig,\n  MergeTree,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<\n    string,\n    {\n      storeObject: StoreObject;\n      mergeTree?: MergeTree;\n      fieldNodeSet: Set<FieldNode>;\n    }\n  >;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n}\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  \"clientOnly\" | \"deferred\" | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"]\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(\n      key,\n      (flavored =\n        context.clientOnly === clientOnly && context.deferred === deferred ?\n          context\n        : {\n            ...context,\n            clientOnly,\n            deferred,\n          })\n    );\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string;\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n  path: Array<string | number>;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n    private fragments?: InMemoryCacheConfig[\"fragments\"]\n  ) {}\n\n  public writeToStore<\n    TData = unknown,\n    TVariables extends OperationVariables = OperationVariables,\n  >(\n    store: NormalizedCache,\n    {\n      query,\n      result,\n      dataId,\n      variables,\n      overwrite,\n      extensions,\n    }: Cache.WriteOptions<TData, TVariables>\n  ): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: {},\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables: variables as OperationVariables,\n      varString: canonicalStringify(variables),\n      ...extractFragmentContext(query, this.fragments),\n      overwrite: !!overwrite,\n      incomingById: new Map(),\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map(),\n      extensions,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || {},\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map() },\n      context,\n      path: [],\n    });\n\n    if (!isReference(ref)) {\n      throw newInvariantError(`Could not identify object %s`, result);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(\n      ({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n        const entityRef = makeReference(dataId);\n\n        if (mergeTree && mergeTree.map.size) {\n          const applied = this.applyMerges(\n            mergeTree,\n            entityRef,\n            storeObject,\n            context\n          );\n          if (isReference(applied)) {\n            // Assume References returned by applyMerges have already been merged\n            // into the store. See makeMergeObjectsFunction in policies.ts for an\n            // example of how this can happen.\n            return;\n          }\n          // Otherwise, applyMerges returned a StoreObject, whose fields we should\n          // merge into the store (see store.merge statement below).\n          storeObject = applied;\n        }\n\n        if (__DEV__ && !context.overwrite) {\n          const fieldsWithSelectionSets: Record<string, true> = {};\n          fieldNodeSet.forEach((field) => {\n            if (field.selectionSet) {\n              fieldsWithSelectionSets[field.name.value] = true;\n            }\n          });\n\n          const hasSelectionSet = (storeFieldName: string) =>\n            fieldsWithSelectionSets[fieldNameFromStoreName(storeFieldName)] ===\n            true;\n\n          const hasMergeFunction = (storeFieldName: string) => {\n            const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n            return Boolean(childTree && childTree.info && childTree.info.merge);\n          };\n\n          Object.keys(storeObject).forEach((storeFieldName) => {\n            // If a merge function was defined for this field, trust that it\n            // did the right thing about (not) clobbering data. If the field\n            // has no selection set, it's a scalar field, so it doesn't need\n            // a merge function (even if it's an object, like JSON data).\n            if (\n              hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)\n            ) {\n              warnAboutDataLoss(\n                entityRef,\n                storeObject,\n                storeFieldName,\n                context.store\n              );\n            }\n          });\n        }\n\n        store.merge(dataId, storeObject);\n      }\n    );\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n    path: currentPath,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = {};\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && (context.store.get(dataId, \"__typename\") as string));\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = (...args) => {\n      const options = normalizeReadFieldOptions(\n        args,\n        incoming,\n        context.variables\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField(\n            {\n              ...options,\n              from: info.storeObject,\n            },\n            context\n          );\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n      const path = [...currentPath, field.name.value];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet ?\n            getContextFlavor(context, false, false)\n          : context,\n          childTree,\n          path\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (\n          field.selectionSet &&\n          (isReference(incomingValue) || storeValueIsStoreObject(incomingValue))\n        ) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n            path,\n          };\n        } else if (\n          hasDirectives([\"stream\"], field) &&\n          Array.isArray(incomingValue) &&\n          context.extensions?.[streamInfoSymbol]\n        ) {\n          childTree.info = {\n            field,\n            typename,\n            merge: defaultStreamFieldMergeFn,\n            path,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(\n          `Missing field '%s' while writing result %o`,\n          resultKeyNameFromField(field),\n          result\n        );\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (\n        this.reader &&\n        this.reader.isFresh(result, dataRef, selectionSet, context)\n      ) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach((field) => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n    path: Array<string | number>\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item,\n          field,\n          context,\n          getChildMergeTree(mergeTree, i),\n          [...path, i]\n        );\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n      path,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<\n    TContext extends Pick<\n      WriteContext,\n      | \"clientOnly\"\n      | \"deferred\"\n      | \"flavors\"\n      | \"fragmentMap\"\n      | \"lookupFragment\"\n      | \"variables\"\n    >,\n  >(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap)\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach((selection) => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach((dir) => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred)\n          );\n        } else {\n          const fragment = getFragmentFromSelection(\n            selection,\n            context.lookupFragment\n          );\n\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(\n              `No fragment named %s`,\n              selection.name.value\n            );\n          }\n\n          if (\n            fragment &&\n            policies.fragmentMatches(\n              fragment,\n              typename,\n              result,\n              context.variables\n            )\n          ) {\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred)\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined =\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        (\n          !isArray(incoming) &&\n          // Likewise, existing must be either a Reference or a StoreObject\n          // in order for its fields to be safe to merge with the fields of\n          // the incoming object.\n          (isReference(existing) || storeValueIsStoreObject(existing))\n        ) ?\n          existing\n        : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number\n      ): StoreValue => {\n        return (\n          isArray(from) ?\n            typeof name === \"number\" ?\n              from[name]\n            : void 0\n          : context.store.getFieldValue(from, String(name))\n        );\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map();\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs)\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map() });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info =\n    left.info && right.info ?\n      {\n        ...left.info,\n        ...right.info,\n      }\n    : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map =\n    needToMergeMaps ? new Map()\n    : left.map.size ? left.map\n    : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(key, mergeMergeTrees(leftTree, right.map.get(key)));\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach((key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(right.map.get(key), left.map.get(key))\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree({ map }: MergeTree, name: string | number) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (\n    Object.keys(existing).every(\n      (key) => store.getFieldValue(incoming, key) !== void 0\n    )\n  ) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) && !isArray(incoming)) {\n    [existing, incoming].forEach((child) => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n    `Cache data may be lost when replacing the %s field of a %s object.\n\nThis could cause additional (usually avoidable) network requests to fetch data that were otherwise cached.\n\nTo address this problem (which is not a bug in Apollo Client), %sdefine a custom merge function for the %s field, so InMemoryCache can safely merge these objects:\n\n  existing: %o\n  incoming: %o\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`,\n    fieldName,\n    parentType,\n    childTypenames.length ?\n      \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") +\n        \" have an ID or a custom merge function, or \"\n    : \"\",\n    typeDotName,\n    Array.isArray(existing) ? [...existing] : { ...existing },\n    Array.isArray(incoming) ? [...incoming] : { ...incoming }\n  );\n}\n\nfunction getTypenameFromResult(\n  result: Record<string, any>,\n  selectionSet: SelectionSetNode,\n  fragmentMap?: FragmentMap\n): string | undefined {\n  let fragments: undefined | Array<InlineFragmentNode | FragmentSpreadNode>;\n  for (const selection of selectionSet.selections) {\n    if (isField(selection)) {\n      if (selection.name.value === \"__typename\") {\n        return result[resultKeyNameFromField(selection)];\n      }\n    } else if (fragments) {\n      fragments.push(selection);\n    } else {\n      fragments = [selection];\n    }\n  }\n  if (typeof result.__typename === \"string\") {\n    return result.__typename;\n  }\n  if (fragments) {\n    for (const selection of fragments) {\n      const typename = getTypenameFromResult(\n        result,\n        getFragmentFromSelection(selection, fragmentMap)!.selectionSet,\n        fragmentMap\n      );\n      if (typeof typename === \"string\") {\n        return typename;\n      }\n    }\n  }\n}\n"],"mappings":";;AAAA,SAASA,KAAT,QAAsB,eAAe;AACrC,SAASC,IAAT,QAAqB,WAAW;AAOhC,SAASC,IAAT,QAAqB,SAAS;AAQ9B,SACEC,qBAAqB,EACrBC,kBAAkB,EAClBC,WAAW,QACN,0BAA0B;AACjC,SAASC,OAAT,QAAwB,sCAAsC;AAK9D,SACEC,wBAAwB,EACxBC,SAAS,EACTC,gBAAgB,EAChBC,wBAAwB,EACxBC,sBAAsB,EACtBC,aAAa,EACbC,OAAO,EACPC,OAAO,EACPC,eAAe,EACfC,aAAa,EACbC,sBAAsB,EACtBC,aAAa,EACbC,gBAAgB,QACX,mCAAmC;AAC1C,SACEC,SAAS,EACTC,iBAAiB,QACZ,oCAAoC;AAK3C,SACEC,sBAAsB,EACtBC,sBAAsB,EACtBC,yBAAyB,EACzBC,uBAAuB,QAClB,cAAc;AAErB,SACEC,yBAAyB,EACzBC,yBAAyB,QACpB,eAAe;AAwCtB;AACA;AACA;AACA;AACA;AACA,SAASC,gBAAgBA,CACvBC,OAAiB,EACjBC,UAAkC,EAClCC,QAA8B,EAHhC;EAKE,MAAMC,GAAR,MAAAC,MAAA,CAAiBH,UAAU,EAAAG,MAAA,CAAGF,QAAQ,CAAE;EACtC,IAAIG,QAAN,GAAiBL,OAAO,CAACM,OAAO,CAACC,GAAG,CAACJ,GAAG,CAAC;EACvC,IAAI,CAACE,QAAQ,EAAE;IACbL,OAAO,CAACM,OAAO,CAACE,GAAG,CACjBL,GAAG,EACFE,QAFP,GAGQL,OAAO,CAACC,UAAhB,KAA+BA,UAA/B,IAA6CD,OAAO,CAACE,QAArD,KAAkEA,QAAlE,GACUF,OAAV,GAAAS,aAAA,CAAAA,aAAA,KAEeT,OAAO;MACVC,UAAU;MACVC;IAAQ,EACR,CACP;EACH;EACA,OAAOG,QAAoB;AAC7B;AAWA,aAAaK,WAAb;EACEC,WAAFA,CACoBC,KAAoB,EAC5BC,MAAoB,EACpBC,SAA4C,EAHxD;IAAAC,eAAA;IAAAA,eAAA;IAAAA,eAAA;IACoB,IAApB,CAAAH,KAAA,GAAoBA,KAAK;IACb,IAAZ,CAAAC,MAAA,GAAYA,MAAM;IACN,IAAZ,CAAAC,SAAA,GAAYA,SAAS;EAChB;EAEIE,YAAYA,CAIjBC,KAAsB,EAAAC,IAAA,EAJ1B;IAAA,IAKI;MACEC,KAAK;MACLC,MAAM;MACNC,MAAM;MACNC,SAAS;MACTC,SAAS;MACTC;IAXN,CAY4C,GAAAN,IAAA;IAExC,MAAMO,mBAAV,GAAgC3C,sBAAsB,CAACqC,KAAK,CAAE;IAC1D,MAAMO,MAAV,GAAmB/B,yBAAyB,CAA5C,CAA8C;IAE1C2B,SAAJ,GAAAb,aAAA,CAAAA,aAAA,KACS7B,gBAAgB,CAAC6C,mBAAmB,CAAC,GACrCH,SAAU,CACd;IAED,MAAMtB,OAAV,GAAAS,aAAA,CAAAA,aAAA;MACMQ,KAAK;MACLU,OAAO,EAAE,CAAf,CAAiB;MACXC,KAAKA,CAAIC,QAAW,EAAEC,QAAW,EAAvC;QACQ,OAAOJ,MAAM,CAACE,KAAK,CAACC,QAAQ,EAAEC,QAAQ,CAAM;MAC9C,CAAC;MACDR,SAAS,EAAEA,SAA+B;MAC1CS,SAAS,EAAExD,kBAAkB,CAAC+C,SAAS;IAAC,GACrC7B,sBAAsB,CAAC0B,KAAK,EAAE,IAAI,CAACL,SAAS,CAAC;MAChDS,SAAS,EAAE,CAAC,CAACA,SAAS;MACtBS,YAAY,EAAE,IAAIC,GAAG,CAA3B,CAA6B;MACvBhC,UAAU,EAAE,KAAK;MACjBC,QAAQ,EAAE,KAAK;MACfI,OAAO,EAAE,IAAI2B,GAAG,CAAtB,CAAwB;MAClBT;IAAU,EACX;IAED,MAAMU,GAAV,GAAgB,IAAI,CAACC,mBAAmB,CAAC;MACnCf,MAAM,EAAEA,MAAd,IAAwB,CAAxB,CAA0B;MACpBC,MAAM;MACNe,YAAY,EAAEX,mBAAmB,CAACW,YAAY;MAC9CC,SAAS,EAAE;QAAEC,GAAG,EAAE,IAAIL,GAAG,CAA/B;MAAA,CAAmC;MAC7BjC,OAAO;MACPuC,IAAI,EAAE;IACZ,CAAK,CAAC;IAEF,IAAI,CAAC/D,WAAW,CAAC0D,GAAG,CAAC,EAAE;MACrB,MAAM1C,iBAAZ,MAA8D4B,MAA9D,CAAqE;IACjE;IAEA;IACA;IACApB,OAAO,CAACgC,YAAY,CAACQ,OAAO,CAC1B,CAAAC,KAAA,EAA2CpB,MAAM,KADvD;MAAA,IACO;QAAEqB,WAAW;QAAEL,SAAS;QAAEM;MADjC,CAC+C,GAAAF,KAAA;MACvC,MAAMG,SAAd,GAA0BzD,aAAa,CAACkC,MAAM,CAAC;MAEvC,IAAIgB,SAAZ,IAAyBA,SAAS,CAACC,GAAG,CAACO,IAAI,EAAE;QACnC,MAAMC,OAAhB,GAA0B,IAAI,CAACC,WAAW,CAC9BV,SAAS,EACTO,SAAS,EACTF,WAAW,EACX1C,OAAO,CACR;QACD,IAAIxB,WAAW,CAACsE,OAAO,CAAC,EAAE;UACxB;UACA;UACA;UACA;QACF;QACA;QACA;QACAJ,WAAV,GAAwBI,OAAO;MACvB;MAEA,IAAIrE,OAAZ,IAAuB,CAACuB,OAAO,CAACuB,SAAS,EAAE;QACjC,MAAMyB,uBAAhB,GAAgE,CAAhE,CAAkE;QACxDL,YAAY,CAACH,OAAO,CAAES,KAAK,IAArC;UACY,IAAIA,KAAK,CAACb,YAAY,EAAE;YACtBY,uBAAuB,CAACC,KAAK,CAACC,IAAI,CAACC,KAAK,IAAI,IAAI;UAClD;QACF,CAAC,CAAC;QAEF,MAAMC,eAAhB,GAAmCC,cAAsB,IAC7CL,uBAAuB,CAACtD,sBAAsB,CAAC2D,cAAc,CAAC,MAC9D,IAAI;QAEN,MAAMC,gBAAhB,GAAoCD,cAAsB,IAA1D;UACY,MAAME,SAAlB,GAA8BlB,SAA9B,IAA2CA,SAAS,CAACC,GAAG,CAAC/B,GAAG,CAAC8C,cAAc,CAAC;UAChE,OAAOG,OAAO,CAACD,SAA3B,IAAwCA,SAAS,CAACE,IAAlD,IAA0DF,SAAS,CAACE,IAAI,CAAC7B,KAAK,CAAC;QACrE,CAAC;QAED8B,MAAM,CAACC,IAAI,CAACjB,WAAW,CAAC,CAACF,OAAO,CAAEa,cAAc,IAA1D;UACY;UACA;UACA;UACA;UACA,IACED,eAAe,CAACC,cAAc,KAC9B,CAACC,gBAAgB,CAACD,cAAc,CAAC,EACjC;YACAO,iBAAiB,CACfhB,SAAS,EACTF,WAAW,EACXW,cAAc,EACdrD,OAAO,CAACiB,KAAK,CACd;UACH;QACF,CAAC,CAAC;MACJ;MAEAA,KAAK,CAACW,KAAK,CAACP,MAAM,EAAEqB,WAAW,CAAC;IAClC,CAAC,CACF;IAED;IACA;IACA;IACA;IACA;IACAzB,KAAK,CAAC4C,MAAM,CAAC3B,GAAG,CAAC4B,KAAK,CAAC;IAEvB,OAAO5B,GAAG;EACZ;EAEQC,mBAAmBA,CAAA4B,KAAA,EAO7B;IAAA,IAP8B;MAC1B1C,MAAM;MACND,MAAM;MACNgB,YAAY;MACZpC,OAAO;MACP;MACA;MACAqC,SAAS;MACTE,IAAI,EAAEyB;IADV,CAE+B,GAAAD,KAAA;IAC3B,MAAM;MAAEE;IAAZ,IAAyB,IAAI,CAACrD,KAAK;IAE/B;IACA;IACA,IAAIkB,QAAR,GAAgC,CAAhC,CAAkC;IAE9B;IACA;IACA;IACA,MAAMoC,QAAV,GACO7C,MADP,IACiB4C,QAAQ,CAACE,iBAAiB,CAAC9C,MAAM,CAAC,IAC7C+C,qBAAqB,CAAChD,MAAM,EAAEgB,YAAY,EAAEpC,OAAO,CAACqE,WAAW,KAC9DhD,MAAP,IAAkBrB,OAAO,CAACiB,KAAK,CAACV,GAAG,CAACc,MAAM,EAAE,YAAY,CAAa;IAEjE,IAAI,QAAR,KAAqB,OAAO6C,QAAQ,EAAE;MAChCpC,QAAQ,CAACwC,UAAf,GAA4BJ,QAAQ;IAChC;IAEA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAMK,SAAV,GAAyC,SAAAA,CAAA,EAAzC;MAAA,SAAAC,IAAA,GAAAC,SAAA,CAAAC,MAAA,EAA6CC,IAAI,OAAAC,KAAA,CAAAJ,IAAA,GAAAK,IAAA,MAAAA,IAAA,GAAAL,IAAA,EAAAK,IAAA;QAAJF,IAAI,CAAAE,IAAA,IAAAJ,SAAA,CAAAI,IAAA;MAAA;MAC3C,MAAMC,OAAZ,GAAsBhF,yBAAyB,CACvC6E,IAAI,EACJ7C,QAAQ,EACR9B,OAAO,CAACsB,SAAS,CAClB;MAED,IAAI9C,WAAW,CAACsG,OAAO,CAACC,IAAI,CAAC,EAAE;QAC7B,MAAMtB,IAAd,GAAqBzD,OAAO,CAACgC,YAAY,CAACzB,GAAG,CAACuE,OAAO,CAACC,IAAI,CAACjB,KAAK,CAAC;QACzD,IAAIL,IAAI,EAAE;UACR,MAAMrC,MAAhB,GAAyB6C,QAAQ,CAACM,SAAS,CAAA9D,aAAA,CAAAA,aAAA,KAE1BqE,OAAO;YACVC,IAAI,EAAEtB,IAAI,CAACf;UAAW,IAExB1C,OAAO,CACR;UAED,IAAIoB,MAAd,KAAyB,KAAK,CAAC,EAAE;YACrB,OAAOA,MAAM;UACf;QACF;MACF;MAEA,OAAO6C,QAAQ,CAACM,SAAS,CAACO,OAAO,EAAE9E,OAAO,CAAC;IAC7C,CAAC;IAED,MAAM2C,YAAV,GAAyB,IAAIqC,GAAG,CAAhC,CAA6C;IAEzC,IAAI,CAACC,aAAa,CAChB7C,YAAY,EACZhB,MAAM;IACN;IACA;IACA;IACApB,OAAO,EACPkE,QAAQ,CACT,CAAC1B,OAAO,CAAC,CAACxC,OAAO,EAAEiD,KAAK,KAF7B;MAGM,MAAMiC,cAAZ,GAA6B9F,sBAAsB,CAAC6D,KAAK,CAAC;MACpD,MAAME,KAAZ,GAAoB/B,MAAM,CAAC8D,cAAc,CAAC;MACpC,MAAM3C,IAAZ,GAAmB,CAAC,GAAGyB,WAAW,EAAEf,KAAK,CAACC,IAAI,CAACC,KAAK,CAAC;MAE/CR,YAAY,CAACwC,GAAG,CAAClC,KAAK,CAAC;MAEvB,IAAIE,KAAV,KAAoB,KAAK,CAAC,EAAE;QAAA,IAAAiC,mBAAA;QACpB,MAAM/B,cAAd,GAA+BY,QAAQ,CAACoB,iBAAiB,CAAC;UAChDnB,QAAQ;UACRoB,SAAS,EAAErC,KAAK,CAACC,IAAI,CAACC,KAAK;UAC3BF,KAAK;UACL3B,SAAS,EAAEtB,OAAO,CAACsB;QAC7B,CAAS,CAAC;QAEF,MAAMiC,SAAd,GAA0BgC,iBAAiB,CAAClD,SAAS,EAAEgB,cAAc,CAAC;QAE9D,IAAImC,aAAZ,GAA4B,IAAI,CAACC,iBAAiB,CACxCtC,KAAK,EACLF,KAAK;QACL;QACA;QACAA,KAAK,CAACb,YAAhB,GACYrC,gBAAgB,CAACC,OAAO,EAAE,KAAK,EAAE,KAAK,IACtCA,OAAO,EACTuD,SAAS,EACThB,IAAI,CACL;QAED;QACA;QACA;QACA,IAAImD,aAAiC;QAErC;QACA;QACA,IACEzC,KAAK,CAACb,YADhB,KAEW5D,WAAW,CAACgH,aAAa,KAAK5F,uBAAuB,CAAC4F,aAAa,CAAC,CAAC,EACtE;UACAE,aAAV,GAA0BnB,SAAS,CAAS,YAAY,EAAEiB,aAAa,CAAC;QAChE;QAEA,MAAM5D,KAAd,GAAsBqC,QAAQ,CAAC0B,gBAAgB,CACrCzB,QAAQ,EACRjB,KAAK,CAACC,IAAI,CAACC,KAAK,EAChBuC,aAAa,CACd;QAED,IAAI9D,KAAK,EAAE;UACT2B,SAAS,CAACE,IAApB,GAA2B;YACf;YACAR,KAAK;YACLiB,QAAQ;YACRtC,KAAK;YACLW;UACZ,CAAW;QACH,OAAO,IACLxD,aAAa,CAAC,CAAC,QAAQ,CAAC,EAAEkE,KAAK,KAC/B2B,KAAK,CAAC5F,OAAO,CAACwG,aAAa,MAAAJ,mBAAA,GAC3BpF,OAAO,CAACwB,UAAU,cAAA4D,mBAAA,eAAlBA,mBAAA,CAAqB9F,gBAAgB,CAAC,EACtC;UACAiE,SAAS,CAACE,IAApB,GAA2B;YACfR,KAAK;YACLiB,QAAQ;YACRtC,KAAK,EAAE/B,yBAAyB;YAChC0C;UACZ,CAAW;QACH,OAAO;UACLqD,0BAA0B,CAACvD,SAAS,EAAEgB,cAAc,CAAC;QACvD;QAEAvB,QAAR,GAAmB9B,OAAO,CAAC4B,KAAK,CAACE,QAAQ,EAAE;UACjC,CAACuB,cAAc,GAAGmC;QAC5B,CAAS,CAAC;MACJ,OAAO,IACL/G,OADR,IAEQ,CAACuB,OAAO,CAACC,UAAjB,IACQ,CAACD,OAAO,CAACE,QAAjB,IACQ,CAAC5B,qBAAqB,CAACuH,KAAK,CAAC5C,KAAK;MAClC;MACA;MACA;MACA,CAACgB,QAAQ,CAAC6B,eAAe,CAAC5B,QAAQ,EAAEjB,KAAK,CAACC,IAAI,CAACC,KAAK,CAAC,EACrD;QACA5D,SAAS,CAACwG,KAAlB,MAEU3G,sBAAsB,CAAC6D,KAAK,GAC5B7B,MAHV,CAIS;MACH;IACF,CAAC,CAAC;IAEF;IACA;IACA,IAAI;MACF,MAAM,CAAC4E,EAAE,EAAEC,SAAS,IAAIhC,QAAQ,CAACiC,QAAQ,CAAC9E,MAAM,EAAE;QAChD8C,QAAQ;QACR9B,YAAY;QACZiC,WAAW,EAAErE,OAAO,CAACqE,WAAW;QAChC3B,WAAW,EAAEZ,QAAQ;QACrByC;MACR,CAAO,CAAC;MAEF;MACA;MACAlD,MAAN,GAAeA,MAAf,IAAyB2E,EAAE;MAErB;MACA;MACA,IAAIC,SAAS,EAAE;QACb;QACAnE,QAAR,GAAmB9B,OAAO,CAAC4B,KAAK,CAACE,QAAQ,EAAEmE,SAAS,CAAC;MAC/C;IACF,EAAE,OAAOE,CAAC,EAAE;MACV;MACA,IAAI,CAAC9E,MAAM,EAAE,MAAM8E,CAAC;IACtB;IAEA,IAAI,QAAR,KAAqB,OAAO9E,MAAM,EAAE;MAC9B,MAAM+E,OAAZ,GAAsBjH,aAAa,CAACkC,MAAM,CAAC;MAErC;MACA;MACA;MACA;MACA;MACA,MAAMgF,IAAZ,GAAmBrG,OAAO,CAAC2B,OAAO,CAACN,MAAM,MAAMrB,OAAO,CAAC2B,OAAO,CAACN,MAAM,IAAI,EAAE,CAAC;MACtE,IAAIgF,IAAI,CAACC,OAAO,CAAClE,YAAY,KAAK,CAAC,EAAE,OAAOgE,OAAO;MACnDC,IAAI,CAACE,IAAI,CAACnE,YAAY,CAAC;MAEvB;MACA;MACA;MACA;MACA;MACA,IACE,IAAI,CAACvB,MADb,IAEQ,IAAI,CAACA,MAAM,CAAC2F,OAAO,CAACpF,MAAM,EAAEgF,OAAO,EAAEhE,YAAY,EAAEpC,OAAO,CAAC,EAC3D;QACA,OAAOoG,OAAO;MAChB;MAEA,MAAMK,QAAZ,GAAuBzG,OAAO,CAACgC,YAAY,CAACzB,GAAG,CAACc,MAAM,CAAC;MACjD,IAAIoF,QAAQ,EAAE;QACZA,QAAQ,CAAC/D,WAAjB,GAA+B1C,OAAO,CAAC4B,KAAK,CAAC6E,QAAQ,CAAC/D,WAAW,EAAEZ,QAAQ,CAAC;QACpE2E,QAAQ,CAACpE,SAAjB,GAA6BqE,eAAe,CAACD,QAAQ,CAACpE,SAAS,EAAEA,SAAS,CAAC;QACnEM,YAAY,CAACH,OAAO,CAAES,KAAK,IAAKwD,QAAQ,CAAC9D,YAAY,CAACwC,GAAG,CAAClC,KAAK,CAAC,CAAC;MACnE,OAAO;QACLjD,OAAO,CAACgC,YAAY,CAACxB,GAAG,CAACa,MAAM,EAAE;UAC/BqB,WAAW,EAAEZ,QAAQ;UACrB;UACA;UACA;UACAO,SAAS,EAAEsE,gBAAgB,CAACtE,SAAS,IAAI,KAAK,IAAIA,SAAS;UAC3DM;QACV,CAAS,CAAC;MACJ;MAEA,OAAOyD,OAAO;IAChB;IAEA,OAAOtE,QAAQ;EACjB;EAEQ2D,iBAAiBA,CACvBtC,KAAU,EACVF,KAAgB,EAChBjD,OAAqB,EACrBqC,SAAoB,EACpBE,IAA4B,EALhC;IAOI,IAAI,CAACU,KAAK,CAACb,YAAf,IAA+Be,KAA/B,KAAyC,IAAI,EAAE;MACzC;MACA;MACA;MACA,OAAO1E,OAAb,GAAuBE,SAAS,CAACwE,KAAK,IAAIA,KAAK;IAC3C;IAEA,IAAInE,OAAO,CAACmE,KAAK,CAAC,EAAE;MAClB,OAAOA,KAAK,CAACb,GAAG,CAAC,CAACsE,IAAI,EAAEC,CAAC,KAA/B;QACQ,MAAM1D,KAAd,GAAsB,IAAI,CAACsC,iBAAiB,CAClCmB,IAAI,EACJ3D,KAAK,EACLjD,OAAO,EACPuF,iBAAiB,CAAClD,SAAS,EAAEwE,CAAC,CAAC,EAC/B,CAAC,GAAGtE,IAAI,EAAEsE,CAAC,CAAC,CACb;QACDjB,0BAA0B,CAACvD,SAAS,EAAEwE,CAAC,CAAC;QACxC,OAAO1D,KAAK;MACd,CAAC,CAAC;IACJ;IAEA,OAAO,IAAI,CAAChB,mBAAmB,CAAC;MAC9Bf,MAAM,EAAE+B,KAAK;MACbf,YAAY,EAAEa,KAAK,CAACb,YAAY;MAChCpC,OAAO;MACPqC,SAAS;MACTE;IACN,CAAK,CAAC;EACJ;EAEA;EACA;EACQ0C,aAAaA,CAWnB7C,YAA8B,EAC9BhB,MAA2B,EAC3BpB,OAAiB,EAbrB;IAAA,IAcIkE,QAdJ,GAAAO,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAqC,SAAA,GAAArC,SAAA,MAceL,qBAAqB,CAAChD,MAAM,EAAEgB,YAAY,EAAEpC,OAAO,CAACqE,WAAW,CAAC;IAE3E,MAAM0C,QAAV,GAAqB,IAAI9E,GAAG,CAA5B,CAAmD;IAC/C,MAAM;MAAEgC;IAAZ,IAAyB,IAAI,CAACrD,KAAK;IAE/B,MAAMoG,YAAV,GAAyB,IAAI5I,IAAI,CAU1B,KAAK,CAAC,EAAE;IAEX,CAAC,SAAS6I,OAAOA,CAEf7E,YAA8B,EAC9B8E,gBAA0B,EAHhC;MAKM,MAAMC,WAAZ,GAA0BH,YAAY,CAACI,MAAM,CACrChF,YAAY;MACZ;MACA;MACA;MACA;MACA8E,gBAAgB,CAACjH,UAAU,EAC3BiH,gBAAgB,CAAChH,QAAQ,CAC1B;MACD,IAAIiH,WAAW,CAACE,OAAO,EAAE;MACzBF,WAAW,CAACE,OAAlB,GAA4B,IAAI;MAE1BjF,YAAY,CAACkF,UAAU,CAAC9E,OAAO,CAAE+E,SAAS,IAAhD;QACQ,IAAI,CAAClI,aAAa,CAACkI,SAAS,EAAEvH,OAAO,CAACsB,SAAS,CAAC,EAAE;QAElD,IAAI;UAAErB,UAAU;UAAEC;QAA1B,IAAuCgH,gBAAgB;QAC/C;QACE;QACA;QACA;QACA,EAAEjH,UAAZ,IAA0BC,QAAQ,KACxBhB,eAAe,CAACqI,SAAS,CAACC,UAAU,CAAC,EACrC;UACAD,SAAS,CAACC,UAAU,CAAChF,OAAO,CAAEiF,GAAG,IAA3C;YACY,MAAMvE,IAAlB,GAAyBuE,GAAG,CAACvE,IAAI,CAACC,KAAK;YAC3B,IAAID,IAAhB,KAAyB,QAAQ,EAAEjD,UAAnC,GAAgD,IAAI;YACxC,IAAIiD,IAAhB,KAAyB,OAAO,EAAE;cACpB,MAAMyB,IAApB,GAA2BjG,wBAAwB,CAAC+I,GAAG,EAAEzH,OAAO,CAACsB,SAAS,CAAC;cAC7D;cACA;cACA;cACA;cACA,IAAI,CAACqD,IAAnB,IAA4BA,IAAyB,CAAC+C,EAAtD,KAA6D,KAAK,EAAE;gBACpDxH,QAAhB,GAA2B,IAAI;cACjB;cACA;cACA;YACF;UACF,CAAC,CAAC;QACJ;QAEA,IAAIjB,OAAO,CAACsI,SAAS,CAAC,EAAE;UACtB,MAAM1F,QAAhB,GAA2BkF,QAAQ,CAACxG,GAAG,CAACgH,SAAS,CAAC;UACxC,IAAI1F,QAAQ,EAAE;YACZ;YACA;YACA;YACA5B,UAAZ,GAAyBA,UAAzB,IAAuC4B,QAAQ,CAAC5B,UAAU;YAC9CC,QAAZ,GAAuBA,QAAvB,IAAmC2B,QAAQ,CAAC3B,QAAQ;UAC1C;UAEA6G,QAAQ,CAACvG,GAAG,CACV+G,SAAS,EACTxH,gBAAgB,CAACC,OAAO,EAAEC,UAAU,EAAEC,QAAQ,CAAC,CAChD;QACH,OAAO;UACL,MAAMyH,QAAhB,GAA2B9I,wBAAwB,CACvC0I,SAAS,EACTvH,OAAO,CAAC4H,cAAc,CACvB;UAED,IAAI,CAACD,QAAf,IAA2BJ,SAAS,CAACM,IAArC,KAA8CxJ,IAAI,CAACyJ,eAAe,EAAE;YACxD,MAAMtI,iBAAlB,MAEc+H,SAAS,CAACrE,IAAI,CAACC,KAF7B,CAGa;UACH;UAEA,IACEwE,QADZ,IAEY1D,QAAQ,CAAC8D,eAAe,CACtBJ,QAAQ,EACRzD,QAAQ,EACR9C,MAAM,EACNpB,OAAO,CAACsB,SAAS,CAClB,EACD;YACA2F,OAAO,CACLU,QAAQ,CAACvF,YAAY,EACrBrC,gBAAgB,CAACC,OAAO,EAAEC,UAAU,EAAEC,QAAQ,CAAC,CAChD;UACH;QACF;MACF,CAAC,CAAC;IACJ,CAAC,EAAEkC,YAAY,EAAEpC,OAAO,CAAC;IAEzB,OAAO+G,QAAQ;EACjB;EAEQhE,WAAWA,CACjBV,SAAoB,EACpBR,QAAoB,EACpBC,QAAW,EACX9B,OAAqB,EACrBgI,cAAsD,EAL1D;IAOI,IAAI3F,SAAS,CAACC,GAAG,CAACO,IAAtB,IAA8B,CAACrE,WAAW,CAACsD,QAAQ,CAAC,EAAE;MAChD,MAAMqE,CAAA;MACJ;MACA;MACA;MAEE,CAACnH,OAAO,CAAC8C,QAAQ;MACjB;MACA;MACA;MACCtD,WAAW,CAACqD,QAAQ,KAAKjC,uBAAuB,CAACiC,QAAQ,CAAC,CAAC,GAE5DA,QAAV,GACU,KAAK,CAAC;MAEV;MACA;MACA;MACA,MAAMgF,CAAA,GAAI/E,QAAsC;MAEhD;MACA;MACA;MACA;MACA,IAAIqE,CAAA,IAAK,CAAC6B,cAAc,EAAE;QACxBA,cAAR,GAAyB,CAACxJ,WAAW,CAAC2H,CAAC,IAAIA,CAAC,CAACrC,KAA7C,GAAqDqC,CAAC,CAAC;MACjD;MAEA;MACA;MACA;MACA;MACA;MACA,IAAI8B,aAA2D;MAE/D,MAAMC,QAAZ,GAAuBA,CACfnD,IAAyB,EACzB7B,IAAqB,KAF7B;QAIQ,OACElE,OAAO,CAAC+F,IAAI,IACV,OAAO7B,IAAnB,KAA4B,QAA5B,GACc6B,IAAI,CAAC7B,IAAI,IACT,KAAK,IACPlD,OAAO,CAACiB,KAAK,CAACkH,aAAa,CAACpD,IAAI,EAAEqD,MAAM,CAAClF,IAAI,CAAC,CAAC;MAErD,CAAC;MAEDb,SAAS,CAACC,GAAG,CAACE,OAAO,CAAC,CAACe,SAAS,EAAEF,cAAc,KAAtD;QACQ,MAAMgF,IAAd,GAAqBH,QAAQ,CAAC/B,CAAC,EAAE9C,cAAc,CAAC;QACxC,MAAMiF,IAAd,GAAqBJ,QAAQ,CAACrB,CAAC,EAAExD,cAAc,CAAC;QACxC;QACA,IAAI,KAAK,MAAMiF,IAAI,EAAE;QACrB,IAAIN,cAAc,EAAE;UAClBA,cAAc,CAACzB,IAAI,CAAClD,cAAc,CAAC;QACrC;QACA,MAAMkF,IAAd,GAAqB,IAAI,CAACxF,WAAW,CAC3BQ,SAAS,EACT8E,IAAI,EACJC,IAAI,EACJtI,OAAO,EACPgI,cAAc,CACf;QACD,IAAIO,IAAZ,KAAqBD,IAAI,EAAE;UACjBL,aAAV,GAA0BA,aAA1B,IAA2C,IAAIhG,GAAG,CAAlD,CAAoD;UAC1CgG,aAAa,CAACzH,GAAG,CAAC6C,cAAc,EAAEkF,IAAI,CAAC;QACzC;QACA,IAAIP,cAAc,EAAE;UAClBzI,SAAS,CAACyI,cAAc,CAACQ,GAAG,CAAtC,MAA6CnF,cAAc,CAAC;QACpD;MACF,CAAC,CAAC;MAEF,IAAI4E,aAAa,EAAE;QACjB;QACAnG,QAAR,GAAoB9C,OAAO,CAAC6H,CAAC,IAAIA,CAAC,CAAC4B,KAAK,CAAC,CAAC,IAAAhI,aAAA,KAASoG,CAAA,CAAS;QACpDoB,aAAa,CAACzF,OAAO,CAAC,CAACW,KAAK,EAAED,IAAI,KAA1C;UACWpB,QAAgB,CAACoB,IAAI,IAAIC,KAAK;QACjC,CAAC,CAAC;MACJ;IACF;IAEA,IAAId,SAAS,CAACoB,IAAI,EAAE;MAClB,OAAO,IAAI,CAAC7C,KAAK,CAACqD,QAAQ,CAACyE,gBAAgB,CACzC7G,QAAQ,EACRC,QAAQ,EACRO,SAAS,CAACoB,IAAI,EACdzD,OAAO,EACPgI,cALR,IAK0BhI,OAAO,CAACiB,KAAK,CAAC0H,UAAU,CAAC,GAAGX,cAAc,CAAC,CAC9D;IACH;IAEA,OAAOlG,QAAQ;EACjB;AACF;AAEA,MAAM8G,kBAAN,GAAwC,EAAE;AAE1C,SAASrD,iBAAiBA,CAAAsD,KAAA,EAExB3F,IAAqB,EAFvB;EAAA,IACE;IAAEZ;EADJ,CACoB,GAAAuG,KAAA;EAGlB,IAAI,CAACvG,GAAG,CAACwG,GAAG,CAAC5F,IAAI,CAAC,EAAE;IAClBZ,GAAG,CAAC9B,GAAG,CAAC0C,IAAI,EAAE0F,kBAAkB,CAACJ,GAAG,CAAxC,KAA8C;MAAElG,GAAG,EAAE,IAAIL,GAAG,CAA5D;IAAA,CAAgE,CAAC;EAC/D;EACA,OAAOK,GAAG,CAAC/B,GAAG,CAAC2C,IAAI,CAAE;AACvB;AAEA,SAASwD,eAAeA,CACtBqC,IAA2B,EAC3BC,KAA4B,EAF9B;EAIE,IAAID,IAAN,KAAeC,KAAf,IAAwB,CAACA,KAAzB,IAAkCrC,gBAAgB,CAACqC,KAAK,CAAC,EAAE,OAAOD,IAAK;EACrE,IAAI,CAACA,IAAP,IAAepC,gBAAgB,CAACoC,IAAI,CAAC,EAAE,OAAOC,KAAK;EAEjD,MAAMvF,IAAR,GACIsF,IAAI,CAACtF,IADT,IACiBuF,KAAK,CAACvF,IADvB,GAAAhD,aAAA,CAAAA,aAAA,KAGWsI,IAAI,CAACtF,IAAI,GACTuF,KAAK,CAACvF,IAAI,IAEfsF,IAAI,CAACtF,IAAX,IAAmBuF,KAAK,CAACvF,IAAI;EAE3B,MAAMwF,eAAR,GAA0BF,IAAI,CAACzG,GAAG,CAACO,IAAnC,IAA2CmG,KAAK,CAAC1G,GAAG,CAACO,IAAI;EACvD,MAAMP,GAAR,GACI2G,eADJ,GACsB,IAAIhH,GAAG,CAD7B,IAEM8G,IAAI,CAACzG,GAAG,CAACO,IAAf,GAAsBkG,IAAI,CAACzG,GAA3B,GACM0G,KAAK,CAAC1G,GAAG;EAEb,MAAM4G,MAAR,GAAiB;IAAEzF,IAAI;IAAEnB;EAAzB,CAA8B;EAE5B,IAAI2G,eAAe,EAAE;IACnB,MAAME,kBAAV,GAA+B,IAAInE,GAAG,CAACgE,KAAK,CAAC1G,GAAG,CAACqB,IAAI,CAArD,CAAuD,CAAC;IAEpDoF,IAAI,CAACzG,GAAG,CAACE,OAAO,CAAC,CAAC4G,QAAQ,EAAEjJ,GAAG,KAAnC;MACM+I,MAAM,CAAC5G,GAAG,CAAC9B,GAAG,CAACL,GAAG,EAAEuG,eAAe,CAAC0C,QAAQ,EAAEJ,KAAK,CAAC1G,GAAG,CAAC/B,GAAG,CAACJ,GAAG,CAAC,CAAC,CAAC;MAClEgJ,kBAAkB,CAACE,MAAM,CAAClJ,GAAG,CAAC;IAChC,CAAC,CAAC;IAEFgJ,kBAAkB,CAAC3G,OAAO,CAAErC,GAAG,IAAnC;MACM+I,MAAM,CAAC5G,GAAG,CAAC9B,GAAG,CACZL,GAAG,EACHuG,eAAe,CAACsC,KAAK,CAAC1G,GAAG,CAAC/B,GAAG,CAACJ,GAAG,CAAC,EAAE4I,IAAI,CAACzG,GAAG,CAAC/B,GAAG,CAACJ,GAAG,CAAC,CAAC,CACvD;IACH,CAAC,CAAC;EACJ;EAEA,OAAO+I,MAAM;AACf;AAEA,SAASvC,gBAAgBA,CAAC2C,IAA2B,EAArD;EACE,OAAO,CAACA,IAAV,IAAkB,EAAEA,IAAI,CAAC7F,IAAzB,IAAiC6F,IAAI,CAAChH,GAAG,CAACO,IAAI,CAAC;AAC/C;AAEA,SAAS+C,0BAA0BA,CAAA2D,KAAA,EAAqBrG,IAAqB,EAA7E;EAAA,IAAoC;IAAEZ;EAAtC,CAAsD,GAAAiH,KAAA;EACpD,MAAMhG,SAAR,GAAoBjB,GAAG,CAAC/B,GAAG,CAAC2C,IAAI,CAAC;EAC/B,IAAIK,SAAN,IAAmBoD,gBAAgB,CAACpD,SAAS,CAAC,EAAE;IAC5CqF,kBAAkB,CAACrC,IAAI,CAAChD,SAAS,CAAC;IAClCjB,GAAG,CAAC+G,MAAM,CAACnG,IAAI,CAAC;EAClB;AACF;AAEA,MAAMsG,QAAN,GAAiB,IAAIxE,GAAG,CAAxB,CAAkC;AAElC;AACA;AACA,SAASpB,iBAAiBA,CACxB6F,WAAsB,EACtBC,WAAwB,EACxBrG,cAAsB,EACtBpC,KAAsB,EAJxB;EAME,MAAM0I,QAAR,GAAoBC,QAAiC,IAArD;IACI,MAAMC,KAAV,GAAkB5I,KAAK,CAACkH,aAAa,CAAcyB,QAAQ,EAAEvG,cAAc,CAAC;IACxE,OAAO,OAAOwG,KAAlB,KAA4B,QAA5B,IAAwCA,KAAK;EAC3C,CAAC;EAED,MAAMhI,QAAR,GAAmB8H,QAAQ,CAACF,WAAW,CAAC;EACtC,IAAI,CAAC5H,QAAQ,EAAE;EAEf,MAAMC,QAAR,GAAmB6H,QAAQ,CAACD,WAAW,CAAC;EACtC,IAAI,CAAC5H,QAAQ,EAAE;EAEf;EACA;EACA,IAAItD,WAAW,CAACqD,QAAQ,CAAC,EAAE;EAE3B;EACA;EACA,IAAI1D,KAAK,CAAC0D,QAAQ,EAAEC,QAAQ,CAAC,EAAE;EAE/B;EACA;EACA;EACA,IACE4B,MAAM,CAACC,IAAI,CAAC9B,QAAQ,CAAC,CAACiI,KAAK,CACxB3J,GAAG,IAAKc,KAAK,CAACkH,aAAa,CAACrG,QAAQ,EAAE3B,GAAG,MAAM,KAAK,CAAC,CACvD,EACD;IACA;EACF;EAEA,MAAM4J,UAAR,GACI9I,KAAK,CAACkH,aAAa,CAASsB,WAAW,EAAE,YAAY,KACrDxI,KAAK,CAACkH,aAAa,CAASuB,WAAW,EAAE,YAAY,CAAC;EACxD,MAAMpE,SAAR,GAAoB5F,sBAAsB,CAAC2D,cAAc,CAAC;EACxD,MAAM2G,WAAR,MAAA5J,MAAA,CAAyB2J,UAAU,OAAA3J,MAAA,CAAIkF,SAAS,CAAE;EAChD;EACA,IAAIkE,QAAQ,CAACV,GAAG,CAACkB,WAAW,CAAC,EAAE;EAC/BR,QAAQ,CAACrE,GAAG,CAAC6E,WAAW,CAAC;EAEzB,MAAMC,cAAR,GAAmC,EAAE;EACnC;EACA;EACA,IAAI,CAACjL,OAAO,CAAC6C,QAAQ,KAAK,CAAC7C,OAAO,CAAC8C,QAAQ,CAAC,EAAE;IAC5C,CAACD,QAAQ,EAAEC,QAAQ,CAAC,CAACU,OAAO,CAAEqH,KAAK,IAAvC;MACM,MAAM3F,QAAZ,GAAuBjD,KAAK,CAACkH,aAAa,CAAC0B,KAAK,EAAE,YAAY,CAAC;MACzD,IAAI,OAAO3F,QAAjB,KAA8B,QAA9B,IAA0C,CAAC+F,cAAc,CAACC,QAAQ,CAAChG,QAAQ,CAAC,EAAE;QACtE+F,cAAc,CAAC1D,IAAI,CAACrC,QAAQ,CAAC;MAC/B;IACF,CAAC,CAAC;EACJ;aAEA3E,SAAS,CAAC4K,IAAZ,MAeI7E,SADJ,EAEIyE,UAFJ,EAGIE,cAAc,CAACvF,MAHnB,GAIM,oCAAN,GACQuF,cAAc,CAACG,IAAI,CAAC,OAAO,IAC3B,6CAAR,GACM,EAAN,EACIJ,WADJ,EAEIpF,KAAK,CAAC5F,OAAO,CAAC6C,QAAQ,IAAI,CAAC,GAAGA,QAAQ,IAAApB,aAAA,KAASoB,QAFnD,GAGI+C,KAAK,CAAC5F,OAAO,CAAC8C,QAAQ,IAAI,CAAC,GAAGA,QAAQ,IAAArB,aAAA,KAASqB,QAHnD,EAIG;AACH;AAEA,SAASsC,qBAAqBA,CAC5BhD,MAA2B,EAC3BgB,YAA8B,EAC9BiC,WAAyB,EAH3B;EAKE,IAAIvD,SAAqE;EACzE,KAAK,MAAMyG,SAAb,IAA0BnF,YAAY,CAACkF,UAAU,EAAE;IAC/C,IAAIrI,OAAO,CAACsI,SAAS,CAAC,EAAE;MACtB,IAAIA,SAAS,CAACrE,IAAI,CAACC,KAAzB,KAAmC,YAAY,EAAE;QACzC,OAAO/B,MAAM,CAAChC,sBAAsB,CAACmI,SAAS,CAAC,CAAC;MAClD;IACF,OAAO,IAAIzG,SAAS,EAAE;MACpBA,SAAS,CAACyF,IAAI,CAACgB,SAAS,CAAC;IAC3B,OAAO;MACLzG,SAAN,GAAkB,CAACyG,SAAS,CAAC;IACzB;EACF;EACA,IAAI,OAAOnG,MAAM,CAACkD,UAApB,KAAmC,QAAQ,EAAE;IACzC,OAAOlD,MAAM,CAACkD,UAAU;EAC1B;EACA,IAAIxD,SAAS,EAAE;IACb,KAAK,MAAMyG,SAAf,IAA4BzG,SAAS,EAAE;MACjC,MAAMoD,QAAZ,GAAuBE,qBAAqB,CACpChD,MAAM,EACNvC,wBAAwB,CAAC0I,SAAS,EAAElD,WAAW,CAAE,CAACjC,YAAY,EAC9DiC,WAAW,CACZ;MACD,IAAI,OAAOH,QAAjB,KAA8B,QAAQ,EAAE;QAChC,OAAOA,QAAQ;MACjB;IACF;EACF;AACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}