{"ast":null,"code":"import _objectSpread from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\nimport _defineProperty from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport { Trie } from \"@wry/trie\";\nimport { DeepMerger, streamInfoSymbol } from \"@apollo/client/utilities/internal\";\nimport { hasDirectives, isNonEmptyArray } from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\nclass IncrementalRequest {\n  constructor() {\n    _defineProperty(this, \"hasNext\", true);\n    _defineProperty(this, \"data\", {});\n    _defineProperty(this, \"errors\", []);\n    _defineProperty(this, \"extensions\", {});\n    _defineProperty(this, \"pending\", new Map());\n    _defineProperty(this, \"streamInfo\", new Trie(false, () => ({\n      current: {\n        isFirstChunk: true,\n        isLastChunk: false\n      }\n    })));\n    // `streamPositions` maps `pending.id` to the index that should be set by the\n    // next `incremental` stream chunk to ensure the streamed array item is placed\n    // at the correct point in the data array. `this.data` contains cached\n    // references with the full array so we can't rely on the array length in\n    // `this.data` to determine where to place item. This also ensures that items\n    // updated by the cache between a streamed chunk aren't overwritten by merges\n    // of future stream items from already merged stream items.\n    _defineProperty(this, \"streamPositions\", {});\n  }\n  handle() {\n    let cacheData = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.data;\n    let chunk = arguments.length > 1 ? arguments[1] : undefined;\n    this.hasNext = chunk.hasNext;\n    this.data = cacheData;\n    if (chunk.pending) {\n      for (const pending of chunk.pending) {\n        this.pending.set(pending.id, pending);\n        if (\"data\" in chunk) {\n          const dataAtPath = pending.path.reduce((data, key) => data[key], chunk.data);\n          if (Array.isArray(dataAtPath)) {\n            this.streamPositions[pending.id] = dataAtPath.length;\n            this.streamInfo.lookupArray(pending.path).current = {\n              isFirstChunk: true,\n              isLastChunk: false\n            };\n          }\n        }\n      }\n    }\n    if (hasIncrementalChunks(chunk)) {\n      for (const incremental of chunk.incremental) {\n        var _incremental$subPath;\n        const pending = this.pending.get(incremental.id);\n        invariant(pending, 66);\n        const path = pending.path.concat((_incremental$subPath = incremental.subPath) !== null && _incremental$subPath !== void 0 ? _incremental$subPath : []);\n        let data;\n        if (\"items\" in incremental) {\n          const items = incremental.items;\n          const parent = [];\n          // This creates a sparse array with values set at the indices streamed\n          // from the server. DeepMerger uses Object.keys and will correctly\n          // place the values in this array in the correct place\n          for (let i = 0; i < items.length; i++) {\n            parent[i + this.streamPositions[pending.id]] = items[i];\n          }\n          this.streamPositions[pending.id] += items.length;\n          this.streamInfo.lookupArray(path).current = {\n            isFirstChunk: false,\n            isLastChunk: false\n          };\n          data = parent;\n        } else {\n          data = incremental.data;\n          // Check if any pending streams added arrays from deferred data so\n          // that we can update streamPositions with the initial length of the\n          // array to ensure future streamed items are inserted at the right\n          // starting index.\n          this.pending.forEach(pendingItem => {\n            if (!(pendingItem.id in this.streamPositions)) {\n              // Check if this incremental data contains array data for the pending path\n              // The pending path is absolute, but incremental data is relative to the defer\n              // E.g., pending.path = [\"nestedObject\"], pendingItem.path = [\"nestedObject\", \"nestedFriendList\"]\n              // incremental.data = { scalarField: \"...\", nestedFriendList: [...] }\n              // So we need the path from pending.path onwards\n              const relativePath = pendingItem.path.slice(pending.path.length);\n              const dataAtPath = relativePath.reduce((data, key) => data === null || data === void 0 ? void 0 : data[key], incremental.data);\n              if (Array.isArray(dataAtPath)) {\n                this.streamPositions[pendingItem.id] = dataAtPath.length;\n              }\n            }\n          });\n        }\n        this.merge({\n          data,\n          extensions: incremental.extensions,\n          errors: incremental.errors\n        }, path);\n      }\n    } else {\n      this.merge(chunk);\n    }\n    if (\"completed\" in chunk && chunk.completed) {\n      for (const completed of chunk.completed) {\n        const {\n          path\n        } = this.pending.get(completed.id);\n        const streamPosition = this.streamPositions[completed.id];\n        // Truncate any stream arrays in case the chunk only contains `hasNext`\n        // and `completed`.\n        if (streamPosition !== undefined) {\n          const dataAtPath = path.reduce((data, key) => data === null || data === void 0 ? void 0 : data[key], this.data);\n          this.merge({\n            data: dataAtPath.slice(0, streamPosition)\n          }, path);\n        }\n        // peek instead of lookup to avoid creating an entry for non-array values\n        const details = this.streamInfo.peekArray(path);\n        if (details) {\n          details.current = {\n            isFirstChunk: false,\n            isLastChunk: true\n          };\n        }\n        this.pending.delete(completed.id);\n        if (completed.errors) {\n          this.errors.push(...completed.errors);\n        }\n      }\n    }\n    const result = {\n      data: this.data\n    };\n    if (isNonEmptyArray(this.errors)) {\n      result.errors = this.errors;\n    }\n    if (Object.keys(this.extensions).length > 0) {\n      result.extensions = this.extensions;\n    }\n    if (this.streamInfo[\"strong\"]) {\n      result.extensions = _objectSpread(_objectSpread({}, result.extensions), {}, {\n        // Create a new object so we can check for === in QueryInfo to trigger a\n        // final cache write when emitting a `hasNext: false` by itself.\n        // We create a `WeakRef`, not a plain object to avoid retaining memory\n        // in case the `result` or `extensions` stays around longer than the handler\n        // itself.\n        [streamInfoSymbol]: new WeakRef(this.streamInfo)\n      });\n    }\n    return result;\n  }\n  merge(normalized, atPath) {\n    if (normalized.data !== undefined) {\n      this.data = new DeepMerger({\n        arrayMerge: \"truncate\"\n      }).merge(this.data, normalized.data, {\n        atPath\n      });\n    }\n    if (normalized.errors) {\n      this.errors.push(...normalized.errors);\n    }\n    Object.assign(this.extensions, normalized.extensions);\n  }\n}\n/**\n * Provides handling for the incremental delivery specification implemented by\n * graphql.js version `17.0.0-alpha.9`.\n */\nexport class GraphQL17Alpha9Handler {\n  /**\n  * @internal\n  * \n  * @deprecated This is an internal API and should not be used directly. This can be removed or changed at any time.\n  */\n  isIncrementalResult(result) {\n    return \"hasNext\" in result;\n  }\n  /**\n  * @internal\n  * \n  * @deprecated This is an internal API and should not be used directly. This can be removed or changed at any time.\n  */\n  prepareRequest(request) {\n    if (hasDirectives([\"defer\", \"stream\"], request.query)) {\n      var _request$context, _context$http;\n      const context = (_request$context = request.context) !== null && _request$context !== void 0 ? _request$context : {};\n      const http = (_context$http = context.http) !== null && _context$http !== void 0 ? _context$http : context.http = {};\n      // https://specs.apollo.dev/incremental/v0.2/\n      http.accept = [\"multipart/mixed;incrementalSpec=v0.2\", ...(http.accept || [])];\n      request.context = context;\n    }\n    return request;\n  }\n  /**\n  * @internal\n  * \n  * @deprecated This is an internal API and should not be used directly. This can be removed or changed at any time.\n  */\n  extractErrors(result) {\n    const acc = [];\n    const push = _ref => {\n      let {\n        errors\n      } = _ref;\n      if (errors) {\n        acc.push(...errors);\n      }\n    };\n    if (this.isIncrementalResult(result)) {\n      if (\"errors\" in result) {\n        push(result);\n      }\n      if (hasIncrementalChunks(result)) {\n        result.incremental.forEach(push);\n      }\n      if (hasCompletedChunks(result)) {\n        result.completed.forEach(push);\n      }\n    } else if (\"errors\" in result) {\n      push(result);\n    }\n    if (acc.length) {\n      return acc;\n    }\n  }\n  /**\n  * @internal\n  * \n  * @deprecated This is an internal API and should not be used directly. This can be removed or changed at any time.\n  */\n  startRequest(_) {\n    return new IncrementalRequest();\n  }\n}\nfunction hasIncrementalChunks(result) {\n  return isNonEmptyArray(result.incremental);\n}\nfunction hasCompletedChunks(result) {\n  return isNonEmptyArray(result.completed);\n}","map":{"version":3,"names":["Trie","DeepMerger","streamInfoSymbol","hasDirectives","isNonEmptyArray","invariant","IncrementalRequest","constructor","_defineProperty","Map","current","isFirstChunk","isLastChunk","handle","cacheData","arguments","length","undefined","data","chunk","hasNext","pending","set","id","dataAtPath","path","reduce","key","Array","isArray","streamPositions","streamInfo","lookupArray","hasIncrementalChunks","incremental","_incremental$subPath","get","concat","subPath","items","parent","i","forEach","pendingItem","relativePath","slice","merge","extensions","errors","completed","streamPosition","details","peekArray","delete","push","result","Object","keys","_objectSpread","WeakRef","normalized","atPath","arrayMerge","assign","GraphQL17Alpha9Handler","isIncrementalResult","prepareRequest","request","query","_request$context","_context$http","context","http","accept","extractErrors","acc","_ref","hasCompletedChunks","startRequest","_"],"sources":["/home/zobair-qauomi/todo_app/node_modules/@apollo/src/incremental/handlers/graphql17Alpha9.ts"],"sourcesContent":["import { Trie } from \"@wry/trie\";\nimport type {\n  DocumentNode,\n  FormattedExecutionResult,\n  GraphQLFormattedError,\n} from \"graphql\";\n\nimport type { ApolloLink } from \"@apollo/client/link\";\nimport type { DeepPartial, HKT } from \"@apollo/client/utilities\";\nimport type {\n  ExtensionsWithStreamInfo,\n  StreamInfoTrie,\n} from \"@apollo/client/utilities/internal\";\nimport {\n  DeepMerger,\n  streamInfoSymbol,\n} from \"@apollo/client/utilities/internal\";\nimport {\n  hasDirectives,\n  isNonEmptyArray,\n} from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\n\nimport type { Incremental } from \"../types.js\";\n\nexport declare namespace GraphQL17Alpha9Handler {\n  interface GraphQL17Alpha9Result extends HKT {\n    arg1: unknown; // TData\n    arg2: unknown; // TExtensions\n    return: GraphQL17Alpha9Handler.Chunk<Record<string, unknown>>;\n  }\n\n  export interface TypeOverrides {\n    AdditionalApolloLinkResultTypes: GraphQL17Alpha9Result;\n  }\n\n  export type InitialResult<TData = Record<string, unknown>> = {\n    data: TData;\n    errors?: ReadonlyArray<GraphQLFormattedError>;\n    pending: ReadonlyArray<PendingResult>;\n    hasNext: boolean;\n    extensions?: Record<string, unknown>;\n  };\n\n  export type SubsequentResult<TData = unknown> = {\n    hasNext: boolean;\n    pending?: ReadonlyArray<PendingResult>;\n    incremental?: ReadonlyArray<IncrementalResult<TData>>;\n    completed?: ReadonlyArray<CompletedResult>;\n    extensions?: Record<string, unknown>;\n  };\n\n  export interface PendingResult {\n    id: string;\n    path: Incremental.Path;\n    label?: string;\n  }\n\n  export interface CompletedResult {\n    id: string;\n    errors?: ReadonlyArray<GraphQLFormattedError>;\n  }\n\n  export interface IncrementalDeferResult<TData = Record<string, unknown>> {\n    errors?: ReadonlyArray<GraphQLFormattedError>;\n    data: TData;\n    id: string;\n    subPath?: Incremental.Path;\n    extensions?: Record<string, unknown>;\n  }\n\n  export interface IncrementalStreamResult<TData = ReadonlyArray<unknown>> {\n    errors?: ReadonlyArray<GraphQLFormattedError>;\n    items: TData;\n    id: string;\n    subPath?: Incremental.Path;\n    extensions?: Record<string, unknown>;\n  }\n\n  export type IncrementalResult<TData = unknown> =\n    | IncrementalDeferResult<TData>\n    | IncrementalStreamResult<TData>;\n\n  export type Chunk<TData> = InitialResult<TData> | SubsequentResult<TData>;\n}\n\nclass IncrementalRequest<TData>\n  implements\n    Incremental.IncrementalRequest<GraphQL17Alpha9Handler.Chunk<TData>, TData>\n{\n  hasNext = true;\n\n  private data: any = {};\n  private errors: GraphQLFormattedError[] = [];\n  private extensions: Record<string, any> = {};\n  private pending = new Map<string, GraphQL17Alpha9Handler.PendingResult>();\n  private streamInfo: StreamInfoTrie = new Trie(false, () => ({\n    current: { isFirstChunk: true, isLastChunk: false },\n  }));\n  // `streamPositions` maps `pending.id` to the index that should be set by the\n  // next `incremental` stream chunk to ensure the streamed array item is placed\n  // at the correct point in the data array. `this.data` contains cached\n  // references with the full array so we can't rely on the array length in\n  // `this.data` to determine where to place item. This also ensures that items\n  // updated by the cache between a streamed chunk aren't overwritten by merges\n  // of future stream items from already merged stream items.\n  private streamPositions: Record<string, number> = {};\n\n  handle(\n    cacheData: TData | DeepPartial<TData> | null | undefined = this.data,\n    chunk: GraphQL17Alpha9Handler.Chunk<TData>\n  ): FormattedExecutionResult<TData> {\n    this.hasNext = chunk.hasNext;\n    this.data = cacheData;\n\n    if (chunk.pending) {\n      for (const pending of chunk.pending) {\n        this.pending.set(pending.id, pending);\n\n        if (\"data\" in chunk) {\n          const dataAtPath = pending.path.reduce(\n            (data, key) => (data as any)[key],\n            chunk.data\n          );\n\n          if (Array.isArray(dataAtPath)) {\n            this.streamPositions[pending.id] = dataAtPath.length;\n            this.streamInfo.lookupArray(pending.path as any[]).current = {\n              isFirstChunk: true,\n              isLastChunk: false,\n            };\n          }\n        }\n      }\n    }\n\n    if (hasIncrementalChunks(chunk)) {\n      for (const incremental of chunk.incremental) {\n        const pending = this.pending.get(incremental.id);\n\n        invariant(\n          pending,\n          \"Could not find pending chunk for incremental value. Please file an issue for the Apollo Client team to investigate.\"\n        );\n\n        const path = pending.path.concat(incremental.subPath ?? []);\n\n        let data: any;\n        if (\"items\" in incremental) {\n          const items = incremental.items as any[];\n          const parent: any[] = [];\n\n          // This creates a sparse array with values set at the indices streamed\n          // from the server. DeepMerger uses Object.keys and will correctly\n          // place the values in this array in the correct place\n          for (let i = 0; i < items.length; i++) {\n            parent[i + this.streamPositions[pending.id]] = items[i];\n          }\n\n          this.streamPositions[pending.id] += items.length;\n          this.streamInfo.lookupArray(path).current = {\n            isFirstChunk: false,\n            isLastChunk: false,\n          };\n          data = parent;\n        } else {\n          data = incremental.data;\n\n          // Check if any pending streams added arrays from deferred data so\n          // that we can update streamPositions with the initial length of the\n          // array to ensure future streamed items are inserted at the right\n          // starting index.\n          this.pending.forEach((pendingItem) => {\n            if (!(pendingItem.id in this.streamPositions)) {\n              // Check if this incremental data contains array data for the pending path\n              // The pending path is absolute, but incremental data is relative to the defer\n              // E.g., pending.path = [\"nestedObject\"], pendingItem.path = [\"nestedObject\", \"nestedFriendList\"]\n              // incremental.data = { scalarField: \"...\", nestedFriendList: [...] }\n              // So we need the path from pending.path onwards\n              const relativePath = pendingItem.path.slice(pending.path.length);\n              const dataAtPath = relativePath.reduce(\n                (data, key) => (data as any)?.[key],\n                incremental.data\n              );\n\n              if (Array.isArray(dataAtPath)) {\n                this.streamPositions[pendingItem.id] = dataAtPath.length;\n              }\n            }\n          });\n        }\n\n        this.merge(\n          {\n            data,\n            extensions: incremental.extensions,\n            errors: incremental.errors,\n          },\n          path\n        );\n      }\n    } else {\n      this.merge(chunk);\n    }\n\n    if (\"completed\" in chunk && chunk.completed) {\n      for (const completed of chunk.completed) {\n        const { path } = this.pending.get(completed.id)!;\n        const streamPosition = this.streamPositions[completed.id];\n\n        // Truncate any stream arrays in case the chunk only contains `hasNext`\n        // and `completed`.\n        if (streamPosition !== undefined) {\n          const dataAtPath = path.reduce(\n            (data, key) => (data as any)?.[key],\n            this.data\n          );\n\n          this.merge({ data: dataAtPath.slice(0, streamPosition) }, path);\n        }\n\n        // peek instead of lookup to avoid creating an entry for non-array values\n        const details = this.streamInfo.peekArray(path as any[]);\n        if (details) {\n          details.current = {\n            isFirstChunk: false,\n            isLastChunk: true,\n          };\n        }\n        this.pending.delete(completed.id);\n\n        if (completed.errors) {\n          this.errors.push(...completed.errors);\n        }\n      }\n    }\n\n    const result: FormattedExecutionResult<TData> = { data: this.data };\n\n    if (isNonEmptyArray(this.errors)) {\n      result.errors = this.errors;\n    }\n\n    if (Object.keys(this.extensions).length > 0) {\n      result.extensions = this.extensions;\n    }\n\n    if (this.streamInfo[\"strong\"]) {\n      result.extensions = {\n        ...result.extensions,\n        // Create a new object so we can check for === in QueryInfo to trigger a\n        // final cache write when emitting a `hasNext: false` by itself.\n        // We create a `WeakRef`, not a plain object to avoid retaining memory\n        // in case the `result` or `extensions` stays around longer than the handler\n        // itself.\n        [streamInfoSymbol]: new WeakRef(this.streamInfo),\n      } satisfies ExtensionsWithStreamInfo;\n    }\n\n    return result;\n  }\n\n  private merge(\n    normalized: FormattedExecutionResult<TData>,\n    atPath?: DeepMerger.MergeOptions[\"atPath\"]\n  ) {\n    if (normalized.data !== undefined) {\n      this.data = new DeepMerger({ arrayMerge: \"truncate\" }).merge(\n        this.data,\n        normalized.data,\n        { atPath }\n      );\n    }\n\n    if (normalized.errors) {\n      this.errors.push(...normalized.errors);\n    }\n\n    Object.assign(this.extensions, normalized.extensions);\n  }\n}\n\n/**\n * Provides handling for the incremental delivery specification implemented by\n * graphql.js version `17.0.0-alpha.9`.\n */\nexport class GraphQL17Alpha9Handler\n  implements Incremental.Handler<GraphQL17Alpha9Handler.Chunk<any>>\n{\n  /** @internal */\n  isIncrementalResult(\n    result: ApolloLink.Result<any>\n  ): result is\n    | GraphQL17Alpha9Handler.InitialResult\n    | GraphQL17Alpha9Handler.SubsequentResult {\n    return \"hasNext\" in result;\n  }\n\n  /** @internal */\n  prepareRequest(request: ApolloLink.Request): ApolloLink.Request {\n    if (hasDirectives([\"defer\", \"stream\"], request.query)) {\n      const context = request.context ?? {};\n      const http = (context.http ??= {});\n      // https://specs.apollo.dev/incremental/v0.2/\n      http.accept = [\n        \"multipart/mixed;incrementalSpec=v0.2\",\n        ...(http.accept || []),\n      ];\n\n      request.context = context;\n    }\n\n    return request;\n  }\n\n  /** @internal */\n  extractErrors(result: ApolloLink.Result<any>) {\n    const acc: GraphQLFormattedError[] = [];\n    const push = ({\n      errors,\n    }: {\n      errors?: ReadonlyArray<GraphQLFormattedError>;\n    }) => {\n      if (errors) {\n        acc.push(...errors);\n      }\n    };\n\n    if (this.isIncrementalResult(result)) {\n      if (\"errors\" in result) {\n        push(result);\n      }\n      if (hasIncrementalChunks(result)) {\n        result.incremental.forEach(push);\n      }\n      if (hasCompletedChunks(result)) {\n        result.completed.forEach(push);\n      }\n    } else if (\"errors\" in result) {\n      push(result);\n    }\n\n    if (acc.length) {\n      return acc;\n    }\n  }\n\n  /** @internal */\n  startRequest<TData>(_: { query: DocumentNode }) {\n    return new IncrementalRequest<TData>();\n  }\n}\n\nfunction hasIncrementalChunks(\n  result: Record<string, any>\n): result is Required<GraphQL17Alpha9Handler.SubsequentResult> {\n  return isNonEmptyArray(result.incremental);\n}\n\nfunction hasCompletedChunks(\n  result: Record<string, any>\n): result is Required<GraphQL17Alpha9Handler.SubsequentResult> {\n  return isNonEmptyArray(result.completed);\n}\n"],"mappings":";;AAAA,SAASA,IAAT,QAAqB,WAAW;AAahC,SACEC,UAAU,EACVC,gBAAgB,QACX,mCAAmC;AAC1C,SACEC,aAAa,EACbC,eAAe,QACV,mCAAmC;AAC1C,SAASC,SAAT,QAA0B,oCAAoC;AAiE9D,MAAMC,kBAAN;EAAAC,YAAA;IAAAC,eAAA,kBAIY,IAAI;IAAAA,eAAA,eAEM,CAAtB,CAAwB;IAAAA,eAAA,iBACoB,EAAE;IAAAA,eAAA,qBACF,CAA5C,CAA8C;IAAAA,eAAA,kBAC1B,IAAIC,GAAG,CAA3B,CAA2E;IAAAD,eAAA,qBACpC,IAAIR,IAAI,CAAC,KAAK,EAAE,OAAO;MAC1DU,OAAO,EAAE;QAAEC,YAAY,EAAE,IAAI;QAAEC,WAAW,EAAE;MAAhD;IACA,CAAG,CAAC,CAAC;IACH;IACA;IACA;IACA;IACA;IACA;IACA;IAAAJ,eAAA,0BACkD,CAApD,CAAsD;EAAA;EAEpDK,MAAMA,CAAA,EAAR;IAAA,IACIC,SADJ,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAC+D,IAAI,CAACG,IAAI;IAAA,IACpEC,KAA0C,GAAAJ,SAAA,CAAAC,MAAA,OAAAD,SAAA,MAAAE,SAAA;IAE1C,IAAI,CAACG,OAAT,GAAmBD,KAAK,CAACC,OAAO;IAC5B,IAAI,CAACF,IAAT,GAAgBJ,SAAS;IAErB,IAAIK,KAAK,CAACE,OAAO,EAAE;MACjB,KAAK,MAAMA,OAAjB,IAA4BF,KAAK,CAACE,OAAO,EAAE;QACnC,IAAI,CAACA,OAAO,CAACC,GAAG,CAACD,OAAO,CAACE,EAAE,EAAEF,OAAO,CAAC;QAErC,IAAI,MAAZ,IAAsBF,KAAK,EAAE;UACnB,MAAMK,UAAhB,GAA6BH,OAAO,CAACI,IAAI,CAACC,MAAM,CACpC,CAACR,IAAI,EAAES,GAAG,KAAMT,IAAY,CAACS,GAAG,CAAC,EACjCR,KAAK,CAACD,IAAI,CACX;UAED,IAAIU,KAAK,CAACC,OAAO,CAACL,UAAU,CAAC,EAAE;YAC7B,IAAI,CAACM,eAAe,CAACT,OAAO,CAACE,EAAE,IAAIC,UAAU,CAACR,MAAM;YACpD,IAAI,CAACe,UAAU,CAACC,WAAW,CAACX,OAAO,CAACI,IAAa,CAAC,CAACf,OAA/D,GAAyE;cAC3DC,YAAY,EAAE,IAAI;cAClBC,WAAW,EAAE;YAC3B,CAAa;UACH;QACF;MACF;IACF;IAEA,IAAIqB,oBAAoB,CAACd,KAAK,CAAC,EAAE;MAC/B,KAAK,MAAMe,WAAjB,IAAgCf,KAAK,CAACe,WAAW,EAAE;QAAA,IAAAC,oBAAA;QAC3C,MAAMd,OAAd,GAAwB,IAAI,CAACA,OAAO,CAACe,GAAG,CAACF,WAAW,CAACX,EAAE,CAAC;QAEhDlB,SAAR,CACUgB,OADV,KAGS;QAED,MAAMI,IAAd,GAAqBJ,OAAO,CAACI,IAAI,CAACY,MAAM,EAAAF,oBAAA,GAACD,WAAW,CAACI,OAArD,cAAAH,oBAAA,cAAAA,oBAAA,GAAgE,EAAE,CAAC;QAE3D,IAAIjB,IAAS;QACb,IAAI,OAAZ,IAAuBgB,WAAW,EAAE;UAC1B,MAAMK,KAAhB,GAAwBL,WAAW,CAACK,KAAc;UACxC,MAAMC,MAAhB,GAAgC,EAAE;UAExB;UACA;UACA;UACA,KAAK,IAAIC,CAAA,GAAI,CAAC,EAAEA,CAAA,GAAIF,KAAK,CAACvB,MAAM,EAAEyB,CAAC,EAAE,EAAE;YACrCD,MAAM,CAACC,CAAA,GAAI,IAAI,CAACX,eAAe,CAACT,OAAO,CAACE,EAAE,CAAC,IAAIgB,KAAK,CAACE,CAAC,CAAC;UACzD;UAEA,IAAI,CAACX,eAAe,CAACT,OAAO,CAACE,EAAE,KAAKgB,KAAK,CAACvB,MAAM;UAChD,IAAI,CAACe,UAAU,CAACC,WAAW,CAACP,IAAI,CAAC,CAACf,OAA5C,GAAsD;YAC1CC,YAAY,EAAE,KAAK;YACnBC,WAAW,EAAE;UACzB,CAAW;UACDM,IAAV,GAAiBsB,MAAM;QACf,OAAO;UACLtB,IAAV,GAAiBgB,WAAW,CAAChB,IAAI;UAEvB;UACA;UACA;UACA;UACA,IAAI,CAACG,OAAO,CAACqB,OAAO,CAAEC,WAAW,IAA3C;YACY,IAAI,EAAEA,WAAW,CAACpB,EAA9B,IAAoC,IAAI,CAACO,eAAe,CAAC,EAAE;cAC7C;cACA;cACA;cACA;cACA;cACA,MAAMc,YAApB,GAAmCD,WAAW,CAAClB,IAAI,CAACoB,KAAK,CAACxB,OAAO,CAACI,IAAI,CAACT,MAAM,CAAC;cAChE,MAAMQ,UAApB,GAAiCoB,YAAY,CAAClB,MAAM,CACpC,CAACR,IAAI,EAAES,GAAG,KAAMT,IAAY,aAAZA,IAAY,uBAAZA,IAAY,CAAGS,GAAG,CAAC,EACnCO,WAAW,CAAChB,IAAI,CACjB;cAED,IAAIU,KAAK,CAACC,OAAO,CAACL,UAAU,CAAC,EAAE;gBAC7B,IAAI,CAACM,eAAe,CAACa,WAAW,CAACpB,EAAE,IAAIC,UAAU,CAACR,MAAM;cAC1D;YACF;UACF,CAAC,CAAC;QACJ;QAEA,IAAI,CAAC8B,KAAK,CACR;UACE5B,IAAI;UACJ6B,UAAU,EAAEb,WAAW,CAACa,UAAU;UAClCC,MAAM,EAAEd,WAAW,CAACc;QAChC,CAAW,EACDvB,IAAI,CACL;MACH;IACF,OAAO;MACL,IAAI,CAACqB,KAAK,CAAC3B,KAAK,CAAC;IACnB;IAEA,IAAI,WAAR,IAAuBA,KAAvB,IAAgCA,KAAK,CAAC8B,SAAS,EAAE;MAC3C,KAAK,MAAMA,SAAjB,IAA8B9B,KAAK,CAAC8B,SAAS,EAAE;QACvC,MAAM;UAAExB;QAAhB,IAAyB,IAAI,CAACJ,OAAO,CAACe,GAAG,CAACa,SAAS,CAAC1B,EAAE,CAAE;QAChD,MAAM2B,cAAd,GAA+B,IAAI,CAACpB,eAAe,CAACmB,SAAS,CAAC1B,EAAE,CAAC;QAEzD;QACA;QACA,IAAI2B,cAAZ,KAA+BjC,SAAS,EAAE;UAChC,MAAMO,UAAhB,GAA6BC,IAAI,CAACC,MAAM,CAC5B,CAACR,IAAI,EAAES,GAAG,KAAMT,IAAY,aAAZA,IAAY,uBAAZA,IAAY,CAAGS,GAAG,CAAC,EACnC,IAAI,CAACT,IAAI,CACV;UAED,IAAI,CAAC4B,KAAK,CAAC;YAAE5B,IAAI,EAAEM,UAAU,CAACqB,KAAK,CAAC,CAAC,EAAEK,cAAc;UAA/D,CAAkE,EAAEzB,IAAI,CAAC;QACjE;QAEA;QACA,MAAM0B,OAAd,GAAwB,IAAI,CAACpB,UAAU,CAACqB,SAAS,CAAC3B,IAAa,CAAC;QACxD,IAAI0B,OAAO,EAAE;UACXA,OAAO,CAACzC,OAAlB,GAA4B;YAChBC,YAAY,EAAE,KAAK;YACnBC,WAAW,EAAE;UACzB,CAAW;QACH;QACA,IAAI,CAACS,OAAO,CAACgC,MAAM,CAACJ,SAAS,CAAC1B,EAAE,CAAC;QAEjC,IAAI0B,SAAS,CAACD,MAAM,EAAE;UACpB,IAAI,CAACA,MAAM,CAACM,IAAI,CAAC,GAAGL,SAAS,CAACD,MAAM,CAAC;QACvC;MACF;IACF;IAEA,MAAMO,MAAV,GAAoD;MAAErC,IAAI,EAAE,IAAI,CAACA;IAAjE,CAAuE;IAEnE,IAAId,eAAe,CAAC,IAAI,CAAC4C,MAAM,CAAC,EAAE;MAChCO,MAAM,CAACP,MAAb,GAAsB,IAAI,CAACA,MAAM;IAC7B;IAEA,IAAIQ,MAAM,CAACC,IAAI,CAAC,IAAI,CAACV,UAAU,CAAC,CAAC/B,MAArC,GAA8C,CAAC,EAAE;MAC3CuC,MAAM,CAACR,UAAb,GAA0B,IAAI,CAACA,UAAU;IACrC;IAEA,IAAI,IAAI,CAAChB,UAAU,CAAC,QAAQ,CAAC,EAAE;MAC7BwB,MAAM,CAACR,UAAb,GAAAW,aAAA,CAAAA,aAAA,KACWH,MAAM,CAACR,UAAU;QACpB;QACA;QACA;QACA;QACA;QACA,CAAC7C,gBAAgB,GAAG,IAAIyD,OAAO,CAAC,IAAI,CAAC5B,UAAU;MAAC,EACd;IACtC;IAEA,OAAOwB,MAAM;EACf;EAEQT,KAAKA,CACXc,UAA2C,EAC3CC,MAA0C,EAF9C;IAII,IAAID,UAAU,CAAC1C,IAAnB,KAA4BD,SAAS,EAAE;MACjC,IAAI,CAACC,IAAX,GAAkB,IAAIjB,UAAU,CAAC;QAAE6D,UAAU,EAAE;MAA/C,CAA2D,CAAC,CAAChB,KAAK,CAC1D,IAAI,CAAC5B,IAAI,EACT0C,UAAU,CAAC1C,IAAI,EACf;QAAE2C;MAHV,CAGkB,CACX;IACH;IAEA,IAAID,UAAU,CAACZ,MAAM,EAAE;MACrB,IAAI,CAACA,MAAM,CAACM,IAAI,CAAC,GAAGM,UAAU,CAACZ,MAAM,CAAC;IACxC;IAEAQ,MAAM,CAACO,MAAM,CAAC,IAAI,CAAChB,UAAU,EAAEa,UAAU,CAACb,UAAU,CAAC;EACvD;AACF;AAEA;;;;AAIA,aAAaiB,sBAAb;;;;;;EAIEC,mBAAmBA,CACjBV,MAA8B,EADlC;IAKI,OAAO,SAAX,IAAwBA,MAAM;EAC5B;;;;;;EAGAW,cAAcA,CAACC,OAA2B,EAA5C;IACI,IAAIhE,aAAa,CAAC,CAAC,OAAO,EAAE,QAAQ,CAAC,EAAEgE,OAAO,CAACC,KAAK,CAAC,EAAE;MAAA,IAAAC,gBAAA,EAAAC,aAAA;MACrD,MAAMC,OAAZ,IAAAF,gBAAA,GAAsBF,OAAO,CAACI,OAA9B,cAAAF,gBAAA,cAAAA,gBAAA,GAAyC,CAAzC,CAA2C;MACrC,MAAMG,IAAZ,IAAAF,aAAA,GAAoBC,OAAO,CAACC,IAA5B,cAAAF,aAAA,cAAAA,aAAA,GAAoBC,OAAO,CAACC,IAA5B,GAAqC,CAArC,CAAwC;MAClC;MACAA,IAAI,CAACC,MAAX,GAAoB,CACZ,sCAAsC,EACtC,IAAID,IAAI,CAACC,MAAjB,IAA2B,EAAE,CAAC,CACvB;MAEDN,OAAO,CAACI,OAAd,GAAwBA,OAAO;IAC3B;IAEA,OAAOJ,OAAO;EAChB;;;;;;EAGAO,aAAaA,CAACnB,MAA8B,EAA9C;IACI,MAAMoB,GAAV,GAAyC,EAAE;IACvC,MAAMrB,IAAV,GAAiBsB,IAAA,IAAjB;MAAA,IAAkB;QACZ5B;MADN,CAIK,GAAA4B,IAAA;MACC,IAAI5B,MAAM,EAAE;QACV2B,GAAG,CAACrB,IAAI,CAAC,GAAGN,MAAM,CAAC;MACrB;IACF,CAAC;IAED,IAAI,IAAI,CAACiB,mBAAmB,CAACV,MAAM,CAAC,EAAE;MACpC,IAAI,QAAV,IAAsBA,MAAM,EAAE;QACtBD,IAAI,CAACC,MAAM,CAAC;MACd;MACA,IAAItB,oBAAoB,CAACsB,MAAM,CAAC,EAAE;QAChCA,MAAM,CAACrB,WAAW,CAACQ,OAAO,CAACY,IAAI,CAAC;MAClC;MACA,IAAIuB,kBAAkB,CAACtB,MAAM,CAAC,EAAE;QAC9BA,MAAM,CAACN,SAAS,CAACP,OAAO,CAACY,IAAI,CAAC;MAChC;IACF,OAAO,IAAI,QAAf,IAA2BC,MAAM,EAAE;MAC7BD,IAAI,CAACC,MAAM,CAAC;IACd;IAEA,IAAIoB,GAAG,CAAC3D,MAAM,EAAE;MACd,OAAO2D,GAAG;IACZ;EACF;;;;;;EAGAG,YAAYA,CAAQC,CAA0B,EAAhD;IACI,OAAO,IAAIzE,kBAAkB,CAAjC,CAA0C;EACxC;AACF;AAEA,SAAS2B,oBAAoBA,CAC3BsB,MAA2B,EAD7B;EAGE,OAAOnD,eAAe,CAACmD,MAAM,CAACrB,WAAW,CAAC;AAC5C;AAEA,SAAS2C,kBAAkBA,CACzBtB,MAA2B,EAD7B;EAGE,OAAOnD,eAAe,CAACmD,MAAM,CAACN,SAAS,CAAC;AAC1C","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}