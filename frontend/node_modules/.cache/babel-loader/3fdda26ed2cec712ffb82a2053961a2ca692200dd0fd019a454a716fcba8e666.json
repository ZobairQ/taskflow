{"ast":null,"code":"import _objectSpread from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\nimport _defineProperty from \"/home/zobair-qauomi/todo_app/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport { equal } from \"@wry/equality\";\nimport { getOperationName, graphQLResultHasError, streamInfoSymbol } from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\nconst IGNORE = {};\nconst destructiveMethodCounts = new WeakMap();\nfunction wrapDestructiveCacheMethod(cache, methodName) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    // @ts-expect-error this is just too generic to be typed correctly\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(cache,\n      // The %1e15 allows the count to wrap around to 0 safely every\n      // quadrillion evictions, so there's no risk of overflow. To be\n      // clear, this is more of a pedantic principle than something\n      // that matters in any conceivable practical scenario.\n      (destructiveMethodCounts.get(cache) + 1) % 1e15);\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\nconst queryInfoIds = new WeakMap();\n// A QueryInfo object represents a single network request, either initiated\n// from the QueryManager or from an ObservableQuery.\n// It will only ever be used for a single network call.\n// It is responsible for reporting results to the cache, merging and in a no-cache\n// scenario accumulating the response.\nexport class QueryInfo {\n  constructor(queryManager, observableQuery) {\n    // TODO remove soon - this should be able to be handled by cancelling old operations before starting new ones\n    _defineProperty(this, \"lastRequestId\", 1);\n    _defineProperty(this, \"cache\", void 0);\n    _defineProperty(this, \"queryManager\", void 0);\n    _defineProperty(this, \"id\", void 0);\n    _defineProperty(this, \"observableQuery\", void 0);\n    _defineProperty(this, \"incremental\", void 0);\n    /**\n    * @internal\n    * For feud-preventing behaviour, `lastWrite` should be shared by all `QueryInfo` instances of an `ObservableQuery`.\n    * In the case of a standalone `QueryInfo`, we will keep a local version.\n    * \n    * @deprecated This is an internal API and should not be used directly. This can be removed or changed at any time.\n    */\n    _defineProperty(this, \"_lastWrite\", void 0);\n    const cache = this.cache = queryManager.cache;\n    const id = (queryInfoIds.get(queryManager) || 0) + 1;\n    queryInfoIds.set(queryManager, id);\n    this.id = id + \"\";\n    this.observableQuery = observableQuery;\n    this.queryManager = queryManager;\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markQueryResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n  get lastWrite() {\n    return (this.observableQuery || this)._lastWrite;\n  }\n  set lastWrite(value) {\n    (this.observableQuery || this)._lastWrite = value;\n  }\n  resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n  shouldWrite(result, variables) {\n    var _result$extensions, _lastWrite$result$ext;\n    const {\n      lastWrite\n    } = this;\n    return !(lastWrite &&\n    // If cache.evict has been called since the last time we wrote this\n    // data into the cache, there's a chance writing this result into\n    // the cache will repair what was evicted.\n    lastWrite.dmCount === destructiveMethodCounts.get(this.cache) && equal(variables, lastWrite.variables) && equal(result.data, lastWrite.result.data) &&\n    // We have to compare these values because its possible the final chunk\n    // emitted in the incremental result is just `hasNext: false`. This\n    // ensures we trigger a cache write when we get `isLastChunk: true`.\n    ((_result$extensions = result.extensions) === null || _result$extensions === void 0 ? void 0 : _result$extensions[streamInfoSymbol]) === ((_lastWrite$result$ext = lastWrite.result.extensions) === null || _lastWrite$result$ext === void 0 ? void 0 : _lastWrite$result$ext[streamInfoSymbol]));\n  }\n  get hasNext() {\n    return this.incremental ? this.incremental.hasNext : false;\n  }\n  maybeHandleIncrementalResult(cacheData, incoming, query) {\n    const {\n      incrementalHandler\n    } = this.queryManager;\n    if (incrementalHandler.isIncrementalResult(incoming)) {\n      this.incremental || (this.incremental = incrementalHandler.startRequest({\n        query\n      }));\n      return this.incremental.handle(cacheData, incoming);\n    }\n    return incoming;\n  }\n  markQueryResult(incoming, _ref) {\n    var _this$observableQuery;\n    let {\n      document: query,\n      variables,\n      errorPolicy,\n      cacheWriteBehavior\n    } = _ref;\n    const diffOptions = {\n      query,\n      variables,\n      returnPartialData: true,\n      optimistic: true\n    };\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    (_this$observableQuery = this.observableQuery) === null || _this$observableQuery === void 0 || _this$observableQuery[\"resetNotifications\"]();\n    const skipCache = cacheWriteBehavior === 0 /* CacheWriteBehavior.FORBID */;\n    const lastDiff = skipCache ? undefined : this.cache.diff(diffOptions);\n    let result = this.maybeHandleIncrementalResult(lastDiff === null || lastDiff === void 0 ? void 0 : lastDiff.result, incoming, query);\n    if (skipCache) {\n      return result;\n    }\n    if (shouldWriteResult(result, errorPolicy)) {\n      // Using a transaction here so we have a chance to read the result\n      // back from the cache before the watch callback fires as a result\n      // of writeQuery, so we can store the new diff quietly and ignore\n      // it when we receive it redundantly from the watch callback.\n      this.cache.batch({\n        onWatchUpdated: (\n        // all additional options on ObservableQuery.CacheWatchOptions are\n        // optional so we can use the type here\n        watch, diff) => {\n          if (watch.watcher === this.observableQuery) {\n            // see comment on `lastOwnDiff` for explanation\n            watch.lastOwnDiff = diff;\n          }\n        },\n        update: cache => {\n          if (this.shouldWrite(result, variables)) {\n            cache.writeQuery({\n              query,\n              data: result.data,\n              variables,\n              overwrite: cacheWriteBehavior === 1 /* CacheWriteBehavior.OVERWRITE */,\n              extensions: result.extensions\n            });\n            this.lastWrite = {\n              result,\n              variables,\n              dmCount: destructiveMethodCounts.get(this.cache)\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (lastDiff && lastDiff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result = _objectSpread(_objectSpread({}, result), {}, {\n                data: lastDiff.result\n              });\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n          const diff = cache.diff(diffOptions);\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          if (diff.complete) {\n            result = _objectSpread(_objectSpread({}, result), {}, {\n              data: diff.result\n            });\n          }\n        }\n      });\n    } else {\n      this.lastWrite = void 0;\n    }\n    return result;\n  }\n  markMutationResult(incoming, mutation) {\n    let cache = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : this.cache;\n    const cacheWrites = [];\n    const skipCache = mutation.cacheWriteBehavior === 0 /* CacheWriteBehavior.FORBID */;\n    let result = this.maybeHandleIncrementalResult(skipCache ? undefined : cache.diff({\n      id: \"ROOT_MUTATION\",\n      // The cache complains if passed a mutation where it expects a\n      // query, so we transform mutations and subscriptions to queries\n      // (only once, thanks to this.transformCache).\n      query: this.queryManager.getDocumentInfo(mutation.document).asQuery,\n      variables: mutation.variables,\n      optimistic: false,\n      returnPartialData: true\n    }).result, incoming, mutation.document);\n    if (mutation.errorPolicy === \"ignore\") {\n      result = _objectSpread(_objectSpread({}, result), {}, {\n        errors: []\n      });\n    }\n    if (graphQLResultHasError(result) && mutation.errorPolicy === \"none\") {\n      return Promise.resolve(result);\n    }\n    const getResultWithDataState = () => _objectSpread(_objectSpread({}, result), {}, {\n      dataState: this.hasNext ? \"streaming\" : \"complete\"\n    });\n    if (!skipCache && shouldWriteResult(result, mutation.errorPolicy)) {\n      cacheWrites.push({\n        result: result.data,\n        dataId: \"ROOT_MUTATION\",\n        query: mutation.document,\n        variables: mutation.variables,\n        extensions: result.extensions\n      });\n      const {\n        updateQueries\n      } = mutation;\n      if (updateQueries) {\n        this.queryManager.getObservableQueries(\"all\").forEach(observableQuery => {\n          const queryName = observableQuery && observableQuery.queryName;\n          if (!queryName || !Object.hasOwnProperty.call(updateQueries, queryName)) {\n            return;\n          }\n          const updater = updateQueries[queryName];\n          const {\n            query: document,\n            variables\n          } = observableQuery;\n          // Read the current query result from the store.\n          const {\n            result: currentQueryResult,\n            complete\n          } = observableQuery.getCacheDiff({\n            optimistic: false\n          });\n          if (complete && currentQueryResult) {\n            // Run our reducer using the current query result and the mutation result.\n            const nextQueryResult = updater(currentQueryResult, {\n              mutationResult: getResultWithDataState(),\n              queryName: document && getOperationName(document) || void 0,\n              queryVariables: variables\n            });\n            // Write the modified result back into the store if we got a new result.\n            if (nextQueryResult) {\n              cacheWrites.push({\n                result: nextQueryResult,\n                dataId: \"ROOT_QUERY\",\n                query: document,\n                variables\n              });\n            }\n          }\n        });\n      }\n    }\n    let refetchQueries = mutation.refetchQueries;\n    if (typeof refetchQueries === \"function\") {\n      refetchQueries = refetchQueries(getResultWithDataState());\n    }\n    if (cacheWrites.length > 0 || (refetchQueries || \"\").length > 0 || mutation.update || mutation.onQueryUpdated || mutation.removeOptimistic) {\n      const results = [];\n      this.queryManager.refetchQueries({\n        updateCache: cache => {\n          if (!skipCache) {\n            cacheWrites.forEach(write => cache.write(write));\n          }\n          // If the mutation has some writes associated with it then we need to\n          // apply those writes to the store by running this reducer again with\n          // a write action.\n          const {\n            update\n          } = mutation;\n          // Determine whether result is a SingleExecutionResult,\n          // or the final ExecutionPatchResult.\n          if (update) {\n            if (!skipCache) {\n              // Re-read the ROOT_MUTATION data we just wrote into the cache\n              // (the first cache.write call in the cacheWrites.forEach loop\n              // above), so field read functions have a chance to run for\n              // fields within mutation result objects.\n              const diff = cache.diff({\n                id: \"ROOT_MUTATION\",\n                // The cache complains if passed a mutation where it expects a\n                // query, so we transform mutations and subscriptions to queries\n                // (only once, thanks to this.transformCache).\n                query: this.queryManager.getDocumentInfo(mutation.document).asQuery,\n                variables: mutation.variables,\n                optimistic: false,\n                returnPartialData: true\n              });\n              if (diff.complete) {\n                result = _objectSpread(_objectSpread({}, result), {}, {\n                  data: diff.result\n                });\n              }\n            }\n            // If we've received the whole response, call the update function.\n            if (!this.hasNext) {\n              update(cache, result, {\n                context: mutation.context,\n                variables: mutation.variables\n              });\n            }\n          }\n          // TODO Do this with cache.evict({ id: 'ROOT_MUTATION' }) but make it\n          // shallow to allow rolling back optimistic evictions.\n          if (!skipCache && !mutation.keepRootFields && !this.hasNext) {\n            cache.modify({\n              id: \"ROOT_MUTATION\",\n              fields(value, _ref2) {\n                let {\n                  fieldName,\n                  DELETE\n                } = _ref2;\n                return fieldName === \"__typename\" ? value : DELETE;\n              }\n            });\n          }\n        },\n        include: refetchQueries,\n        // Write the final mutation.result to the root layer of the cache.\n        optimistic: false,\n        // Remove the corresponding optimistic layer at the same time as we\n        // write the final non-optimistic result.\n        removeOptimistic: mutation.removeOptimistic,\n        // Let the caller of client.mutate optionally determine the refetching\n        // behavior for watched queries after the mutation.update function runs.\n        // If no onQueryUpdated function was provided for this mutation, pass\n        // null instead of undefined to disable the default refetching behavior.\n        onQueryUpdated: mutation.onQueryUpdated || null\n      }).forEach(result => results.push(result));\n      if (mutation.awaitRefetchQueries || mutation.onQueryUpdated) {\n        // Returning a promise here makes the mutation await that promise, so we\n        // include results in that promise's work if awaitRefetchQueries or an\n        // onQueryUpdated function was specified.\n        return Promise.all(results).then(() => result);\n      }\n    }\n    return Promise.resolve(result);\n  }\n  markMutationOptimistic(optimisticResponse, mutation) {\n    const data = typeof optimisticResponse === \"function\" ? optimisticResponse(mutation.variables, {\n      IGNORE\n    }) : optimisticResponse;\n    if (data === IGNORE) {\n      return false;\n    }\n    this.cache.recordOptimisticTransaction(cache => {\n      try {\n        this.markMutationResult({\n          data\n        }, mutation, cache);\n      } catch (error) {\n        invariant.error(error);\n      }\n    }, this.id);\n    return true;\n  }\n  markSubscriptionResult(result, _ref3) {\n    let {\n      document,\n      variables,\n      errorPolicy,\n      cacheWriteBehavior\n    } = _ref3;\n    if (cacheWriteBehavior !== 0 /* CacheWriteBehavior.FORBID */) {\n      if (shouldWriteResult(result, errorPolicy)) {\n        this.cache.write({\n          query: document,\n          result: result.data,\n          dataId: \"ROOT_SUBSCRIPTION\",\n          variables: variables,\n          extensions: result.extensions\n        });\n      }\n      this.queryManager.broadcastQueries();\n    }\n  }\n}\nfunction shouldWriteResult(result) {\n  let errorPolicy = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"none\";\n  const ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}","map":{"version":3,"names":["equal","getOperationName","graphQLResultHasError","streamInfoSymbol","invariant","IGNORE","destructiveMethodCounts","WeakMap","wrapDestructiveCacheMethod","cache","methodName","original","set","get","apply","arguments","queryInfoIds","QueryInfo","constructor","queryManager","observableQuery","_defineProperty","id","has","lastWrite","_lastWrite","value","resetLastWrite","shouldWrite","result","variables","_result$extensions","_lastWrite$result$ext","dmCount","data","extensions","hasNext","incremental","maybeHandleIncrementalResult","cacheData","incoming","query","incrementalHandler","isIncrementalResult","startRequest","handle","markQueryResult","_ref","_this$observableQuery","document","errorPolicy","cacheWriteBehavior","diffOptions","returnPartialData","optimistic","skipCache","lastDiff","undefined","diff","shouldWriteResult","batch","onWatchUpdated","watch","watcher","lastOwnDiff","update","writeQuery","overwrite","complete","_objectSpread","markMutationResult","mutation","length","cacheWrites","getDocumentInfo","asQuery","errors","Promise","resolve","getResultWithDataState","dataState","push","dataId","updateQueries","getObservableQueries","forEach","queryName","Object","hasOwnProperty","call","updater","currentQueryResult","getCacheDiff","nextQueryResult","mutationResult","queryVariables","refetchQueries","onQueryUpdated","removeOptimistic","results","updateCache","write","context","keepRootFields","modify","fields","_ref2","fieldName","DELETE","include","awaitRefetchQueries","all","then","markMutationOptimistic","optimisticResponse","recordOptimisticTransaction","error","markSubscriptionResult","_ref3","broadcastQueries","ignoreErrors","writeWithErrors"],"sources":["/home/zobair-qauomi/todo_app/node_modules/@apollo/src/core/QueryInfo.ts"],"sourcesContent":["import { equal } from \"@wry/equality\";\nimport type { DocumentNode, FormattedExecutionResult } from \"graphql\";\n\nimport type { ApolloCache, Cache } from \"@apollo/client/cache\";\nimport type { IgnoreModifier } from \"@apollo/client/cache\";\nimport type { Incremental } from \"@apollo/client/incremental\";\nimport type { ApolloLink } from \"@apollo/client/link\";\nimport type { Unmasked } from \"@apollo/client/masking\";\nimport type { DeepPartial } from \"@apollo/client/utilities\";\nimport type { ExtensionsWithStreamInfo } from \"@apollo/client/utilities/internal\";\nimport {\n  getOperationName,\n  graphQLResultHasError,\n  streamInfoSymbol,\n} from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\n\nimport type { ApolloClient } from \"./ApolloClient.js\";\nimport type { ObservableQuery } from \"./ObservableQuery.js\";\nimport type { QueryManager } from \"./QueryManager.js\";\nimport type {\n  DataValue,\n  DefaultContext,\n  InternalRefetchQueriesInclude,\n  MutationQueryReducer,\n  MutationUpdaterFunction,\n  NormalizedExecutionResult,\n  OnQueryUpdated,\n  OperationVariables,\n  TypedDocumentNode,\n} from \"./types.js\";\nimport type { ErrorPolicy } from \"./watchQueryOptions.js\";\n\ntype UpdateQueries<TData> = ApolloClient.MutateOptions<\n  TData,\n  any,\n  any\n>[\"updateQueries\"];\n\nconst IGNORE = {} as IgnoreModifier;\n\nexport const enum CacheWriteBehavior {\n  FORBID,\n  OVERWRITE,\n  MERGE,\n}\n\ninterface LastWrite {\n  result: FormattedExecutionResult<any, ExtensionsWithStreamInfo>;\n  variables: ApolloClient.WatchQueryOptions[\"variables\"];\n  dmCount: number | undefined;\n}\n\nconst destructiveMethodCounts = new WeakMap<ApolloCache, number>();\n\ninterface OperationInfo<\n  TData,\n  TVariables extends OperationVariables,\n  AllowedCacheWriteBehavior = CacheWriteBehavior,\n> {\n  document: DocumentNode | TypedDocumentNode<TData, TVariables>;\n  variables: TVariables;\n  errorPolicy: ErrorPolicy;\n  cacheWriteBehavior: AllowedCacheWriteBehavior;\n}\n\nfunction wrapDestructiveCacheMethod(\n  cache: ApolloCache,\n  methodName: \"evict\" | \"modify\" | \"reset\"\n) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    // @ts-expect-error this is just too generic to be typed correctly\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(\n        cache,\n        // The %1e15 allows the count to wrap around to 0 safely every\n        // quadrillion evictions, so there's no risk of overflow. To be\n        // clear, this is more of a pedantic principle than something\n        // that matters in any conceivable practical scenario.\n        (destructiveMethodCounts.get(cache)! + 1) % 1e15\n      );\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\n\nconst queryInfoIds = new WeakMap<QueryManager, number>();\n\n// A QueryInfo object represents a single network request, either initiated\n// from the QueryManager or from an ObservableQuery.\n// It will only ever be used for a single network call.\n// It is responsible for reporting results to the cache, merging and in a no-cache\n// scenario accumulating the response.\nexport class QueryInfo<\n  TData,\n  TVariables extends OperationVariables = OperationVariables,\n  TCache extends ApolloCache = ApolloCache,\n> {\n  // TODO remove soon - this should be able to be handled by cancelling old operations before starting new ones\n  lastRequestId = 1;\n\n  private cache: TCache;\n  private queryManager: Pick<\n    QueryManager,\n    | \"getObservableQueries\"\n    | \"refetchQueries\"\n    | \"getDocumentInfo\"\n    | \"broadcastQueries\"\n    | \"incrementalHandler\"\n  >;\n  public readonly id: string;\n  private readonly observableQuery?: ObservableQuery<any, any>;\n  private incremental?: Incremental.IncrementalRequest<\n    Record<string, unknown>,\n    DataValue.Complete<TData> | DataValue.Streaming<TData>\n  >;\n\n  constructor(\n    queryManager: QueryManager,\n    observableQuery?: ObservableQuery<any, any>\n  ) {\n    const cache = (this.cache = queryManager.cache as TCache);\n    const id = (queryInfoIds.get(queryManager) || 0) + 1;\n    queryInfoIds.set(queryManager, id);\n    this.id = id + \"\";\n    this.observableQuery = observableQuery;\n    this.queryManager = queryManager;\n\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markQueryResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n\n  /**\n   * @internal\n   * For feud-preventing behaviour, `lastWrite` should be shared by all `QueryInfo` instances of an `ObservableQuery`.\n   * In the case of a standalone `QueryInfo`, we will keep a local version.\n   */\n  public _lastWrite?: LastWrite;\n  private get lastWrite(): LastWrite | undefined {\n    return (this.observableQuery || this)._lastWrite as LastWrite | undefined;\n  }\n  private set lastWrite(value: LastWrite | undefined) {\n    (this.observableQuery || this)._lastWrite = value;\n  }\n\n  public resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n\n  private shouldWrite(\n    result: FormattedExecutionResult<any, ExtensionsWithStreamInfo>,\n    variables: ApolloClient.WatchQueryOptions[\"variables\"]\n  ) {\n    const { lastWrite } = this;\n    return !(\n      lastWrite &&\n      // If cache.evict has been called since the last time we wrote this\n      // data into the cache, there's a chance writing this result into\n      // the cache will repair what was evicted.\n      lastWrite.dmCount === destructiveMethodCounts.get(this.cache) &&\n      equal(variables, lastWrite.variables) &&\n      equal(result.data, lastWrite.result.data) &&\n      // We have to compare these values because its possible the final chunk\n      // emitted in the incremental result is just `hasNext: false`. This\n      // ensures we trigger a cache write when we get `isLastChunk: true`.\n      result.extensions?.[streamInfoSymbol] ===\n        lastWrite.result.extensions?.[streamInfoSymbol]\n    );\n  }\n\n  get hasNext() {\n    return this.incremental ? this.incremental.hasNext : false;\n  }\n\n  private maybeHandleIncrementalResult(\n    cacheData: TData | DeepPartial<TData> | undefined | null,\n    incoming: ApolloLink.Result<TData>,\n    query: DocumentNode\n  ): FormattedExecutionResult<\n    DataValue.Complete<TData> | DataValue.Streaming<TData>,\n    ExtensionsWithStreamInfo\n  > {\n    const { incrementalHandler } = this.queryManager;\n\n    if (incrementalHandler.isIncrementalResult(incoming)) {\n      this.incremental ||= incrementalHandler.startRequest<\n        TData & Record<string, unknown>\n      >({\n        query,\n      }) as Incremental.IncrementalRequest<\n        Record<string, unknown>,\n        DataValue.Complete<TData> | DataValue.Streaming<TData>\n      >;\n\n      return this.incremental.handle(cacheData, incoming);\n    }\n    return incoming;\n  }\n\n  public markQueryResult(\n    incoming: ApolloLink.Result<TData>,\n    {\n      document: query,\n      variables,\n      errorPolicy,\n      cacheWriteBehavior,\n    }: OperationInfo<TData, TVariables>\n  ): FormattedExecutionResult<\n    DataValue.Complete<TData> | DataValue.Streaming<TData>,\n    ExtensionsWithStreamInfo\n  > {\n    const diffOptions = {\n      query,\n      variables,\n      returnPartialData: true,\n      optimistic: true,\n    };\n\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.observableQuery?.[\"resetNotifications\"]();\n\n    const skipCache = cacheWriteBehavior === CacheWriteBehavior.FORBID;\n    const lastDiff =\n      skipCache ? undefined : this.cache.diff<TData>(diffOptions);\n\n    let result = this.maybeHandleIncrementalResult(\n      lastDiff?.result,\n      incoming,\n      query\n    );\n    if (skipCache) {\n      return result;\n    }\n\n    if (shouldWriteResult(result, errorPolicy)) {\n      // Using a transaction here so we have a chance to read the result\n      // back from the cache before the watch callback fires as a result\n      // of writeQuery, so we can store the new diff quietly and ignore\n      // it when we receive it redundantly from the watch callback.\n      this.cache.batch({\n        onWatchUpdated: (\n          // all additional options on ObservableQuery.CacheWatchOptions are\n          // optional so we can use the type here\n          watch: ObservableQuery.CacheWatchOptions,\n          diff\n        ) => {\n          if (watch.watcher === this.observableQuery) {\n            // see comment on `lastOwnDiff` for explanation\n            watch.lastOwnDiff = diff;\n          }\n        },\n        update: (cache) => {\n          if (this.shouldWrite(result, variables)) {\n            cache.writeQuery({\n              query,\n              data: result.data as Unmasked<any>,\n              variables,\n              overwrite: cacheWriteBehavior === CacheWriteBehavior.OVERWRITE,\n              extensions: result.extensions,\n            });\n\n            this.lastWrite = {\n              result,\n              variables,\n              dmCount: destructiveMethodCounts.get(this.cache),\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (lastDiff && lastDiff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result = { ...result, data: lastDiff.result };\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n\n          const diff = cache.diff<TData>(diffOptions);\n\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          if (diff.complete) {\n            result = { ...result, data: diff.result };\n          }\n        },\n      });\n    } else {\n      this.lastWrite = void 0;\n    }\n\n    return result;\n  }\n\n  public markMutationResult(\n    incoming: ApolloLink.Result<TData>,\n    mutation: OperationInfo<\n      TData,\n      TVariables,\n      CacheWriteBehavior.FORBID | CacheWriteBehavior.MERGE\n    > & {\n      context?: DefaultContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TCache>;\n      awaitRefetchQueries?: boolean;\n      refetchQueries?:\n        | ((\n            result: NormalizedExecutionResult<Unmasked<TData>>\n          ) => InternalRefetchQueriesInclude)\n        | InternalRefetchQueriesInclude;\n      removeOptimistic?: string;\n      onQueryUpdated?: OnQueryUpdated<any>;\n      keepRootFields?: boolean;\n    },\n    cache = this.cache\n  ): Promise<\n    FormattedExecutionResult<\n      DataValue.Complete<TData> | DataValue.Streaming<TData>,\n      ExtensionsWithStreamInfo\n    >\n  > {\n    const cacheWrites: Cache.WriteOptions[] = [];\n    const skipCache = mutation.cacheWriteBehavior === CacheWriteBehavior.FORBID;\n\n    let result = this.maybeHandleIncrementalResult(\n      skipCache ? undefined : (\n        cache.diff<TData>({\n          id: \"ROOT_MUTATION\",\n          // The cache complains if passed a mutation where it expects a\n          // query, so we transform mutations and subscriptions to queries\n          // (only once, thanks to this.transformCache).\n          query: this.queryManager.getDocumentInfo(mutation.document).asQuery,\n          variables: mutation.variables,\n          optimistic: false,\n          returnPartialData: true,\n        }).result\n      ),\n      incoming,\n      mutation.document\n    );\n\n    if (mutation.errorPolicy === \"ignore\") {\n      result = { ...result, errors: [] };\n    }\n\n    if (graphQLResultHasError(result) && mutation.errorPolicy === \"none\") {\n      return Promise.resolve(result);\n    }\n\n    const getResultWithDataState = () =>\n      ({\n        ...result,\n        dataState: this.hasNext ? \"streaming\" : \"complete\",\n      }) as NormalizedExecutionResult<Unmasked<TData>>;\n\n    if (!skipCache && shouldWriteResult(result, mutation.errorPolicy)) {\n      cacheWrites.push({\n        result: result.data,\n        dataId: \"ROOT_MUTATION\",\n        query: mutation.document,\n        variables: mutation.variables,\n        extensions: result.extensions,\n      });\n\n      const { updateQueries } = mutation;\n      if (updateQueries) {\n        this.queryManager\n          .getObservableQueries(\"all\")\n          .forEach((observableQuery) => {\n            const queryName = observableQuery && observableQuery.queryName;\n            if (\n              !queryName ||\n              !Object.hasOwnProperty.call(updateQueries, queryName)\n            ) {\n              return;\n            }\n            const updater = updateQueries[queryName];\n            const { query: document, variables } = observableQuery;\n\n            // Read the current query result from the store.\n            const { result: currentQueryResult, complete } =\n              observableQuery.getCacheDiff({ optimistic: false });\n\n            if (complete && currentQueryResult) {\n              // Run our reducer using the current query result and the mutation result.\n              const nextQueryResult = (updater as MutationQueryReducer<any>)(\n                currentQueryResult,\n                {\n                  mutationResult: getResultWithDataState(),\n                  queryName: (document && getOperationName(document)) || void 0,\n                  queryVariables: variables!,\n                }\n              );\n\n              // Write the modified result back into the store if we got a new result.\n              if (nextQueryResult) {\n                cacheWrites.push({\n                  result: nextQueryResult,\n                  dataId: \"ROOT_QUERY\",\n                  query: document!,\n                  variables,\n                });\n              }\n            }\n          });\n      }\n    }\n\n    let refetchQueries = mutation.refetchQueries;\n    if (typeof refetchQueries === \"function\") {\n      refetchQueries = refetchQueries(getResultWithDataState());\n    }\n\n    if (\n      cacheWrites.length > 0 ||\n      (refetchQueries || \"\").length > 0 ||\n      mutation.update ||\n      mutation.onQueryUpdated ||\n      mutation.removeOptimistic\n    ) {\n      const results: any[] = [];\n\n      this.queryManager\n        .refetchQueries({\n          updateCache: (cache) => {\n            if (!skipCache) {\n              cacheWrites.forEach((write) => cache.write(write));\n            }\n\n            // If the mutation has some writes associated with it then we need to\n            // apply those writes to the store by running this reducer again with\n            // a write action.\n            const { update } = mutation;\n            // Determine whether result is a SingleExecutionResult,\n            // or the final ExecutionPatchResult.\n\n            if (update) {\n              if (!skipCache) {\n                // Re-read the ROOT_MUTATION data we just wrote into the cache\n                // (the first cache.write call in the cacheWrites.forEach loop\n                // above), so field read functions have a chance to run for\n                // fields within mutation result objects.\n                const diff = cache.diff<TData>({\n                  id: \"ROOT_MUTATION\",\n                  // The cache complains if passed a mutation where it expects a\n                  // query, so we transform mutations and subscriptions to queries\n                  // (only once, thanks to this.transformCache).\n                  query: this.queryManager.getDocumentInfo(mutation.document)\n                    .asQuery,\n                  variables: mutation.variables,\n                  optimistic: false,\n                  returnPartialData: true,\n                });\n\n                if (diff.complete) {\n                  result = {\n                    ...result,\n                    data: diff.result,\n                  };\n                }\n              }\n\n              // If we've received the whole response, call the update function.\n              if (!this.hasNext) {\n                update(\n                  cache as TCache,\n                  result as FormattedExecutionResult<Unmasked<TData>>,\n                  {\n                    context: mutation.context,\n                    variables: mutation.variables,\n                  }\n                );\n              }\n            }\n\n            // TODO Do this with cache.evict({ id: 'ROOT_MUTATION' }) but make it\n            // shallow to allow rolling back optimistic evictions.\n            if (!skipCache && !mutation.keepRootFields && !this.hasNext) {\n              cache.modify({\n                id: \"ROOT_MUTATION\",\n                fields(value, { fieldName, DELETE }) {\n                  return fieldName === \"__typename\" ? value : DELETE;\n                },\n              });\n            }\n          },\n\n          include: refetchQueries,\n\n          // Write the final mutation.result to the root layer of the cache.\n          optimistic: false,\n\n          // Remove the corresponding optimistic layer at the same time as we\n          // write the final non-optimistic result.\n          removeOptimistic: mutation.removeOptimistic,\n\n          // Let the caller of client.mutate optionally determine the refetching\n          // behavior for watched queries after the mutation.update function runs.\n          // If no onQueryUpdated function was provided for this mutation, pass\n          // null instead of undefined to disable the default refetching behavior.\n          onQueryUpdated: mutation.onQueryUpdated || null,\n        })\n        .forEach((result) => results.push(result));\n\n      if (mutation.awaitRefetchQueries || mutation.onQueryUpdated) {\n        // Returning a promise here makes the mutation await that promise, so we\n        // include results in that promise's work if awaitRefetchQueries or an\n        // onQueryUpdated function was specified.\n        return Promise.all(results).then(() => result);\n      }\n    }\n\n    return Promise.resolve(result);\n  }\n\n  public markMutationOptimistic(\n    optimisticResponse: any,\n    mutation: OperationInfo<\n      TData,\n      TVariables,\n      CacheWriteBehavior.FORBID | CacheWriteBehavior.MERGE\n    > & {\n      context?: DefaultContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TCache>;\n      keepRootFields?: boolean;\n    }\n  ) {\n    const data =\n      typeof optimisticResponse === \"function\" ?\n        optimisticResponse(mutation.variables, { IGNORE })\n      : optimisticResponse;\n\n    if (data === IGNORE) {\n      return false;\n    }\n\n    this.cache.recordOptimisticTransaction((cache) => {\n      try {\n        this.markMutationResult({ data }, mutation, cache as TCache);\n      } catch (error) {\n        invariant.error(error);\n      }\n    }, this.id);\n\n    return true;\n  }\n\n  public markSubscriptionResult(\n    result: FormattedExecutionResult<TData>,\n    {\n      document,\n      variables,\n      errorPolicy,\n      cacheWriteBehavior,\n    }: OperationInfo<\n      TData,\n      TVariables,\n      CacheWriteBehavior.FORBID | CacheWriteBehavior.MERGE\n    >\n  ) {\n    if (cacheWriteBehavior !== CacheWriteBehavior.FORBID) {\n      if (shouldWriteResult(result, errorPolicy)) {\n        this.cache.write({\n          query: document,\n          result: result.data as any,\n          dataId: \"ROOT_SUBSCRIPTION\",\n          variables: variables,\n          extensions: result.extensions,\n        });\n      }\n\n      this.queryManager.broadcastQueries();\n    }\n  }\n}\n\nfunction shouldWriteResult<T>(\n  result: FormattedExecutionResult<T>,\n  errorPolicy: ErrorPolicy = \"none\"\n) {\n  const ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}\n"],"mappings":";;AAAA,SAASA,KAAT,QAAsB,eAAe;AAUrC,SACEC,gBAAgB,EAChBC,qBAAqB,EACrBC,gBAAgB,QACX,mCAAmC;AAC1C,SAASC,SAAT,QAA0B,oCAAoC;AAwB9D,MAAMC,MAAN,GAAe,CAAf,CAAmC;AAcnC,MAAMC,uBAAN,GAAgC,IAAIC,OAAO,CAA3C,CAAkE;AAalE,SAASC,0BAA0BA,CACjCC,KAAkB,EAClBC,UAAwC,EAF1C;EAIE,MAAMC,QAAR,GAAmBF,KAAK,CAACC,UAAU,CAAC;EAClC,IAAI,OAAOC,QAAb,KAA0B,UAAU,EAAE;IAClC;IACAF,KAAK,CAACC,UAAU,IAAI,YAAxB;MACMJ,uBAAuB,CAACM,GAAG,CACzBH,KAAK;MACL;MACA;MACA;MACA;MACA,CAACH,uBAAuB,CAACO,GAAG,CAACJ,KAAK,IAAK,CAAC,IAAI,IAAI,CACjD;MACD;MACA,OAAOE,QAAQ,CAACG,KAAK,CAAC,IAAI,EAAEC,SAAS,CAAC;IACxC,CAAC;EACH;AACF;AAEA,MAAMC,YAAN,GAAqB,IAAIT,OAAO,CAAhC,CAAwD;AAExD;AACA;AACA;AACA;AACA;AACA,aAAaU,SAAb;EAwBEC,WAAFA,CACIC,YAA0B,EAC1BC,eAA2C,EAF/C;IAnBE;IAAAC,eAAA,wBACgB,CAAC;IAAAA,eAAA;IAAAA,eAAA;IAAAA,eAAA;IAAAA,eAAA;IAAAA,eAAA;;;;;;;;;IAsBf,MAAMZ,KAAV,GAAmB,IAAI,CAACA,KAAxB,GAAgCU,YAAY,CAACV,KAAgB;IACzD,MAAMa,EAAV,GAAe,CAACN,YAAY,CAACH,GAAG,CAACM,YAAY,KAAK,CAAC,IAAI,CAAC;IACpDH,YAAY,CAACJ,GAAG,CAACO,YAAY,EAAEG,EAAE,CAAC;IAClC,IAAI,CAACA,EAAT,GAAcA,EAAd,GAAmB,EAAE;IACjB,IAAI,CAACF,eAAT,GAA2BA,eAAe;IACtC,IAAI,CAACD,YAAT,GAAwBA,YAAY;IAEhC;IACA;IACA;IACA;IACA;IACA,IAAI,CAACb,uBAAuB,CAACiB,GAAG,CAACd,KAAK,CAAC,EAAE;MACvCH,uBAAuB,CAACM,GAAG,CAACH,KAAK,EAAE,CAAC,CAAC;MACrCD,0BAA0B,CAACC,KAAK,EAAE,OAAO,CAAC;MAC1CD,0BAA0B,CAACC,KAAK,EAAE,QAAQ,CAAC;MAC3CD,0BAA0B,CAACC,KAAK,EAAE,OAAO,CAAC;IAC5C;EACF;EAQA,IAAYe,SAASA,CAAA,EAAvB;IACI,OAAO,CAAC,IAAI,CAACJ,eAAjB,IAAoC,IAAI,EAAEK,UAAmC;EAC3E;EACA,IAAYD,SAASA,CAACE,KAA4B,EAApD;IACI,CAAC,IAAI,CAACN,eAAV,IAA6B,IAAI,EAAEK,UAAnC,GAAgDC,KAAK;EACnD;EAEOC,cAAcA,CAAA,EAAvB;IACI,IAAI,CAACH,SAAT,GAAqB,KAAK,CAAC;EACzB;EAEQI,WAAWA,CACjBC,MAA+D,EAC/DC,SAAsD,EAF1D;IAAA,IAAAC,kBAAA,EAAAC,qBAAA;IAII,MAAM;MAAER;IAAZ,IAA0B,IAAI;IAC1B,OAAO,EACLA,SADN;IAEM;IACA;IACA;IACAA,SAAS,CAACS,OAAhB,KAA4B3B,uBAAuB,CAACO,GAAG,CAAC,IAAI,CAACJ,KAAK,KAC5DT,KAAK,CAAC8B,SAAS,EAAEN,SAAS,CAACM,SAAS,KACpC9B,KAAK,CAAC6B,MAAM,CAACK,IAAI,EAAEV,SAAS,CAACK,MAAM,CAACK,IAAI;IACxC;IACA;IACA;IACA,EAAAH,kBAAA,GAAAF,MAAM,CAACM,UAAU,cAAAJ,kBAAA,uBAAjBA,kBAAA,CAAoB5B,gBAAgB,SAAA6B,qBAAA,GAClCR,SAAS,CAACK,MAAM,CAACM,UAAU,cAAAH,qBAAA,uBAA3BA,qBAAA,CAA8B7B,gBAAgB,CAAC,EAClD;EACH;EAEA,IAAIiC,OAAOA,CAAA,EAAb;IACI,OAAO,IAAI,CAACC,WAAhB,GAA8B,IAAI,CAACA,WAAW,CAACD,OAA/C,GAAyD,KAAK;EAC5D;EAEQE,4BAA4BA,CAClCC,SAAwD,EACxDC,QAAkC,EAClCC,KAAmB,EAHvB;IAQI,MAAM;MAAEC;IAAZ,IAAmC,IAAI,CAACvB,YAAY;IAEhD,IAAIuB,kBAAkB,CAACC,mBAAmB,CAACH,QAAQ,CAAC,EAAE;MACpD,IAAI,CAACH,WAAX,KAAM,IAAI,CAACA,WAAX,GAA2BK,kBAAkB,CAACE,YAAY,CAElD;QACAH;MACR,CAAO,CAGA;MAED,OAAO,IAAI,CAACJ,WAAW,CAACQ,MAAM,CAACN,SAAS,EAAEC,QAAQ,CAAC;IACrD;IACA,OAAOA,QAAQ;EACjB;EAEOM,eAAeA,CACpBN,QAAkC,EAAAO,IAAA,EADtC;IAAA,IAAAC,qBAAA;IAAA,IAEI;MACEC,QAAQ,EAAER,KAAK;MACfX,SAAS;MACToB,WAAW;MACXC;IANN,CAOuC,GAAAJ,IAAA;IAKnC,MAAMK,WAAV,GAAwB;MAClBX,KAAK;MACLX,SAAS;MACTuB,iBAAiB,EAAE,IAAI;MACvBC,UAAU,EAAE;IAClB,CAAK;IAED;IACA;IACA,CAAAN,qBAAA,OAAI,CAAC5B,eAAe,cAAA4B,qBAAA,eAApBA,qBAAA,CAAuB,oBAAoB,CAAC,CAAhD,CAAkD;IAE9C,MAAMO,SAAV,GAAsBJ,kBAAtB;IACI,MAAMK,QAAV,GACMD,SADN,GACkBE,SADlB,GAC8B,IAAI,CAAChD,KAAK,CAACiD,IAAI,CAAQN,WAAW,CAAC;IAE7D,IAAIvB,MAAR,GAAiB,IAAI,CAACS,4BAA4B,CAC5CkB,QAAQ,aAARA,QAAQ,uBAARA,QAAQ,CAAE3B,MAAM,EAChBW,QAAQ,EACRC,KAAK,CACN;IACD,IAAIc,SAAS,EAAE;MACb,OAAO1B,MAAM;IACf;IAEA,IAAI8B,iBAAiB,CAAC9B,MAAM,EAAEqB,WAAW,CAAC,EAAE;MAC1C;MACA;MACA;MACA;MACA,IAAI,CAACzC,KAAK,CAACmD,KAAK,CAAC;QACfC,cAAc,EAAEA;QACd;QACA;QACAC,KAAwC,EACxCJ,IAAI,KADd;UAGU,IAAII,KAAK,CAACC,OAApB,KAAgC,IAAI,CAAC3C,eAAe,EAAE;YAC1C;YACA0C,KAAK,CAACE,WAAlB,GAAgCN,IAAI;UAC1B;QACF,CAAC;QACDO,MAAM,EAAGxD,KAAK,IAAtB;UACU,IAAI,IAAI,CAACmB,WAAW,CAACC,MAAM,EAAEC,SAAS,CAAC,EAAE;YACvCrB,KAAK,CAACyD,UAAU,CAAC;cACfzB,KAAK;cACLP,IAAI,EAAEL,MAAM,CAACK,IAAqB;cAClCJ,SAAS;cACTqC,SAAS,EAAEhB,kBAAzB;cACchB,UAAU,EAAEN,MAAM,CAACM;YACjC,CAAa,CAAC;YAEF,IAAI,CAACX,SAAjB,GAA6B;cACfK,MAAM;cACNC,SAAS;cACTG,OAAO,EAAE3B,uBAAuB,CAACO,GAAG,CAAC,IAAI,CAACJ,KAAK;YAC7D,CAAa;UACH,OAAO;YACL;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA,IAAI+C,QAAhB,IAA4BA,QAAQ,CAACY,QAAQ,EAAE;cACjC;cACA;cACAvC,MAAd,GAAAwC,aAAA,CAAAA,aAAA,KAA4BxC,MAAM;gBAAEK,IAAI,EAAEsB,QAAQ,CAAC3B;cAAnD,EAA2D;cAC7C;YACF;YACA;YACA;UACF;UAEA,MAAM6B,IAAhB,GAAuBjD,KAAK,CAACiD,IAAI,CAAQN,WAAW,CAAC;UAE3C;UACA;UACA;UACA;UACA;UACA,IAAIM,IAAI,CAACU,QAAQ,EAAE;YACjBvC,MAAZ,GAAAwC,aAAA,CAAAA,aAAA,KAA0BxC,MAAM;cAAEK,IAAI,EAAEwB,IAAI,CAAC7B;YAA7C,EAAqD;UAC3C;QACF;MACR,CAAO,CAAC;IACJ,OAAO;MACL,IAAI,CAACL,SAAX,GAAuB,KAAK,CAAC;IACzB;IAEA,OAAOK,MAAM;EACf;EAEOyC,kBAAkBA,CACvB9B,QAAkC,EAClC+B,QAiBC,EAnBL;IAAA,IAoBI9D,KApBJ,GAAAM,SAAA,CAAAyD,MAAA,QAAAzD,SAAA,QAAA0C,SAAA,GAAA1C,SAAA,MAoBY,IAAI,CAACN,KAAK;IAOlB,MAAMgE,WAAV,GAA8C,EAAE;IAC5C,MAAMlB,SAAV,GAAsBgB,QAAQ,CAACpB,kBAA/B;IAEI,IAAItB,MAAR,GAAiB,IAAI,CAACS,4BAA4B,CAC5CiB,SADN,GACkBE,SADlB,GAEQhD,KAAK,CAACiD,IAAI,CAAQ;MAChBpC,EAAE,EAAE,eAAe;MACnB;MACA;MACA;MACAmB,KAAK,EAAE,IAAI,CAACtB,YAAY,CAACuD,eAAe,CAACH,QAAQ,CAACtB,QAAQ,CAAC,CAAC0B,OAAO;MACnE7C,SAAS,EAAEyC,QAAQ,CAACzC,SAAS;MAC7BwB,UAAU,EAAE,KAAK;MACjBD,iBAAiB,EAAE;IAC7B,CAAS,CAAC,CAACxB,MACJ,EACDW,QAAQ,EACR+B,QAAQ,CAACtB,QAAQ,CAClB;IAED,IAAIsB,QAAQ,CAACrB,WAAjB,KAAiC,QAAQ,EAAE;MACrCrB,MAAN,GAAAwC,aAAA,CAAAA,aAAA,KAAoBxC,MAAM;QAAE+C,MAAM,EAAE;MAApC,EAAwC;IACpC;IAEA,IAAI1E,qBAAqB,CAAC2B,MAAM,KAAK0C,QAAQ,CAACrB,WAAlD,KAAkE,MAAM,EAAE;MACpE,OAAO2B,OAAO,CAACC,OAAO,CAACjD,MAAM,CAAC;IAChC;IAEA,MAAMkD,sBAAV,GAAmCA,CAAA,KAAAV,aAAA,CAAAA,aAAA,KAExBxC,MAAM;MACTmD,SAAS,EAAE,IAAI,CAAC5C,OAAxB,GAAkC,WAAlC,GAAgD;IAAU,EACJ;IAElD,IAAI,CAACmB,SAAT,IAAsBI,iBAAiB,CAAC9B,MAAM,EAAE0C,QAAQ,CAACrB,WAAW,CAAC,EAAE;MACjEuB,WAAW,CAACQ,IAAI,CAAC;QACfpD,MAAM,EAAEA,MAAM,CAACK,IAAI;QACnBgD,MAAM,EAAE,eAAe;QACvBzC,KAAK,EAAE8B,QAAQ,CAACtB,QAAQ;QACxBnB,SAAS,EAAEyC,QAAQ,CAACzC,SAAS;QAC7BK,UAAU,EAAEN,MAAM,CAACM;MAC3B,CAAO,CAAC;MAEF,MAAM;QAAEgD;MAAd,IAAgCZ,QAAQ;MAClC,IAAIY,aAAa,EAAE;QACjB,IAAI,CAAChE,YAAb,CACWiE,oBAAoB,CAAC,KAAK,EAC1BC,OAAO,CAAEjE,eAAe,IAAnC;UACY,MAAMkE,SAAlB,GAA8BlE,eAA9B,IAAiDA,eAAe,CAACkE,SAAS;UAC9D,IACE,CAACA,SADf,IAEc,CAACC,MAAM,CAACC,cAAc,CAACC,IAAI,CAACN,aAAa,EAAEG,SAAS,CAAC,EACrD;YACA;UACF;UACA,MAAMI,OAAlB,GAA4BP,aAAa,CAACG,SAAS,CAAC;UACxC,MAAM;YAAE7C,KAAK,EAAEQ,QAAQ;YAAEnB;UAArC,IAAmDV,eAAe;UAEtD;UACA,MAAM;YAAES,MAAM,EAAE8D,kBAAkB;YAAEvB;UAAhD,IACchD,eAAe,CAACwE,YAAY,CAAC;YAAEtC,UAAU,EAAE;UADzD,CACgE,CAAC;UAErD,IAAIc,QAAhB,IAA4BuB,kBAAkB,EAAE;YAClC;YACA,MAAME,eAApB,GAAuCH,OAAqC,CAC5DC,kBAAkB,EAClB;cACEG,cAAc,EAAEf,sBAAsB,CAAxD,CAA0D;cACxCO,SAAS,EAAGrC,QAA9B,IAA0ChD,gBAAgB,CAACgD,QAAQ,CAAC,IAAK,KAAK,CAAC;cAC7D8C,cAAc,EAAEjE;YAClC,CAAiB,CACF;YAED;YACA,IAAI+D,eAAe,EAAE;cACnBpB,WAAW,CAACQ,IAAI,CAAC;gBACfpD,MAAM,EAAEgE,eAAe;gBACvBX,MAAM,EAAE,YAAY;gBACpBzC,KAAK,EAAEQ,QAAS;gBAChBnB;cAClB,CAAiB,CAAC;YACJ;UACF;QACF,CAAC,CAAC;MACN;IACF;IAEA,IAAIkE,cAAR,GAAyBzB,QAAQ,CAACyB,cAAc;IAC5C,IAAI,OAAOA,cAAf,KAAkC,UAAU,EAAE;MACxCA,cAAN,GAAuBA,cAAc,CAACjB,sBAAsB,CAA5D,CAA8D,CAAC;IAC3D;IAEA,IACEN,WAAW,CAACD,MADlB,GAC2B,KACrB,CAACwB,cAAP,IAAyB,EAAE,EAAExB,MAA7B,GAAsC,KAChCD,QAAQ,CAACN,MAAf,IACMM,QAAQ,CAAC0B,cAAf,IACM1B,QAAQ,CAAC2B,gBAAgB,EACzB;MACA,MAAMC,OAAZ,GAA6B,EAAE;MAEzB,IAAI,CAAChF,YAAX,CACS6E,cAAc,CAAC;QACdI,WAAW,EAAG3F,KAAK,IAA7B;UACY,IAAI,CAAC8C,SAAS,EAAE;YACdkB,WAAW,CAACY,OAAO,CAAEgB,KAAK,IAAK5F,KAAK,CAAC4F,KAAK,CAACA,KAAK,CAAC,CAAC;UACpD;UAEA;UACA;UACA;UACA,MAAM;YAAEpC;UAApB,IAA+BM,QAAQ;UAC3B;UACA;UAEA,IAAIN,MAAM,EAAE;YACV,IAAI,CAACV,SAAS,EAAE;cACd;cACA;cACA;cACA;cACA,MAAMG,IAAtB,GAA6BjD,KAAK,CAACiD,IAAI,CAAQ;gBAC7BpC,EAAE,EAAE,eAAe;gBACnB;gBACA;gBACA;gBACAmB,KAAK,EAAE,IAAI,CAACtB,YAAY,CAACuD,eAAe,CAACH,QAAQ,CAACtB,QAAQ,EACvD0B,OAAO;gBACV7C,SAAS,EAAEyC,QAAQ,CAACzC,SAAS;gBAC7BwB,UAAU,EAAE,KAAK;gBACjBD,iBAAiB,EAAE;cACrC,CAAiB,CAAC;cAEF,IAAIK,IAAI,CAACU,QAAQ,EAAE;gBACjBvC,MAAlB,GAAAwC,aAAA,CAAAA,aAAA,KACuBxC,MAAM;kBACTK,IAAI,EAAEwB,IAAI,CAAC7B;gBAAM,EAClB;cACH;YACF;YAEA;YACA,IAAI,CAAC,IAAI,CAACO,OAAO,EAAE;cACjB6B,MAAM,CACJxD,KAAe,EACfoB,MAAmD,EACnD;gBACEyE,OAAO,EAAE/B,QAAQ,CAAC+B,OAAO;gBACzBxE,SAAS,EAAEyC,QAAQ,CAACzC;cACxC,CAAmB,CACF;YACH;UACF;UAEA;UACA;UACA,IAAI,CAACyB,SAAjB,IAA8B,CAACgB,QAAQ,CAACgC,cAAxC,IAA0D,CAAC,IAAI,CAACnE,OAAO,EAAE;YAC3D3B,KAAK,CAAC+F,MAAM,CAAC;cACXlF,EAAE,EAAE,eAAe;cACnBmF,MAAMA,CAAC/E,KAAK,EAAAgF,KAAA,EAA5B;gBAAA,IAA8B;kBAAEC,SAAS;kBAAEC;gBAA3C,CAAmD,GAAAF,KAAA;gBACjC,OAAOC,SAAzB,KAAuC,YAAvC,GAAsDjF,KAAtD,GAA8DkF,MAAM;cACpD;YAChB,CAAe,CAAC;UACJ;QACF,CAAC;QAEDC,OAAO,EAAEb,cAAc;QAEvB;QACA1C,UAAU,EAAE,KAAK;QAEjB;QACA;QACA4C,gBAAgB,EAAE3B,QAAQ,CAAC2B,gBAAgB;QAE3C;QACA;QACA;QACA;QACAD,cAAc,EAAE1B,QAAQ,CAAC0B,cAAnC,IAAqD;MACrD,CAAS,EACAZ,OAAO,CAAExD,MAAM,IAAKsE,OAAO,CAAClB,IAAI,CAACpD,MAAM,CAAC,CAAC;MAE5C,IAAI0C,QAAQ,CAACuC,mBAAnB,IAA0CvC,QAAQ,CAAC0B,cAAc,EAAE;QAC3D;QACA;QACA;QACA,OAAOpB,OAAO,CAACkC,GAAG,CAACZ,OAAO,CAAC,CAACa,IAAI,CAAC,MAAMnF,MAAM,CAAC;MAChD;IACF;IAEA,OAAOgD,OAAO,CAACC,OAAO,CAACjD,MAAM,CAAC;EAChC;EAEOoF,sBAAsBA,CAC3BC,kBAAuB,EACvB3C,QASC,EAXL;IAaI,MAAMrC,IAAV,GACM,OAAOgF,kBADb,KACoC,UADpC,GAEQA,kBAAkB,CAAC3C,QAAQ,CAACzC,SAAS,EAAE;MAAEzB;IAAjD,CAAyD,IACjD6G,kBAAkB;IAEtB,IAAIhF,IAAR,KAAiB7B,MAAM,EAAE;MACnB,OAAO,KAAK;IACd;IAEA,IAAI,CAACI,KAAK,CAAC0G,2BAA2B,CAAE1G,KAAK,IAAjD;MACM,IAAI;QACF,IAAI,CAAC6D,kBAAkB,CAAC;UAAEpC;QAAlC,CAAwC,EAAEqC,QAAQ,EAAE9D,KAAe,CAAC;MAC9D,EAAE,OAAO2G,KAAK,EAAE;QACdhH,SAAS,CAACgH,KAAK,CAACA,KAAK,CAAC;MACxB;IACF,CAAC,EAAE,IAAI,CAAC9F,EAAE,CAAC;IAEX,OAAO,IAAI;EACb;EAEO+F,sBAAsBA,CAC3BxF,MAAuC,EAAAyF,KAAA,EAD3C;IAAA,IAEI;MACErE,QAAQ;MACRnB,SAAS;MACToB,WAAW;MACXC;IANN,CAWK,GAAAmE,KAAA;IAED,IAAInE,kBAAR,wCAA0D;MACpD,IAAIQ,iBAAiB,CAAC9B,MAAM,EAAEqB,WAAW,CAAC,EAAE;QAC1C,IAAI,CAACzC,KAAK,CAAC4F,KAAK,CAAC;UACf5D,KAAK,EAAEQ,QAAQ;UACfpB,MAAM,EAAEA,MAAM,CAACK,IAAW;UAC1BgD,MAAM,EAAE,mBAAmB;UAC3BpD,SAAS,EAAEA,SAAS;UACpBK,UAAU,EAAEN,MAAM,CAACM;QAC7B,CAAS,CAAC;MACJ;MAEA,IAAI,CAAChB,YAAY,CAACoG,gBAAgB,CAAxC,CAA0C;IACtC;EACF;AACF;AAEA,SAAS5D,iBAAiBA,CACxB9B,MAAmC,EADrC;EAAA,IAEEqB,WAFF,GAAAnC,SAAA,CAAAyD,MAAA,QAAAzD,SAAA,QAAA0C,SAAA,GAAA1C,SAAA,MAE6B,MAAM;EAEjC,MAAMyG,YAAR,GAAuBtE,WAAvB,KAAuC,QAAvC,IAAmDA,WAAnD,KAAmE,KAAK;EACtE,IAAIuE,eAAN,GAAwB,CAACvH,qBAAqB,CAAC2B,MAAM,CAAC;EACpD,IAAI,CAAC4F,eAAP,IAA0BD,YAA1B,IAA0C3F,MAAM,CAACK,IAAI,EAAE;IACnDuF,eAAJ,GAAsB,IAAI;EACxB;EACA,OAAOA,eAAe;AACxB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}